[
  {
    "title": "Epstein-linked longevity guru Peter Attia leaves David Protein, and his own startup ‘won’t comment’",
    "slug": "epsteinlinked-longevity-guru-peter-attia-leaves-david-protein-and-his-own-startup-wont-comment",
    "content": "Attia co-founded longevity medical testing startup Biograph, which came out of stealth a year ago.",
    "link": "https://techcrunch.com/2026/02/03/epstein-linked-longevity-guru-peter-attia-leaves-david-protein-and-his-own-startup-wont-comment/"
  },
  {
    "title": "India’s Varaha bags $20M to scale carbon removal from the Global South",
    "slug": "indias-varaha-bags-20m-to-scale-carbon-removal-from-the-global-south",
    "content": "Varaha's fresh funding is part of a $45 million Series B round led by WestBridge Capital.",
    "link": "https://techcrunch.com/2026/02/03/indias-varaha-bags-20m-to-scale-carbon-removal-from-the-global-south/"
  },
  {
    "title": "The Minneapolis tech community holds strong during ‘tense and difficult time’",
    "slug": "the-minneapolis-tech-community-holds-strong-during-tense-and-difficult-time",
    "content": "Founders and investors in the Minneapolis tech industry told TechCrunch they've put much of their work on hold to help out their community.",
    "link": "https://techcrunch.com/2026/02/03/minnesota-tech-community-founders-investors-ice-response/"
  },
  {
    "title": "Intel will start making GPUs, a market dominated by Nvidia",
    "slug": "intel-will-start-making-gpus-a-market-dominated-by-nvidia",
    "content": "Intel has been bulking up a team to focus on this effort and will develop its GPU strategy around customer needs.",
    "link": "https://techcrunch.com/2026/02/03/intel-will-start-making-gpus-a-market-dominated-by-nvidia/"
  },
  {
    "title": "YC startups can now receive investment in stablecoin",
    "slug": "yc-startups-can-now-receive-investment-in-stablecoin",
    "content": "All startups accepted into YC will soon have the option to receive their seed checks via stablecoins.",
    "link": "https://techcrunch.com/2026/02/03/yc-startups-can-now-recieve-investment-in-stablecoin/"
  },
  {
    "title": "2026 plans: What’s next for Startup Battlefield 200",
    "slug": "2026-plans-whats-next-for-startup-battlefield-200",
    "content": "See what to expect for Startup Battlefield 200 in 2026, the ultimate startup pitch competition on the global stage at TechCrunch Disrupt. Join the mailing list to be the first to know when applications drop.",
    "link": "https://techcrunch.com/2026/02/03/looking-ahead-to-2026-whats-next-for-startup-battlefield-200/"
  },
  {
    "title": "Homeland Security is trying to force tech companies to hand over data about Trump critics",
    "slug": "homeland-security-is-trying-to-force-tech-companies-to-hand-over-data-about-trump-critics",
    "content": "The use of administrative subpoenas, which are not subject to judicial oversight, are used to demand a wealth of information from tech companies, including the owners of anonymous online accounts documenting ICE operations.",
    "link": "https://techcrunch.com/2026/02/03/homeland-security-is-trying-to-force-tech-companies-to-hand-over-data-about-trump-critics/"
  },
  {
    "title": "Skyryse lands another $300M to make flying, even helicopters, simple and safe",
    "slug": "skyryse-lands-another-300m-to-make-flying-even-helicopters-simple-and-safe",
    "content": "Skyrsye, now valued at $1.15 billion, is pushing to get FAA certification for its universal operating system for flight.",
    "link": "https://techcrunch.com/2026/02/03/skyryse-lands-another-300m-to-make-flying-even-helicopters-simple-and-safe/"
  },
  {
    "title": "Xcode moves into agentic coding with deeper OpenAI and Anthropic integrations",
    "slug": "xcode-moves-into-agentic-coding-with-deeper-openai-and-anthropic-integrations",
    "content": "Xcode 26.3 offers agentic coding capabilities with Anthropic's Claude Agent and OpenAI's Codex.",
    "link": "https://techcrunch.com/2026/02/03/xcode-moves-into-agentic-coding-with-deeper-openai-and-anthropic-integrations/"
  },
  {
    "title": "Gradient’s heat pumps get new smarts to enable old-building retrofits",
    "slug": "gradients-heat-pumps-get-new-smarts-to-enable-oldbuilding-retrofits",
    "content": "Gradient's heat pumps fit in windows, minimizing installation times. Now, it is introducing software to make those units more intelligent.",
    "link": "https://techcrunch.com/2026/02/03/gradients-heat-pumps-get-new-smarts-to-enable-old-building-retrofits/"
  },
  {
    "title": "Watch Club is producing short video dramas and building a social network around them",
    "slug": "watch-club-is-producing-short-video-dramas-and-building-a-social-network-around-them",
    "content": "Watch Club will house microdramas and fan discussions in the same app, creating a fandom-focused social media experience.",
    "link": "https://techcrunch.com/2026/02/03/watch-club-microdrama-video-social-network/"
  },
  {
    "title": "Lotus Health nabs $35M for AI doctor that sees patients for free",
    "slug": "lotus-health-nabs-35m-for-ai-doctor-that-sees-patients-for-free",
    "content": "This AI doctor is licensed in all 50 states, the startup says. The deal was led by CRV and Kleiner Perkins.",
    "link": "https://techcrunch.com/2026/02/03/lotus-health-nabs-35m-for-ai-doctor-that-sees-patients-for-free/"
  },
  {
    "title": "French police search X office in Paris, summon Elon Musk for questioning",
    "slug": "french-police-search-x-office-in-paris-summon-elon-musk-for-questioning",
    "content": "The Paris prosecutor’s office announced that it is expanding a criminal investigation into X for alleged crimes, including the possession and distribution of child sexual exploitation material.",
    "link": "https://techcrunch.com/2026/02/03/french-police-search-x-office-in-paris-summon-elon-musk-for-questioning/"
  },
  {
    "title": "What tech CEOs and executives have said about ICE’s actions in Minnesota",
    "slug": "what-tech-ceos-and-executives-have-said-about-ices-actions-in-minnesota",
    "content": "The Trump administration’s approach to immigration has reached a level of violence that the tech industry cannot ignore. Here's how tech leaders are responding to the moment.",
    "link": "https://techcrunch.com/2026/02/03/what-tech-ceos-and-executives-have-said-about-ice-in-minnesota/"
  },
  {
    "title": "TikTok recovers from dip in usage that benefited rival apps following US ownership change",
    "slug": "tiktok-recovers-from-dip-in-usage-that-benefited-rival-apps-following-us-ownership-change",
    "content": "TikTok usage dropped following ownership change, benefiting rival apps. But now, its numbers are climbing again.",
    "link": "https://techcrunch.com/2026/02/03/tiktok-recovers-from-dip-in-usage-that-benefited-rival-apps-following-u-s-ownership-change/"
  },
  {
    "title": "Fitbit founders launch AI platform to help families monitor their health",
    "slug": "fitbit-founders-launch-ai-platform-to-help-families-monitor-their-health",
    "content": "Luffu uses AI in the background to gather and organize family information, learn day-to-day patterns, and flag notable changes so families can stay aligned and address potential well-being issues.",
    "link": "https://techcrunch.com/2026/02/03/fitbit-founders-launch-ai-platform-to-help-families-monitor-their-health/"
  },
  {
    "title": "PayPal hires HP’s Enrique Lores as its new CEO",
    "slug": "paypal-hires-hps-enrique-lores-as-its-new-ceo",
    "content": "PayPal is appointing CFO and COO Jamie Miller as interim CEO until March 1.",
    "link": "https://techcrunch.com/2026/02/03/paypal-hires-hps-enrique-lores-as-its-new-ceo/"
  },
  {
    "title": "Peak XV says internal disagreement led to partner exits as it doubles down on AI",
    "slug": "peak-xv-says-internal-disagreement-led-to-partner-exits-as-it-doubles-down-on-ai",
    "content": "Peak XV is transitioning board roles and opening a U.S. office while continuing to view India as its largest market.",
    "link": "https://techcrunch.com/2026/02/03/peak-xv-says-internal-disagreement-led-to-partner-exits-as-it-doubles-down-on-ai/"
  },
  {
    "title": "India’s Supreme Court to WhatsApp: ‘You cannot play with the right to privacy’",
    "slug": "indias-supreme-court-to-whatsapp-you-cannot-play-with-the-right-to-privacy",
    "content": "India's top court is investigating WhatsApp’s data-sharing model, monopoly power, and user consent.",
    "link": "https://techcrunch.com/2026/02/03/indias-supreme-court-to-whatsapp-you-cannot-play-with-the-right-to-privacy/"
  },
  {
    "title": "Vema predicts cheap hydrogen could change where data centers are built",
    "slug": "vema-predicts-cheap-hydrogen-could-change-where-data-centers-are-built",
    "content": "Vema Hydrogen drills wells to stimulate hydrogen production deep underground, which could result in some of the cheapest hydrogen available.",
    "link": "https://techcrunch.com/2026/02/03/vema-predicts-cheap-hydrogen-could-change-where-data-centers-are-built/"
  },
  {
    "title": "Netflix says users can cancel service if HBO Max merger makes it too expensive",
    "slug": "netflix-says-users-can-cancel-service-if-hbo-max-merger-makes-it-too-expensive",
    "content": "80 percent of HBO Max subscribers subscribe to Netflix, Sarandos tells Senate.",
    "link": "https://arstechnica.com/gadgets/2026/02/netflix-claims-subscribers-will-get-more-content-for-less-if-it-buys-hbo-max/"
  },
  {
    "title": "Godlike Titan threatens humanity in Monarch: Legacy of Monsters S2 trailer",
    "slug": "godlike-titan-threatens-humanity-in-monarch-legacy-of-monsters-s2-trailer",
    "content": "\"This Titan is like a god, and the sea creatures worship it.\"",
    "link": "https://arstechnica.com/culture/2026/02/meet-the-new-tentacled-titan-x-in-monarch-legacy-of-monsters-s2-trailer/"
  },
  {
    "title": "Nvidia's $100 billion OpenAI deal has seemingly vanished",
    "slug": "nvidias-100-billion-openai-deal-has-seemingly-vanished",
    "content": "Two AI giants shake market confidence after investment fails to materialize.",
    "link": "https://arstechnica.com/information-technology/2026/02/five-months-later-nvidias-100-billion-openai-investment-plan-has-fizzled-out/"
  },
  {
    "title": "Newborn dies after mother drinks raw milk during pregnancy",
    "slug": "newborn-dies-after-mother-drinks-raw-milk-during-pregnancy",
    "content": "Raw milk is promoted by anti-vaccine Health Secretary Kennedy.",
    "link": "https://arstechnica.com/health/2026/02/newborns-death-spurs-raw-milk-warning-in-new-mexico/"
  },
  {
    "title": "X office raided in France's Grok probe; Elon Musk summoned for questioning",
    "slug": "x-office-raided-in-frances-grok-probe-elon-musk-summoned-for-questioning",
    "content": "Paris prosecutor: Illegal content probe includes pornographic images of minors.",
    "link": "https://arstechnica.com/tech-policy/2026/02/x-office-raided-in-frances-grok-probe-elon-musk-summoned-for-questioning/"
  },
  {
    "title": "Nintendo Switch is the second-bestselling game console ever, behind only the PS2",
    "slug": "nintendo-switch-is-the-secondbestselling-game-console-ever-behind-only-the-ps2",
    "content": "Switch 2 has already beaten the Wii U and is on its way to overtaking GameCube.",
    "link": "https://arstechnica.com/gadgets/2026/02/original-nintendo-switch-passes-the-ds-to-become-nintendos-bestselling-console/"
  },
  {
    "title": "Google court filings suggest ChromeOS has an expiration date",
    "slug": "google-court-filings-suggest-chromeos-has-an-expiration-date",
    "content": "ChromeOS may be canned once the current support guarantee has run its course.",
    "link": "https://arstechnica.com/google/2026/02/google-court-filings-suggest-googles-chromeos-has-an-expiration-date/"
  },
  {
    "title": "Xcode 26.3 adds support for Claude, Codex, and other agentic tools via MCP",
    "slug": "xcode-263-adds-support-for-claude-codex-and-other-agentic-tools-via-mcp",
    "content": "With Model Context Protocol (MCP), this works with more than Codex/Claude, too.",
    "link": "https://arstechnica.com/apple/2026/02/xcode-26-3-adds-support-for-claude-codex-and-other-agentic-tools-via-mcp/"
  },
  {
    "title": "Wing Commander III: \"Isn't that the guy from Star Wars?\"",
    "slug": "wing-commander-iii-isnt-that-the-guy-from-star-wars",
    "content": "C:\\ArsGames looks at a vanguard of the multimedia FMV future that never quite came to pass.",
    "link": "https://arstechnica.com/gaming/2026/02/wing-commander-iii-the-game-kind-of-sucked-but-the-experience-blew-me-away/"
  },
  {
    "title": "Upset at reports that he'd given up, Trump now wants $1B from Harvard",
    "slug": "upset-at-reports-that-hed-given-up-trump-now-wants-1b-from-harvard",
    "content": "Hefty \"fine\" comes in wake of NY Times reporting of money-free settlement.",
    "link": "https://arstechnica.com/tech-policy/2026/02/upset-at-reports-that-hed-given-up-trump-now-wants-1b-from-harvard/"
  },
  {
    "title": "China bans all retractable car door handles, starting next year",
    "slug": "china-bans-all-retractable-car-door-handles-starting-next-year",
    "content": "The pop-out door handle ban starts in 2027 for new cars, 2029 for existing models.",
    "link": "https://arstechnica.com/cars/2026/02/china-bans-all-retractable-car-door-handles-starting-next-year/"
  },
  {
    "title": "Senior staff departing OpenAI as firm prioritizes ChatGPT development",
    "slug": "senior-staff-departing-openai-as-firm-prioritizes-chatgpt-development",
    "content": "Resources are redirected from long-term research toward improving the flagship chatbot.",
    "link": "https://arstechnica.com/ai/2026/02/senior-staff-departing-openai-as-firm-prioritizes-chatgpt-development/"
  },
  {
    "title": "The rise of Moltbook suggests viral AI prompts may be the next big security threat",
    "slug": "the-rise-of-moltbook-suggests-viral-ai-prompts-may-be-the-next-big-security-threat",
    "content": "We don't need self-replicating AI models to have problems, just self-replicating prompts.",
    "link": "https://arstechnica.com/ai/2026/02/the-rise-of-moltbook-suggests-viral-ai-prompts-may-be-the-next-big-security-threat/"
  },
  {
    "title": "Unable to tame hydrogen leaks, NASA delays launch of Artemis II until March",
    "slug": "unable-to-tame-hydrogen-leaks-nasa-delays-launch-of-artemis-ii-until-march",
    "content": "NASA spent most of Monday trying to overcome hydrogen leaks on the Artemis II rocket.",
    "link": "https://arstechnica.com/space/2026/02/unable-to-tame-hydrogen-leaks-nasa-delays-launch-of-artemis-ii-until-march/"
  },
  {
    "title": "Looking back at Catacomb 3D, the game that led to Wolfenstein 3D",
    "slug": "looking-back-at-catacomb-3d-the-game-that-led-to-wolfenstein-3d",
    "content": "Romero, Carmack, and colleagues discuss an oft-forgotten piece of PC gaming history.",
    "link": "https://arstechnica.com/gaming/2026/02/looking-back-at-catacomb-3d-the-game-that-led-to-wolfenstein-3d/"
  },
  {
    "title": "Streaming service Crunchyroll raises prices weeks after killing its free tier",
    "slug": "streaming-service-crunchyroll-raises-prices-weeks-after-killing-its-free-tier",
    "content": "Sony has made streaming anime pricier since buying Crunchyroll.",
    "link": "https://arstechnica.com/gadgets/2026/02/streaming-service-crunchyroll-raises-prices-weeks-after-killing-its-free-tier/"
  },
  {
    "title": "SpaceX acquires xAI, plans to launch a massive satellite constellation to power it",
    "slug": "spacex-acquires-xai-plans-to-launch-a-massive-satellite-constellation-to-power-it",
    "content": "\"This marks not just the next chapter, but the next book in SpaceX and xAI's mission.\"",
    "link": "https://arstechnica.com/ai/2026/02/spacex-acquires-xai-plans-1-million-satellite-constellation-to-power-it/"
  },
  {
    "title": "Russian drones use Starlink, but Ukraine has plan to block their Internet access",
    "slug": "russian-drones-use-starlink-but-ukraine-has-plan-to-block-their-internet-access",
    "content": "Defense chief: \"No Ukrainians have been killed by Russian drones using Starlink.\"",
    "link": "https://arstechnica.com/tech-policy/2026/02/russian-drones-use-starlink-but-ukraine-has-plan-to-block-their-internet-access/"
  },
  {
    "title": "Court orders restart of all US offshore wind construction",
    "slug": "court-orders-restart-of-all-us-offshore-wind-construction",
    "content": "Trump admin's \"it's classified\" ploy put on hold in five different cases.",
    "link": "https://arstechnica.com/science/2026/02/court-orders-restart-of-all-us-offshore-wind-construction/"
  },
  {
    "title": "Notepad++ users take note: It's time to check if you're hacked",
    "slug": "notepad-users-take-note-its-time-to-check-if-youre-hacked",
    "content": "Suspected China-state hackers used update infrastructure to deliver backdoored version.",
    "link": "https://arstechnica.com/security/2026/02/notepad-updater-was-compromised-for-6-months-in-supply-chain-attack/"
  },
  {
    "title": "SpaceX and xAI: A merger of ambition, optics, and unanswered questions",
    "slug": "spacex-and-xai-a-merger-of-ambition-optics-and-unanswered-questions",
    "content": "<img height=\"417\" src=\"https://img-cdn.tnwcdn.com/image?fit=796%2C417&amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2026%2F02%2FSpacex-aquires-xAI.png&amp;signature=f1114eea3adec6f16fea3b2757eb82ac\" width=\"796\" /><br />If you look at the press releases and breathless commentary around the recent acquisition of xAI by SpaceX, you might think we’re witnessing a tectonic shift in technological destiny.  A $1.25 trillion “mega-company” is born, poised to reshape artificial intelligence, space infrastructure, satellite internet, and possibly the fate of humanity itself. That narrative, enthusiastically repeated across headlines, serves a purpose: it frames a somewhat messy corporate consolidation as inevitable progress.  But let’s take a closer look and separate actual substance from Silicon Valley myth-making. A mega-deal that’s really an identity crisis At its core, this acquisition solves one problem: xAI needed&#8230;<br /><br /><a href=\"https://thenextweb.com/news/spacex-and-xai-a-merger-of-ambition-optics-and-unanswered-questions?utm_source=social&#038;utm_medium=feed&#038;utm_campaign=profeed\">This story continues</a> at The Next Web<br /><br />Or just read more coverage about: <a href=\"https://thenextweb.com/company/spacex\">SpaceX</a>",
    "link": "https://thenextweb.com/news/spacex-and-xai-a-merger-of-ambition-optics-and-unanswered-questions"
  },
  {
    "title": "OpenAI’s Codex app: When your IDE gets a brain",
    "slug": "openais-codex-app-when-your-ide-gets-a-brain",
    "content": "<img height=\"417\" src=\"https://img-cdn.tnwcdn.com/image?fit=796%2C417&amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2026%2F02%2FOpenAI-Codex-app.png&amp;signature=de04b0abc9b015ab0901a845660ece30\" width=\"796\" /><br />OpenAI has given software developers a new desktop toy, and judging by the early reactions, it might feel like someone finally handed coders the Swiss Army knife they’ve been dreaming about or the kind of gadget that makes them wonder if they’re working with a robot coworker now.  The company rolled out the Codex app for macOS, a focused interface for managing AI coding agents, designed to let developers do more than just “generate a few lines of code.” Instead, Codex can juggle multiple tasks in parallel, run background workflows, and act on instructions that span hours or even days. &#8230;<br /><br /><a href=\"https://thenextweb.com/news/openais-codex-app-when-your-ide-gets-a-brain?utm_source=social&#038;utm_medium=feed&#038;utm_campaign=profeed\">This story continues</a> at The Next Web",
    "link": "https://thenextweb.com/news/openais-codex-app-when-your-ide-gets-a-brain"
  },
  {
    "title": "Europe’s not-so-dry January: Unicorns and a new tech identity",
    "slug": "europes-notsodry-january-unicorns-and-a-new-tech-identity",
    "content": "<img height=\"417\" src=\"https://img-cdn.tnwcdn.com/image?fit=796%2C417&amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2026%2F02%2FEurope-new-startup-unicorns.png&amp;signature=25cb1e3fe390cd2851e9255259ed392a\" width=\"796\" /><br />Every January, millions take on Dry January, a ritual of restraint and resetting after the holiday season. If that’s the benchmark for kicking off the year with moderation, Europe’s startup ecosystem clearly didn’t get the memo.  In the opening weeks of 2026, the region saw five startups join the unicorn club, crossing the $1 billion valuation mark across sectors as varied as cybersecurity, cloud optimisation, defence tech, ESG software, and education technology.  January was anything but dry for European companies. This burst of activity signals more than a funding spike; it invites a deeper look at what Europe’s innovation identity&#8230;<br /><br /><a href=\"https://thenextweb.com/news/europes-not-so-dry-january-unicorns-and-a-new-tech-identity?utm_source=social&#038;utm_medium=feed&#038;utm_campaign=profeed\">This story continues</a> at The Next Web",
    "link": "https://thenextweb.com/news/europes-not-so-dry-january-unicorns-and-a-new-tech-identity"
  },
  {
    "title": "TNW Weekly Briefing",
    "slug": "tnw-weekly-briefing",
    "content": "<img height=\"417\" src=\"https://img-cdn.tnwcdn.com/image?fit=796%2C417&amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2026%2F02%2FWhatsApp-Image-2026-02-01-at-15.29.53.jpeg&amp;signature=27b25aeabece1a66224e35e4a86043b1\" width=\"796\" /><br />G2 acquires Capterra, Software Advice, and GetApp from Gartner G2 has completed a major acquisition by purchasing three of the world’s most influential software discovery platforms from Gartner. The move significantly reshapes the global B2B software reviews market and strengthens G2’s position in how companies evaluate and buy software. Noora Saksaa appointed CEO of Slush Slush, one of Europe’s most influential tech and startup events, has named Noora Saksa as its new CEO. The leadership change signals a strategic shift toward expanding Slush beyond its annual event and building a year-round global founder platform. France moves public sector away from&#8230;<br /><br /><a href=\"https://thenextweb.com/news/tnw-weekly-briefing-3?utm_source=social&#038;utm_medium=feed&#038;utm_campaign=profeed\">This story continues</a> at The Next Web",
    "link": "https://thenextweb.com/news/tnw-weekly-briefing-3"
  },
  {
    "title": "Is G2 becoming too powerful for the software market?",
    "slug": "is-g2-becoming-too-powerful-for-the-software-market",
    "content": "<img height=\"417\" src=\"https://img-cdn.tnwcdn.com/image?fit=796%2C417&amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2026%2F02%2FTNW-Article-Banner-3.png&amp;signature=6797c16e5545dbe1de29f4fa151f75a3\" width=\"796\" /><br />The software industry is increasingly questioning the growing influence of G2 following its agreement to acquire Capterra, Software Advice, and GetApp from Gartner. The deal, announced in late January and expected to close in Q1 2026, consolidates several of the most influential B2B software discovery platforms under a single owner . How big is G2’s footprint after the acquisition? According to G2’s own disclosures, the combined group will host around 6 million verified software reviews and reach more than 200 million software buyers annually across thousands of categories. Individually, the platforms already commanded significant scale: G2 reports over 3 million&#8230;<br /><br /><a href=\"https://thenextweb.com/news/is-g2-becoming-too-powerful-for-the-software-market?utm_source=social&#038;utm_medium=feed&#038;utm_campaign=profeed\">This story continues</a> at The Next Web",
    "link": "https://thenextweb.com/news/is-g2-becoming-too-powerful-for-the-software-market"
  },
  {
    "title": "The rise of the always-on economy: subscriptions beyond streaming",
    "slug": "the-rise-of-the-alwayson-economy-subscriptions-beyond-streaming",
    "content": "<img height=\"417\" src=\"https://img-cdn.tnwcdn.com/image?fit=796%2C417&amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2026%2F01%2FSubscription-economy.png&amp;signature=4f57f31cbd673db51364979f3036f3b0\" width=\"796\" /><br />We are all familiar with the subscription economy, and it certainly works as a reminder of the COVID-19 pandemic, when we were all hooked on our TVs watching Netflix or listening to our favorite music artist on Spotify. Despite how modern it seems to be, the truth is that the subscription economy has been around for some time, surprisingly dating back to around 1800, with the first magazine subscriptions, or the subscriptions for fresh British milk, around 1860. Over the years, the of subscription-based companies has turned the subscription model into an ideal business strategy since it provides unique benefits.&#8230;<br /><br /><a href=\"https://thenextweb.com/news/the-rise-of-subscription-economy?utm_source=social&#038;utm_medium=feed&#038;utm_campaign=profeed\">This story continues</a> at The Next Web",
    "link": "https://thenextweb.com/news/the-rise-of-subscription-economy"
  },
  {
    "title": "Apple buys “Silent Speech” AI startup for $2B,  because talking is so 2025",
    "slug": "apple-buys-silent-speech-ai-startup-for-2b--because-talking-is-so-2025",
    "content": "<img height=\"417\" src=\"https://img-cdn.tnwcdn.com/image?fit=796%2C417&amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2026%2F01%2FTNW-Article-Banner-10-1.png&amp;signature=338348850b64fdcf6dfc2e3405df8882\" width=\"796\" /><br />Apple confirmed this week that it has acquired Israeli AI startup Q.ai in a deal valued at close to $2 billion, making it one of the company’s largest acquisitions ever, second only to the $3 billion purchase of Beats in 2014.  But check your assumptions: this isn’t Beats 2.0. There’s no new headphone brand to flex. Instead, Apple is paying top dollar for tech that might let your devices understand you without you ever saying a word. ​​These days we put our phones on silent so they won’t disturb us; soon the phone will put us on silent so it&#8230;<br /><br /><a href=\"https://thenextweb.com/news/apple-buys-silent-speech-ai-startup-for-2b-because-talking-is-so-2025?utm_source=social&#038;utm_medium=feed&#038;utm_campaign=profeed\">This story continues</a> at The Next Web<br /><br />Or just read more coverage about: <a href=\"https://thenextweb.com/company/apple\">Apple</a>",
    "link": "https://thenextweb.com/news/apple-buys-silent-speech-ai-startup-for-2b-because-talking-is-so-2025"
  },
  {
    "title": "G2 bold move to reshape software discovery with major acquisition from Gartner",
    "slug": "g2-bold-move-to-reshape-software-discovery-with-major-acquisition-from-gartner",
    "content": "<img height=\"417\" src=\"https://img-cdn.tnwcdn.com/image?fit=796%2C417&amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2026%2F01%2FG2.png&amp;signature=40e184ca34f454de6ddc895b6aca8f25\" width=\"796\" /><br />G2, the Chicago-based software insights platform, agreed today to acquire three prominent software review and discovery properties from Gartner: Capterra, Software Advice, and GetApp. The deal brings four of the largest B2B review sites under a single roof and signals a shift toward unified, AI-driven software recommendation and buying experiences.   According to the announcement, the combined business will include roughly six million verified customer reviews and tap into an audience of more than 200 million annual software buyers. G2 said it expects the transaction to close in the first quarter of 2026, subject to standard regulatory and closing conditions.   G2’s&#8230;<br /><br /><a href=\"https://thenextweb.com/news/g2-bold-move-to-reshape-software-discovery-with-major-acquisition-from-gartner?utm_source=social&#038;utm_medium=feed&#038;utm_campaign=profeed\">This story continues</a> at The Next Web",
    "link": "https://thenextweb.com/news/g2-bold-move-to-reshape-software-discovery-with-major-acquisition-from-gartner"
  },
  {
    "title": "AI isn’t coming for your job, it’s coming for your justification",
    "slug": "ai-isnt-coming-for-your-job-its-coming-for-your-justification",
    "content": "<img height=\"417\" src=\"https://img-cdn.tnwcdn.com/image?fit=796%2C417&amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2026%2F01%2FAI-isnt-coming-for-your-job.png&amp;signature=b08fd13fff5b1d7d7006843fdd66eb57\" width=\"796\" /><br />AI adoption is creating a clear divide among employees. Some see AI as a tool to increase their impact, while others see it as a threat to their role. So, where does the truth lie between these two mindsets? Let’s explore. AI doesn’t eliminate roles, it removes low-leverage work Over the past two years, we’ve seen a wave of layoffs often attributed to “AI replacing humans.” Among widely discussed cases, IBM openly stated that over 7,000 back-office roles may no longer need to be hired because AI can absorb the work. Many other tech players, including Microsoft, Amazon, and HP,&#8230;<br /><br /><a href=\"https://thenextweb.com/news/ai-isnt-coming-for-your-job?utm_source=social&#038;utm_medium=feed&#038;utm_campaign=profeed\">This story continues</a> at The Next Web",
    "link": "https://thenextweb.com/news/ai-isnt-coming-for-your-job"
  },
  {
    "title": "TNW Moves Its Flagship Conference to London",
    "slug": "tnw-moves-its-flagship-conference-to-london",
    "content": "<img height=\"417\" src=\"https://img-cdn.tnwcdn.com/image?fit=796%2C417&amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2026%2F01%2FTNW-Article-Banner-1.png&amp;signature=cf30ba706b55325d695c14b7fba49efd\" width=\"796\" /><br />The Next Web (TNW) is making a bold move: its flagship conference is relocating to London, placing TNW’s main annual event at the centre of one of the world’s most powerful technology and investment ecosystems. The move marks a significant moment for TNW and signals a broader evolution of the brand’s global events strategy. A new concept: TNW Gathering Alongside the move to London, TNW is introducing a new global event concept: TNW Gathering. Designed as an intimate, invite-only format, TNW Gathering is created for members of the TNW Council and a carefully selected group of founders, operators, and investors.&#8230;<br /><br /><a href=\"https://thenextweb.com/news/tnw-moves-its-flagship-conference-to-london?utm_source=social&#038;utm_medium=feed&#038;utm_campaign=profeed\">This story continues</a> at The Next Web",
    "link": "https://thenextweb.com/news/tnw-moves-its-flagship-conference-to-london"
  },
  {
    "title": "Adobe actually won’t discontinue Animate",
    "slug": "adobe-actually-wont-discontinue-animate",
    "content": "Adobe is no longer planning to discontinue Adobe Animate on March 1st. In an FAQ, the company now says that Animate will now be in maintenance mode and that it has \"no plans to&#8239;discontinue or remove access\" to the app. Animate will still receive \"ongoing security and bug fixes\" and will still be available for [&#8230;]",
    "link": "https://www.theverge.com/tech/873621/adobe-animate-maintenance-mode-reverse-course"
  },
  {
    "title": "Republicans haul Netflix before Congress for being too ‘woke’",
    "slug": "republicans-haul-netflix-before-congress-for-being-too-woke",
    "content": "Netflix CEO Ted Sarandos was launched into the middle of a congressional culture war on Tuesday as he testified before a Senate subcommittee about the company's attempt to buy a large part of Warner Bros Discovery. The hearing before the Senate Judiciary antitrust subcommittee highlighted an array of traditional merger concerns on both sides of [&#8230;]",
    "link": "https://www.theverge.com/policy/873533/netflix-warner-bros-discovery-senate-antitrust-hearing"
  },
  {
    "title": "AMD hints Microsoft could launch its next-gen Xbox in 2027",
    "slug": "amd-hints-microsoft-could-launch-its-nextgen-xbox-in-2027",
    "content": "Microsoft confirmed last year that it's working on a next-gen Xbox console in partnership with AMD. Now, AMD is hinting that the next Xbox console, which will use custom AMD chips, could be launching in 2027. \"Development of Microsoft's next-gen Xbox, featuring an AMD semi-custom SoC, is progressing well to support a launch in 2027,\" [&#8230;]",
    "link": "https://www.theverge.com/news/873490/microsoft-next-gen-xbox-console-2027-date-amd"
  },
  {
    "title": "Department of Justice appeals Google search monopoly ruling",
    "slug": "department-of-justice-appeals-google-search-monopoly-ruling",
    "content": "On Tuesday, the Department of Justice and the plaintiffs in the antitrust case against Google filed a cross-appeal, as the DOJ Antitrust Division announced in a post on X: \"Today, the DOJ Antitrust Division filed notice that it will cross-appeal from the remedies decisions in its case against Google's unlawful monopolization of internet search and [&#8230;]",
    "link": "https://www.theverge.com/tech/873438/google-antitrust-case-doj-states-appeal"
  },
  {
    "title": "Slopaganda goes West",
    "slug": "slopaganda-goes-west",
    "content": "After right-wing YouTuber Nick Shirley's viral video alleging fraud at Minnesota daycares he said were operated by Somali residents, Donald Trump's administration responded by flooding the state with federal immigration agents and freezing funding for childcare services. (A judge ruled that the federal government must continue funding childcare subsidies, at least temporarily.) Now Shirley is [&#8230;]",
    "link": "https://www.theverge.com/news/873400/nick-shirley-somali-daycares-san-diego-california-youtube"
  },
  {
    "title": "Borderlands 4 for Switch 2 is on ‘pause’",
    "slug": "borderlands-4-for-switch-2-is-on-pause",
    "content": "Development on the Nintendo Switch 2 version of Borderlands 4 is on \"pause,\" according to a statement from a Take-Two spokesperson given to Variety. \"We made the difficult decision to pause development on that SKU,\" Take-Two spokesperson Alan Lewis said in the statement published by Variety. \"Our focus continues to be delivering quality post-launch content [&#8230;]",
    "link": "https://www.theverge.com/games/873409/borderlands-4-nintendo-switch-2-development-pause"
  },
  {
    "title": "The four best Super Bowl TV deals we found",
    "slug": "the-four-best-super-bowl-tv-deals-we-found",
    "content": "The Super Bowl is not only one of the biggest sporting events in the world, it’s also one of the best times of year to find a deal on a big TV. For major events in particular, a large TV makes sense because it provides a more immersive experience and allows for groups of friends [&#8230;]",
    "link": "https://www.theverge.com/gadgets/873160/super-bowl-4k-oled-big-tv-deal-sale"
  },
  {
    "title": "Elon Musk is merging SpaceX and xAI to build data centers in space — or so he says",
    "slug": "elon-musk-is-merging-spacex-and-xai-to-build-data-centers-in-space--or-so-he-says",
    "content": "On Monday, Elon Musk announced that he was merging two of his companies, SpaceX and xAI, in a deal said to be worth $1.25 trillion. The reason, Musk said in an announcement, was that in order for AI to grow, it needed to go to space. AI relies on \"large terrestrial data centers\" that run [&#8230;]",
    "link": "https://www.theverge.com/transportation/873203/elon-musk-spacex-xai-merge-data-centers-space-tesla-ipo"
  },
  {
    "title": "Microsoft says it’s building an app store for AI content licensing",
    "slug": "microsoft-says-its-building-an-app-store-for-ai-content-licensing",
    "content": "Microsoft says it is working on the Publisher Content Marketplace (PCM), an AI licensing hub that shows usage terms set by publishers. That way, AI companies can easily shop the terms and set up deals to use online content for \"grounding\" their AI models, while the content owners get usage-based reporting to help set prices. [&#8230;]",
    "link": "https://www.theverge.com/news/873296/microsoft-publisher-content-marketplace-ai-licensing"
  },
  {
    "title": "Apple’s Xcode adds OpenAI and Anthropic’s coding agents",
    "slug": "apples-xcode-adds-openai-and-anthropics-coding-agents",
    "content": "Apple is building OpenAI and Anthropic's AI-powered coding agents directly into Xcode. New integrations in Xcode 26.3 will give developers the ability to call upon Anthropic's Claude Agent and OpenAI's Codex to write and edit code, update project settings, search documentation, and more. Xcode is the software developers can use to create and test apps [&#8230;]",
    "link": "https://www.theverge.com/news/873300/apple-xcode-openai-anthropic-ai-agentic-coding"
  },
  {
    "title": "I miss thinking hard",
    "slug": "i-miss-thinking-hard",
    "content": "<p>Article URL: <a href=\"https://www.jernesto.com/articles/thinking_hard\">https://www.jernesto.com/articles/thinking_hard</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46881264\">https://news.ycombinator.com/item?id=46881264</a></p>\n<p>Points: 70</p>\n<p># Comments: 45</p>",
    "link": "https://www.jernesto.com/articles/thinking_hard"
  },
  {
    "title": "Notepad++ supply chain attack breakdown",
    "slug": "notepad-supply-chain-attack-breakdown",
    "content": "<p>Article URL: <a href=\"https://securelist.com/notepad-supply-chain-attack/118708/\">https://securelist.com/notepad-supply-chain-attack/118708/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46878338\">https://news.ycombinator.com/item?id=46878338</a></p>\n<p>Points: 217</p>\n<p># Comments: 100</p>",
    "link": "https://securelist.com/notepad-supply-chain-attack/118708/"
  },
  {
    "title": "FlashAttention-T: Towards Tensorized Attention",
    "slug": "flashattentiont-towards-tensorized-attention",
    "content": "<p>Article URL: <a href=\"https://dl.acm.org/doi/10.1145/3774934.3786425\">https://dl.acm.org/doi/10.1145/3774934.3786425</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46877403\">https://news.ycombinator.com/item?id=46877403</a></p>\n<p>Points: 85</p>\n<p># Comments: 46</p>",
    "link": "https://dl.acm.org/doi/10.1145/3774934.3786425"
  },
  {
    "title": "Data centers in space makes no sense",
    "slug": "data-centers-in-space-makes-no-sense",
    "content": "<p>Article URL: <a href=\"https://civai.org/blog/space-data-centers\">https://civai.org/blog/space-data-centers</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46876105\">https://news.ycombinator.com/item?id=46876105</a></p>\n<p>Points: 369</p>\n<p># Comments: 493</p>",
    "link": "https://civai.org/blog/space-data-centers"
  },
  {
    "title": "China Moon Mission: Aiming for 2030 lunar landing",
    "slug": "china-moon-mission-aiming-for-2030-lunar-landing",
    "content": "<p>Article URL: <a href=\"https://spectrum.ieee.org/china-moon-mission-mengzhou-artemis\">https://spectrum.ieee.org/china-moon-mission-mengzhou-artemis</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46876047\">https://news.ycombinator.com/item?id=46876047</a></p>\n<p>Points: 121</p>\n<p># Comments: 130</p>",
    "link": "https://spectrum.ieee.org/china-moon-mission-mengzhou-artemis"
  },
  {
    "title": "AliSQL: Alibaba's open-source MySQL with vector and DuckDB engines",
    "slug": "alisql-alibabas-opensource-mysql-with-vector-and-duckdb-engines",
    "content": "<p>Article URL: <a href=\"https://github.com/alibaba/AliSQL\">https://github.com/alibaba/AliSQL</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46875228\">https://news.ycombinator.com/item?id=46875228</a></p>\n<p>Points: 165</p>\n<p># Comments: 22</p>",
    "link": "https://github.com/alibaba/AliSQL"
  },
  {
    "title": "Y Combinator will let founders receive funds in stablecoins",
    "slug": "y-combinator-will-let-founders-receive-funds-in-stablecoins",
    "content": "<p>Article URL: <a href=\"https://fortune.com/2026/02/03/famed-startup-incubator-y-combinator-to-let-founders-receive-funds-in-stablecoins/\">https://fortune.com/2026/02/03/famed-startup-incubator-y-combinator-to-let-founders-receive-funds-in-stablecoins/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46875033\">https://news.ycombinator.com/item?id=46875033</a></p>\n<p>Points: 101</p>\n<p># Comments: 132</p>",
    "link": "https://fortune.com/2026/02/03/famed-startup-incubator-y-combinator-to-let-founders-receive-funds-in-stablecoins/"
  },
  {
    "title": "Xcode 26.3 – Developers can leverage coding agents directly in Xcode",
    "slug": "xcode-263--developers-can-leverage-coding-agents-directly-in-xcode",
    "content": "<p>Article URL: <a href=\"https://www.apple.com/newsroom/2026/02/xcode-26-point-3-unlocks-the-power-of-agentic-coding/\">https://www.apple.com/newsroom/2026/02/xcode-26-point-3-unlocks-the-power-of-agentic-coding/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46874619\">https://news.ycombinator.com/item?id=46874619</a></p>\n<p>Points: 269</p>\n<p># Comments: 221</p>",
    "link": "https://www.apple.com/newsroom/2026/02/xcode-26-point-3-unlocks-the-power-of-agentic-coding/"
  },
  {
    "title": "Deno Sandbox",
    "slug": "deno-sandbox",
    "content": "<p>Article URL: <a href=\"https://deno.com/blog/introducing-deno-sandbox\">https://deno.com/blog/introducing-deno-sandbox</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46874097\">https://news.ycombinator.com/item?id=46874097</a></p>\n<p>Points: 363</p>\n<p># Comments: 126</p>",
    "link": "https://deno.com/blog/introducing-deno-sandbox"
  },
  {
    "title": "221 Cannon is Not For Sale",
    "slug": "221-cannon-is-not-for-sale",
    "content": "<p>Article URL: <a href=\"https://fredbenenson.com/blog/2026/02/03/221-cannon-is-not-for-sale/\">https://fredbenenson.com/blog/2026/02/03/221-cannon-is-not-for-sale/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46873574\">https://news.ycombinator.com/item?id=46873574</a></p>\n<p>Points: 208</p>\n<p># Comments: 164</p>",
    "link": "https://fredbenenson.com/blog/2026/02/03/221-cannon-is-not-for-sale/"
  },
  {
    "title": "1 kilobyte is precisely 1000 bytes?",
    "slug": "1-kilobyte-is-precisely-1000-bytes",
    "content": "<p>Article URL: <a href=\"https://waspdev.com/articles/2026-01-11/kilobyte-is-1000-bytes\">https://waspdev.com/articles/2026-01-11/kilobyte-is-1000-bytes</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46873539\">https://news.ycombinator.com/item?id=46873539</a></p>\n<p>Points: 82</p>\n<p># Comments: 258</p>",
    "link": "https://waspdev.com/articles/2026-01-11/kilobyte-is-1000-bytes"
  },
  {
    "title": "France dumps Zoom and Teams as Europe seeks digital autonomy from the US",
    "slug": "france-dumps-zoom-and-teams-as-europe-seeks-digital-autonomy-from-the-us",
    "content": "<p>Article URL: <a href=\"https://apnews.com/article/europe-digital-sovereignty-big-tech-9f5388b68a0648514cebc8d92f682060\">https://apnews.com/article/europe-digital-sovereignty-big-tech-9f5388b68a0648514cebc8d92f682060</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46873294\">https://news.ycombinator.com/item?id=46873294</a></p>\n<p>Points: 841</p>\n<p># Comments: 449</p>",
    "link": "https://apnews.com/article/europe-digital-sovereignty-big-tech-9f5388b68a0648514cebc8d92f682060"
  },
  {
    "title": "Prek: A better, faster, drop-in pre-commit replacement, engineered in Rust",
    "slug": "prek-a-better-faster-dropin-precommit-replacement-engineered-in-rust",
    "content": "<p>Article URL: <a href=\"https://github.com/j178/prek\">https://github.com/j178/prek</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46873138\">https://news.ycombinator.com/item?id=46873138</a></p>\n<p>Points: 206</p>\n<p># Comments: 100</p>",
    "link": "https://github.com/j178/prek"
  },
  {
    "title": "Launch HN: Modelence (YC S25) – App Builder with TypeScript / MongoDB Framework",
    "slug": "launch-hn-modelence-yc-s25--app-builder-with-typescript--mongodb-framework",
    "content": "<p>Hi all, Aram and Eduard here - co-founders of Modelence (<a href=\"https://modelence.com\">https://modelence.com</a>). After spending years on scaling our previous startup’s platform, we built an open-source full-stack TypeScript + MongoDB framework to stop solving the same auth / database / API / cron job implementations every time we created an app, and we didn’t like the idea of using multiple managed platforms for each of these to run our apps either.<p>(Here’s our prior Show HN post for reference: <a href=\"https://news.ycombinator.com/item?id=44902227\">https://news.ycombinator.com/item?id=44902227</a>)<p>At the same time, we were excited by the whole AI app builder boom and realized that the real challenge there is the platform rather than the tool itself. Now we’re making Modelence the first full-stack framework that’s built for coding agents and humans alike:<p>- TypeScript is already great for AI coding because it provides guardrails and catches many errors at build time, so agents can auto-correct<p>- MongoDB eliminates the schema management problem for agents, which is where they fail the most often otherwise (+ works great with TS/Node.js)<p>- Built-in auth, database, cron jobs and else that just works together out of the box means agents only focus on your product logic and don’t fail at trying to set these things up (+ less tokens spent on boilerplate).<p>You can now try the Modelence app builder (based on Claude Agent SDK) by just typing a prompt on our landing page ( <a href=\"https://modelence.com\">https://modelence.com</a> ) - watch a demo video here: <a href=\"https://youtu.be/BPsYvj_nGuE\" rel=\"nofollow\">https://youtu.be/BPsYvj_nGuE</a><p>Then you can check it out locally and continue working in your own IDE, while still using Modelence Cloud as your backend, with a dev cloud environment, and later deploy and run on Modelence Cloud with built-in observability around every operation running in your app.<p>We’re also going to add a built-in DevOps agent that lives in the same cloud, knows the framework end-to-end, and will use all this observability data to act on errors, alerts, and incidents - closing the loop, because running in production is much harder than just building.<p>We launched the app builder as a quick start for developers, to demonstrate the framework and Modelence Cloud without having to manually read docs and follow the steps to set up a new app. Our main focus is still the platform itself, since we believe the real challenge in AI coding is the framework and the platform rather than the builder tool itself.</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46872733\">https://news.ycombinator.com/item?id=46872733</a></p>\n<p>Points: 67</p>\n<p># Comments: 38</p>",
    "link": "https://news.ycombinator.com/item?id=46872733"
  },
  {
    "title": "Qwen3-Coder-Next",
    "slug": "qwen3codernext",
    "content": "<p>Article URL: <a href=\"https://qwen.ai/blog?id=qwen3-coder-next\">https://qwen.ai/blog?id=qwen3-coder-next</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46872706\">https://news.ycombinator.com/item?id=46872706</a></p>\n<p>Points: 601</p>\n<p># Comments: 374</p>",
    "link": "https://qwen.ai/blog?id=qwen3-coder-next"
  },
  {
    "title": "New York’s budget bill would require “blocking technology” on all 3D printers",
    "slug": "new-yorks-budget-bill-would-require-blocking-technology-on-all-3d-printers",
    "content": "<p>Article URL: <a href=\"https://blog.adafruit.com/2026/02/03/new-york-wants-to-ctrlaltdelete-your-3d-printer/\">https://blog.adafruit.com/2026/02/03/new-york-wants-to-ctrlaltdelete-your-3d-printer/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46872540\">https://news.ycombinator.com/item?id=46872540</a></p>\n<p>Points: 312</p>\n<p># Comments: 341</p>",
    "link": "https://blog.adafruit.com/2026/02/03/new-york-wants-to-ctrlaltdelete-your-3d-printer/"
  },
  {
    "title": "Agent Skills",
    "slug": "agent-skills",
    "content": "<p>Article URL: <a href=\"https://agentskills.io/home\">https://agentskills.io/home</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46871173\">https://news.ycombinator.com/item?id=46871173</a></p>\n<p>Points: 405</p>\n<p># Comments: 217</p>",
    "link": "https://agentskills.io/home"
  },
  {
    "title": "Bunny Database",
    "slug": "bunny-database",
    "content": "<p>Article URL: <a href=\"https://bunny.net/blog/meet-bunny-database-the-sql-service-that-just-works/\">https://bunny.net/blog/meet-bunny-database-the-sql-service-that-just-works/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46870015\">https://news.ycombinator.com/item?id=46870015</a></p>\n<p>Points: 262</p>\n<p># Comments: 108</p>",
    "link": "https://bunny.net/blog/meet-bunny-database-the-sql-service-that-just-works/"
  },
  {
    "title": "Emerge Career (YC S22) is hiring a product designer",
    "slug": "emerge-career-yc-s22-is-hiring-a-product-designer",
    "content": "<p>Article URL: <a href=\"https://www.ycombinator.com/companies/emerge-career/jobs/omqT34S-founding-product-designer\">https://www.ycombinator.com/companies/emerge-career/jobs/omqT34S-founding-product-designer</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46869901\">https://news.ycombinator.com/item?id=46869901</a></p>\n<p>Points: 0</p>\n<p># Comments: 0</p>",
    "link": "https://www.ycombinator.com/companies/emerge-career/jobs/omqT34S-founding-product-designer"
  },
  {
    "title": "X offices raided in France as UK opens fresh investigation into Grok",
    "slug": "x-offices-raided-in-france-as-uk-opens-fresh-investigation-into-grok",
    "content": "<p>Article URL: <a href=\"https://www.bbc.com/news/articles/ce3ex92557jo\">https://www.bbc.com/news/articles/ce3ex92557jo</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46868998\">https://news.ycombinator.com/item?id=46868998</a></p>\n<p>Points: 255</p>\n<p># Comments: 461</p>",
    "link": "https://www.bbc.com/news/articles/ce3ex92557jo"
  },
  {
    "title": "Ada (programming language)",
    "slug": "ada-programming-language",
    "content": "Ada is a structured, statically typed, imperative, and object-oriented high-level programming language, inspired by Pascal and other languages. It has built-in language support for design by contract (DbC), extremely strong typing, explicit concurrency, tasks, synchronous message passing, protected objects, and non-determinism. Ada improves code safety and maintainability by using the compiler to find errors in favor of runtime errors. Ada is an international technical standard, jointly defined by the International Organization for Standardization (ISO), and the International Electrotechnical Commission (IEC). As of May 2023, the standard, ISO/IEC 8652:2023, is called Ada 2022 informally.\nAda was originally designed by a team led by French computer scientist Jean Ichbiah of Honeywell under contract to the United States Department of Defense (DoD) from 1977 to 1983 to supersede over 450 programming languages then used by the DoD. Ada was named after Ada Lovelace (1815–1852), who has been credited as the first computer programmer.",
    "link": "https://en.wikipedia.org/wiki/Ada_(programming_language)"
  },
  {
    "title": "APL (programming language)",
    "slug": "apl-programming-language",
    "content": "APL (named after the book A Programming Language) is a programming language developed in the 1960s by Kenneth E. Iverson. Its central datatype is the multidimensional array. It uses a large range of special graphic symbols to represent most functions and operators, leading to very concise code. It has been an important influence on the development of concept modeling, spreadsheets, functional programming, and computer math packages. It has also inspired several other programming languages.",
    "link": "https://en.wikipedia.org/wiki/APL_(programming_language)"
  },
  {
    "title": "BASIC",
    "slug": "basic",
    "content": "BASIC (Beginner's All-purpose Symbolic Instruction Code) is a family of general-purpose, high-level programming languages designed for ease of use. The original version was created by John G. Kemeny and Thomas E. Kurtz at Dartmouth College in 1964. They wanted to enable students in non-scientific fields to use computers. At the time, nearly all computers required writing custom software, which only scientists and mathematicians tended to learn.\nIn addition to the programming language, Kemeny and Kurtz developed the Dartmouth Time-Sharing System (DTSS), which allowed multiple users to edit and run BASIC programs simultaneously on remote terminals. This general model became popular on minicomputer systems like the PDP-11 and Data General Nova in the late 1960s and early 1970s. Hewlett-Packard produced an entire computer line for this method of operation, introducing the HP2000 series in the late 1960s and continuing sales into the 1980s. Many early video games trace their history to one of these versions of BASIC.\nThe emergence of microcomputers in the mid-1970s led to the development of multiple BASIC dialects, including Microsoft BASIC in 1975. Due to the tiny main memory available on these machines, often 4 KB, a variety of Tiny BASIC dialects were also created. BASIC was available for almost any system of the era and became the de facto programming language for home computer systems that emerged in the late 1970s. These PCs almost always had a BASIC interpreter installed by default, often in the machine's firmware or sometimes on a ROM cartridge.\nBASIC declined in popularity in the 1990s, as more powerful microcomputers came to market and programming languages with advanced features (such as Pascal and C) became tenable on such computers. By then, most nontechnical personal computer users relied on pre-written applications rather than writing their own programs. In 1991, Microsoft released Visual Basic, combining an updated version of BASIC with a visual forms builder. This reignited use of the language and \"VB\" remains a major programming language in the form of VB.NET, while a hobbyist scene for BASIC more broadly continues to exist.",
    "link": "https://en.wikipedia.org/wiki/BASIC"
  },
  {
    "title": "Brainfuck",
    "slug": "brainfuck",
    "content": "Brainfuck is an esoteric programming language created in 1993 by Swiss student Urban Müller. Designed to be extremely minimalistic, the language consists of only eight simple commands, a data pointer, and an instruction pointer.\nBrainfuck is an example of a so-called Turing tarpit: it can be used to write any program, but it is not practical to do so because it provides so little abstraction that the programs get very long or complicated. While Brainfuck is fully Turing-complete, it is not intended for practical use but to challenge and amuse programmers. Brainfuck requires one to break down commands into small and simple instructions.\nThe language takes its name from the slang term brainfuck, which refers to things so complicated or unusual that they exceed the limits of one's understanding, as it was not meant or made for designing actual software but to challenge the boundaries of computer programming.\nBecause the language's name contains profanity, many substitute names are used, such as brainf*ck, brainfsck, branflakes, brainoof, brainfrick, BrainF, and BF.",
    "link": "https://en.wikipedia.org/wiki/Brainfuck"
  },
  {
    "title": "B (programming language)",
    "slug": "b-programming-language",
    "content": "B is a programming language developed at Bell Labs circa 1969 by Ken Thompson and Dennis Ritchie.\nB was designed for recursive, non-numeric, machine-independent applications, such as system and language software. It was a typeless language, with the only data type being the underlying machine's natural memory word format, whatever that might be. Depending on the context, the word was treated either as an integer or a memory address.\nAs machines with ASCII processing became common, notably the DEC PDP-11 that arrived at Bell Labs, support for character data stuffed in memory words became important. The typeless nature of the language was seen as a disadvantage, which led Thompson and Ritchie to develop an expanded version of the language supporting new internal and user-defined types, which became the ubiquitous C programming language.",
    "link": "https://en.wikipedia.org/wiki/B_(programming_language)"
  },
  {
    "title": "Software",
    "slug": "software",
    "content": "Software consists of computer programs that instruct the execution of a computer. Software also includes design documents and specifications.\nThe history of software is closely tied to the development of digital computers in the mid-20th century. Early programs were written in the machine language specific to the hardware. The introduction of high-level programming languages in 1958 allowed for more human-readable instructions, making software development easier and more portable across different computer architectures. Software in a programming language is run through a compiler or interpreter to execute on the architecture's hardware. Over time, software has become complex, owing to developments in networking, operating systems, and databases.\nSoftware can generally be categorized into two main types:\n\noperating systems, which manage hardware resources and provide services for applications\napplication software, which performs specific tasks for users\nThe rise of cloud computing has introduced the new software delivery model Software as a Service (SaaS). In SaaS, applications are hosted by a provider and accessed over the Internet.\nThe process of developing software involves several stages. The stages include software design, programming, testing, release, and maintenance. Software quality assurance and security are critical aspects of software development, as bugs and security vulnerabilities can lead to system failures and security breaches. Additionally, legal issues such as software licenses and intellectual property rights play a significant role in the distribution of software products.",
    "link": "https://en.wikipedia.org/wiki/Software"
  },
  {
    "title": "Computer program",
    "slug": "computer-program",
    "content": "A computer program is a sequence or set of instructions in a programming language for a computer to execute. It is one component of software, which also includes documentation and other intangible components.\nA computer program in its human-readable form is called source code. Source code needs another computer program to execute because computers can only execute their native machine instructions. Therefore, source code may be translated to machine instructions using a compiler written for the language. (Assembly language programs are translated using an assembler.) The resulting file is called an executable. Alternatively, source code may execute within an interpreter written for the language.\nIf the executable is requested for execution, then the operating system loads it into memory and starts a process. The central processing unit will soon switch to this process so it can fetch, decode, and then execute each machine instruction.\nIf the source code is requested for execution, then the operating system loads the corresponding interpreter into memory and starts a process. The interpreter then loads the source code into memory to translate and execute each statement. Running the source code is slower than running an executable. Moreover, the interpreter must be installed on the computer.",
    "link": "https://en.wikipedia.org/wiki/Computer_program"
  },
  {
    "title": "C (programming language)",
    "slug": "c-programming-language",
    "content": "C is a general-purpose programming language created in the 1970s by Dennis Ritchie. By design, C gives the programmer relatively direct access to the features of the typical CPU architecture, customized for the target instruction set. It has been and continues to be used to implement operating systems (especially kernels), device drivers, and protocol stacks, but its use in application software has been decreasing. C is used on computers that range from the largest supercomputers to the smallest microcontrollers and embedded systems.\nA successor to the programming language B, C was originally developed at Bell Labs by Ritchie between 1972 and 1973 to construct utilities running on Unix. It was applied to re-implementing the kernel of the Unix operating system. During the 1980s, C gradually gained popularity. It has become one of the most widely used programming languages, with C compilers available for practically all modern computer architectures and operating systems. The book The C Programming Language, co-authored by the original language designer, served for many years as the de facto standard for the language. C has been standardized since 1989 by the American National Standards Institute (ANSI) and, subsequently, jointly by the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC).\nC is an imperative procedural language, supporting structured programming, lexical variable scope, and recursion, with a static type system. It was designed to be compiled to provide low-level access to memory and language constructs that map efficiently to machine instructions, all with minimal runtime support. Despite its low-level capabilities, the language was designed to encourage cross-platform programming. A standards-compliant C program written with portability in mind can be compiled for a wide variety of computer platforms and operating systems with few changes to its source code.\nAlthough neither C nor its standard library provide some popular features found in other languages, it is flexible enough to support them. For example, object orientation and garbage collection are provided by external libraries GLib Object System and Boehm garbage collector, respectively.\nSince 2000, C has typically ranked as the most or second-most popular language in the TIOBE index.",
    "link": "https://en.wikipedia.org/wiki/C_(programming_language)"
  },
  {
    "title": "Programming language",
    "slug": "programming-language",
    "content": "A programming language is an engineered language for expressing computer programs.\nProgramming languages typically allow software to be written in a human readable manner.\nExecution of a program requires an implementation. There are two main approaches for implementing a programming language – compilation, where programs are compiled ahead-of-time to machine code, and interpretation, where programs are directly executed. In addition to these two extremes, some implementations use hybrid approaches such as just-in-time compilation and bytecode interpreters.\nThe design of programming languages has been strongly influenced by computer architecture, with most imperative languages designed around the ubiquitous von Neumann architecture. While early programming languages were closely tied to the hardware, modern languages often hide hardware details via abstraction in an effort to enable better software with less effort.",
    "link": "https://en.wikipedia.org/wiki/Programming_language"
  },
  {
    "title": "AppleScript",
    "slug": "applescript",
    "content": "AppleScript is a scripting language created by Apple Inc. that facilitates automated control of Mac applications. First introduced in System 7, it is currently included in macOS in a package of automation tools. The term AppleScript may refer to the scripting language, to a script written in the language, or to the macOS Open Scripting Architecture that underlies the language.\nAppleScript is primarily a mechanism for driving Apple events – an inter-application communication (IAC) technology that exchanges data between and controls applications. Additionally, AppleScript supports basic calculations and text processing, and is extensible via scripting additions that add functions to the language. \nAppleScript is tightly bound to the Mac environment, similar to how Windows Script Host is bound to the Windows environment. In other words, AppleScript is not a general purpose scripting language like Python. One way that AppleScript is bound to the unique aspects of its environment is that it relies on applications to publish dictionaries of addressable objects and operations.\nAs is typical of a command language, AppleScript is not designed to directly perform intensive processing. For example, a script cannot efficiently perform intensive math operations or complicated text processing. However, AppleScript can be used in combination with other tools and technologies which allows it to leverage more efficient programming contexts.\nThe language has aspects of structured, procedural, object-oriented and natural language programming, but does not strictly conform to any of these paradigms.",
    "link": "https://en.wikipedia.org/wiki/AppleScript"
  },
  {
    "title": "AspectJ",
    "slug": "aspectj",
    "content": "AspectJ is an aspect-oriented programming (AOP) extension for the Java programming language, created at PARC. It is available in Eclipse Foundation open-source projects, both stand-alone and integrated into Eclipse. AspectJ has become a widely used de facto standard for AOP by emphasizing simplicity and usability for end users. It uses Java-like syntax, and included IDE integrations for displaying crosscutting structure since its initial public release in 2001.",
    "link": "https://en.wikipedia.org/wiki/AspectJ"
  },
  {
    "title": "ABAP",
    "slug": "abap",
    "content": "ABAP (Advanced Business Application Programming, originally Allgemeiner Berichts-Aufbereitungs-Prozessor, German for \"general report preparation processor\") is a high-level programming language created by the German software company SAP SE. It is currently positioned, alongside Java, as the language for programming the SAP NetWeaver Application Server, which is part of the SAP NetWeaver platform for building business applications.",
    "link": "https://en.wikipedia.org/wiki/ABAP"
  },
  {
    "title": "The C Programming Language",
    "slug": "the-c-programming-language",
    "content": "The C Programming Language (sometimes termed K&R, after its authors' initials) is a computer programming book written by Brian Kernighan and Dennis Ritchie, the latter of whom originally designed and implemented the C programming language, as well as co-designed the Unix operating system with which development of the language was closely intertwined.  The book was central to the development and popularization of C and is still widely read and used.  Because the book was co-authored by the original language designer, and because the first edition of the book served for many years as the de facto standard for the language, the book was regarded by many to be the authoritative reference on C.",
    "link": "https://en.wikipedia.org/wiki/The_C_Programming_Language"
  },
  {
    "title": "BLISS",
    "slug": "bliss",
    "content": "BLISS is a system programming language developed at Carnegie Mellon University (CMU) by W. A. Wulf, D. B. Russell, and A. N. Habermann around 1970. It was perhaps the best known system language until C debuted a few years later. Since then, C became popular and common, and BLISS faded into obscurity. When C was in its infancy, a few projects within Bell Labs debated the merits of BLISS vs. C.\nBLISS is a typeless block-structured programming language based on expressions rather than statements, and includes constructs for exception handling, coroutines, and macros. It does not include a goto statement.\nThe name is variously said to be short for Basic Language for Implementation of System Software or System Software Implementation Language, Backwards. However, in his 2015 oral history for the Babbage Institute's Computer Security History Project, Wulf claimed that the acronym was originally based on the name \"Bill's Language for Implementing System Software.\"\nThe original Carnegie Mellon compiler was notable for its extensive use of optimizations, and formed the basis of the classic book The Design of an Optimizing Compiler.\nDigital Equipment Corporation (DEC) developed and maintained BLISS compilers for the PDP-10, PDP-11, VAX, DEC PRISM, MIPS, DEC Alpha, and Intel IA-32, The language did not become popular among customers and few had the compiler, but DEC used it heavily in-house into the 1980s; most of the utility programs for the OpenVMS operating system were written in BLISS-32. The DEC BLISS compiler has been ported to the IA-64 and x86-64 architectures as part of the ports of OpenVMS to these platforms. The x86-64 BLISS compiler uses LLVM as its backend code generator, replacing the proprietary GEM backend used for Alpha and IA-64.",
    "link": "https://en.wikipedia.org/wiki/BLISS"
  },
  {
    "title": "Apache Groovy",
    "slug": "apache-groovy",
    "content": "Apache Groovy is a Java-syntax-compatible object-oriented programming language for the Java platform. It is both a static and dynamic language with features similar to those of Python, Ruby, and Smalltalk. It can be used as both a programming language and a scripting language for the Java Platform, is compiled to Java virtual machine (JVM) bytecode, and interoperates seamlessly with other Java code and libraries. Groovy uses a curly-bracket syntax similar to Java's. Groovy supports closures, multiline strings, and expressions embedded in strings. Much of Groovy's power lies in its AST transformations, triggered through annotations.\nGroovy 1.0 was released on January 2, 2007, and Groovy 2.0 in July, 2012. Since version 2, Groovy can be compiled statically, offering type inference and performance near that of Java. Groovy 2.4 was the last major release under Pivotal Software's sponsorship which ended in March 2015. Groovy has since changed its governance structure to a Project Management Committee in the Apache Software Foundation.",
    "link": "https://en.wikipedia.org/wiki/Apache_Groovy"
  },
  {
    "title": "ALGOL 68",
    "slug": "algol-68",
    "content": "ALGOL 68 (short for Algorithmic Language 1968) is an imperative programming language member of the ALGOL family that was conceived as a successor to the ALGOL 60 language, designed with the goal of a much wider scope of application and more rigorously defined syntax and semantics.\nThe complexity of the language's definition, which runs to several hundred pages filled with non-standard terminology, made compiler implementation difficult and it was said it had \"no implementations and no users\". This was only partly true; ALGOL 68 did find use in several niche markets, notably in the United Kingdom where it was popular on International Computers Limited (ICL) machines, and in teaching roles. Outside these fields, use was relatively limited.\nNevertheless, the contributions of ALGOL 68 to the field of computer science have been deep, wide-ranging and enduring, although many of these contributions were only publicly identified when they had reappeared in subsequently developed programming languages. Many languages were developed specifically as a response to the perceived complexity of the language, the most notable being Pascal, or were reimplementations for specific roles, like Ada.\nMany languages of the 1970s trace their design specifically to ALGOL 68, selecting some features while abandoning others that were considered too complex or out-of-scope for given roles. Most modern languages trace at least some of their syntax to either C or Pascal, and thus directly or indirectly to ALGOL 68.",
    "link": "https://en.wikipedia.org/wiki/ALGOL_68"
  },
  {
    "title": "A+ (programming language)",
    "slug": "a-programming-language",
    "content": "A+ is a high-level, interactive, interpreted array programming language designed for numerically intensive applications, especially those found in financial applications.",
    "link": "https://en.wikipedia.org/wiki/A%2B_(programming_language)"
  },
  {
    "title": "Skeleton (computer programming)",
    "slug": "skeleton-computer-programming",
    "content": "Skeleton programming is a style of computer programming based on simple high-level program structures and so called dummy code. Program skeletons resemble pseudocode, but allow parsing, compilation and testing of the code.  Dummy code is inserted in a program skeleton to simulate processing and avoid compilation error messages. It may involve empty function declarations, or functions that return a correct result only for a simple test case where the expected response of the code is known.\nSkeleton programming facilitates a top-down design approach, where a partially functional system with complete high-level structures is designed and coded, and this system is then progressively expanded to fulfill the requirements of the project.  Program skeletons are also sometimes used for high-level descriptions of algorithms.  A program skeleton may also be utilized as a template that reflects syntax and structures commonly used in a wide class of problems.\nSkeleton programs are utilized in the template method design pattern used in object-oriented programming. In object-oriented programming, dummy code corresponds to an abstract method, a method stub or a mock object. In the Java remote method invocation (Java RMI) nomenclature, a stub communicates on the client-side with a skeleton on the server-side.\nA class skeleton is an outline of a class that is used in software engineering. It contains a description of the class's roles, and describes the purposes of the variables and methods, but does not implement them. The class is later implemented from the skeleton. The skeleton can also be known as either an interface or an abstract class, with languages that follow a polymorphic paradigm.",
    "link": "https://en.wikipedia.org/wiki/Skeleton_(computer_programming)"
  },
  {
    "title": "Boo (programming language)",
    "slug": "boo-programming-language",
    "content": "Boo is an object-oriented, statically typed, general-purpose programming language that seeks to make use of the Common Language Infrastructure's support for Unicode, internationalization, and web applications, while using a Python-inspired syntax and a special focus on language and compiler extensibility. Some features of note include type inference, generators, multimethods, optional duck typing, macros, true closures, currying, and first-class functions.\nBoo was one of the three scripting languages for the Unity game engine (Unity Technologies employed De Oliveira, its designer), until official support was dropped in 2014 due to the small userbase. The Boo Compiler was removed from the engine in 2017. Boo has since been abandoned by De Oliveira, with development being taken over by Mason Wheeler.\nBoo is free software released under the BSD 3-Clause license. It is compatible with the Microsoft .NET and Mono frameworks.",
    "link": "https://en.wikipedia.org/wiki/Boo_(programming_language)"
  },
  {
    "title": "Entry point",
    "slug": "entry-point",
    "content": "In computer programming, an entry point is the place in a program where the execution of a program begins, and where the program has access to command line arguments.\nTo start a program's execution, the loader or operating system passes control to its entry point. (During booting, the operating system itself is the program). This marks the transition from load time (and dynamic link time, if present) to run time.\nFor some operating systems and programming languages, the entry point is in a runtime library, a set of support functions for the language. The library code initializes the program and then passes control to the program proper. In other cases, the program may initialize the runtime library itself. \nIn simple systems, execution begins at the first statement, which is common in interpreted languages, simple executable formats, and boot loaders. In other cases, the entry point is at some other known memory address which can be an absolute address or relative address (offset).\nAlternatively, execution of a program can begin at a named point, either with a conventional name defined by the programming language or operating system or at a caller-specified name. In many C-family languages, this is a function called main; as a result, the entry point is often known as the main function.\nIn JVM languages, such as Java, the entry point is a static method called main; in CLI languages such as C# the entry point is a static method named Main.",
    "link": "https://en.wikipedia.org/wiki/Entry_point"
  },
  {
    "title": "Erlang (programming language)",
    "slug": "erlang-programming-language",
    "content": "Erlang ( UR-lang) is a general-purpose, concurrent, functional high-level programming language, and a garbage-collected runtime system. The term Erlang is used interchangeably with Erlang/OTP, or Open Telecom Platform (OTP), which consists of the Erlang runtime system, several ready-to-use components (OTP) mainly written in Erlang, and a set of design principles for Erlang programs.\nThe Erlang runtime system is designed for systems with these traits:\n\nDistributed\nFault-tolerant\nSoft real-time\nHighly available, non-stop applications\nHot swapping, where code can be changed without stopping a system.\nThe Erlang programming language has data, pattern matching, and functional programming. The sequential subset of the Erlang language supports eager evaluation, single assignment, and dynamic typing.\nA normal Erlang application is built out of hundreds of small Erlang processes.\nIt was originally proprietary software within Ericsson, developed by Joe Armstrong, Robert Virding, and Mike Williams in 1986, but was released as free and open-source software in 1998. Erlang/OTP is supported and maintained by the Open Telecom Platform (OTP) product unit at Ericsson.",
    "link": "https://en.wikipedia.org/wiki/Erlang_(programming_language)"
  },
  {
    "title": "JavaScript",
    "slug": "javascript",
    "content": "JavaScript (JS) is a programming language and core technology of the Web, alongside HTML and CSS. It was created by Brendan Eich in 1995. As of 2025, the overwhelming majority of websites (98.9%) uses JavaScript for client side webpage behavior.\nWeb browsers have a dedicated JavaScript engine that executes the client code. These engines are also utilized in some servers and a variety of apps. The most popular runtime system for non-browser usage is Node.js.\nJavaScript is a high-level, often just-in-time–compiled language that conforms to the ECMAScript standard. It has dynamic typing, prototype-based object-orientation, and first-class functions. It is multi-paradigm, supporting event-driven, functional, and imperative programming styles. It has application programming interfaces (APIs) for working with text, dates, regular expressions, standard data structures, and the Document Object Model (DOM).\nThe ECMAScript standard does not include any input/output (I/O), such as networking, storage, or graphics facilities. In practice, the web browser or other runtime system provides JavaScript APIs for I/O.\nAlthough Java and JavaScript are similar in name and syntax, the two languages are distinct and differ greatly in design.",
    "link": "https://en.wikipedia.org/wiki/JavaScript"
  },
  {
    "title": "Forth (programming language)",
    "slug": "forth-programming-language",
    "content": "Forth is a stack-oriented programming language and interactive integrated development environment designed by Charles H. \"Chuck\" Moore and first used by other programmers in 1970. Although not an acronym, the language's name in its early years was often spelled in all capital letters as FORTH. The FORTH-79 and FORTH-83 implementations, which were not written by Moore, became de facto standards, and an official technical standard of the language was published in 1994 as ANS Forth. A wide range of Forth derivatives existed before and after ANS Forth. The free and open-source software Gforth implementation is actively maintained, as are several commercially supported systems.\nForth typically combines a compiler with an integrated command shell, where the user interacts via subroutines called words.\nWords can be defined, tested, redefined, and debugged without recompiling or restarting the whole program. All syntactic elements, including variables, operators, and control flow, are defined as words. A stack is used to pass parameters between words, leading to a Reverse Polish notation style.\nFor much of Forth's existence, the standard technique was to compile to threaded code, which can be interpreted faster than bytecode. One of the early benefits of Forth was size: an entire development environment—including compiler, editor, and user programs—could fit in memory on an 8-bit or similarly limited system. No longer constrained by space, there are modern implementations that generate optimized machine code like other language compilers.\nThe relative simplicity of creating a basic Forth system has led to many personal and proprietary variants, such as the custom Forth used to implement the bestselling 1986 video game Starflight from Electronic Arts. Forth is used in the Open Firmware boot loader, in spaceflight applications such as the Philae spacecraft, and in other embedded systems which involve interaction with hardware. \nBeginning in the early 1980s, Moore developed a series of microprocessors for executing compiled Forth-like code directly and experimented with smaller languages based on Forth concepts, including cmForth and colorForth. Most of these languages were created to support Moore's own projects, such as chip design.",
    "link": "https://en.wikipedia.org/wiki/Forth_(programming_language)"
  },
  {
    "title": "Java (programming language)",
    "slug": "java-programming-language",
    "content": "Java is a high-level, general-purpose, memory-safe, object-oriented programming language. It is intended to let programmers write once, run anywhere (WORA), meaning that compiled Java code can run on all platforms that support Java without the need to recompile. Java applications are typically compiled to bytecode that can run on any Java virtual machine (JVM) regardless of the underlying computer architecture. The syntax of Java is similar to C and C++, but has fewer low-level facilities than either of them. The Java runtime provides dynamic capabilities (such as reflection and runtime code modification) that are typically not available in traditional compiled languages.\nJava gained popularity shortly after its release, and has been a popular programming language since then. Java was the third most popular programming language in 2022 according to GitHub. Although still widely popular, there has been a gradual decline in use of Java in recent years with other languages using JVM gaining popularity.\nJava was designed by James Gosling at Sun Microsystems. It was released in May 1995 as a core component of Sun's Java platform. The original and reference implementation Java compilers, virtual machines, and class libraries were released by Sun under proprietary licenses. As of May 2007, in compliance with the specifications of the Java Community Process, Sun had relicensed most of its Java technologies under the GPL-2.0-only license. Oracle, which bought Sun in 2010, offers its own HotSpot Java Virtual Machine. However, the official reference implementation is the OpenJDK JVM, which is open-source software used by most developers and is the default JVM for almost all Linux distributions.\nJava 25 is the version current as of September 2025. Java 8, 11, 17, 21, and 25 are long-term support versions still under maintenance.",
    "link": "https://en.wikipedia.org/wiki/Java_(programming_language)"
  },
  {
    "title": "FX-87",
    "slug": "fx87",
    "content": "FX-87 is a polymorphic typed functional language based on a system for static program analysis in which every expression has two static properties: a type and an effect. In a study done by MIT, FX-87 yields similar performance results as functional languages on programs that do not contain side effects (Fibonacci, Factorial). FX-87 did yield a great performance increase when matching DNA sequences.\nKFX is the kernel language of FX-87. It was described in 'Polymorphic Effect Systems', J.M. Lucassen et al., Proceedings of the 15th Annual ACM Conference POPL, ACM 1988, pp. 47–57.",
    "link": "https://en.wikipedia.org/wiki/FX-87"
  },
  {
    "title": "J (programming language)",
    "slug": "j-programming-language",
    "content": "The J programming language, developed in the early 1990s by Kenneth E. Iverson and Roger Hui, is an array programming language based primarily on APL (also by Iverson).\nTo avoid repeating the APL special-character problem, J uses only the basic ASCII character set, resorting to the use of the dot and colon as inflections to form short words similar to digraphs. Most such primary (or primitive) J words serve as mathematical symbols, with the dot or colon extending the meaning of the basic characters available.  Also, many characters which in other languages often must be paired (such as [] {} \"\" `` or <>) are treated by J as stand-alone words or, when inflected, as single-character roots of multi-character words.\nJ is a very terse array programming language, and is most suited to mathematical and statistical programming, especially when performing operations on matrices. It has also been used in extreme programming and network performance analysis.\nLike John Backus's languages FP and FL, J supports function-level programming via its tacit programming features.\nUnlike most languages that support object-oriented programming, J's flexible hierarchical namespace scheme (where every name exists in a specific locale) can be effectively used as a framework for both class-based and prototype-based object-oriented programming.\nSince March 2011, J is free and open-source software under the GNU General Public License version 3 (GPLv3). One may also purchase source under a negotiated license.",
    "link": "https://en.wikipedia.org/wiki/J_(programming_language)"
  },
  {
    "title": "COWSEL",
    "slug": "cowsel",
    "content": "COWSEL (COntrolled Working SpacE Language) is a programming language designed between 1964 and 1966 by Robin Popplestone. It was based on an reverse Polish notation (RPN) form of the language Lisp, combined with some ideas from Combined Programming Language (CPL).\nCOWSEL was initially implemented on a Ferranti Pegasus computer at the University of Leeds and on a Stantec Zebra at the Bradford Institute of Technology. Later, Rod Burstall implemented it on an Elliot 4120 at the University of Edinburgh.\nCOWSEL was renamed POP-1 in 1966, during summer, and development continued under that name from then on.",
    "link": "https://en.wikipedia.org/wiki/COWSEL"
  },
  {
    "title": "COMAL",
    "slug": "comal",
    "content": "COMAL (Common Algorithmic Language) is a computer programming language developed in Denmark by Børge R. Christensen and Benedict Løfstedt and originally released in 1975. It was based on the BASIC programming language, adding multi-line statements and well-defined subroutines among other additions.\nCOMAL was originally written for minicomputers, but was small enough to run on early microcomputers as well. It is one of the few structured programming languages that were available for and comfortably usable on 8-bit home computers. \n\"COMAL Kernel Syntax & Semantics\" contains the formal definition of the language. Further extensions are common to many implementations.",
    "link": "https://en.wikipedia.org/wiki/COMAL"
  },
  {
    "title": "D (programming language)",
    "slug": "d-programming-language",
    "content": "D, also known as dlang, is a multi-paradigm system programming language created by Walter Bright at Digital Mars and released in 2001. Andrei Alexandrescu joined the design and development effort in 2007. Though it originated as a re-engineering of C++, D is now a very different language. As it has developed, it has drawn inspiration from other high-level programming languages. Notably, it has been influenced by Java, Python, Ruby, C#, and Eiffel.\nThe D language reference describes it as follows:\n\nD is a general-purpose systems programming language with a C-like syntax that compiles to native code. It is statically typed and supports both automatic (garbage collected) and manual memory management. D programs are structured as modules that can be compiled separately and linked with external libraries to create native libraries or executables.",
    "link": "https://en.wikipedia.org/wiki/D_(programming_language)"
  },
  {
    "title": "Clipper (programming language)",
    "slug": "clipper-programming-language",
    "content": "Clipper is an xBase compiler that implements a variant of the xBase computer programming language. It is used to create or extend software programs that usually ran on DOS originally. Although it is a powerful general-purpose programming language, it was used mainly to create database business programs.\nOne major dBase feature not implemented in Clipper is the dot-prompt (. prompt) interactive command set, which was an important part of the original dBase implementation.\nClipper, from Nantucket Corp and later Computer Associates, started out as a native code compiler for dBase III databases, and later evolved.",
    "link": "https://en.wikipedia.org/wiki/Clipper_(programming_language)"
  },
  {
    "title": "Io (programming language)",
    "slug": "io-programming-language",
    "content": "Io is a pure object-oriented programming language inspired by Smalltalk, Self, Lua, Lisp, Act1, and NewtonScript. Io has a prototype-based object model similar to those in Self and NewtonScript, eliminating the distinction between instance and class. Like Smalltalk, everything is an object and it uses dynamic typing. Like Lisp, programs are just data trees. Io uses actors for concurrency.\nRemarkable features of Io are its minimal size and openness to using external code resources. Io is executed by a small, portable virtual machine.",
    "link": "https://en.wikipedia.org/wiki/Io_(programming_language)"
  },
  {
    "title": "CorbaScript",
    "slug": "corbascript",
    "content": "CorbaScript is an object-oriented scripting language designed to support interaction with Common Object Request Broker Architecture (CORBA) objects. It was developed to provide a flexible scripting environment for both client- and server-side CORBA application development, leveraging dynamic invocation and interface reflection capabilities.\nCorbaScript is a dynamic, interpreted language whose syntax resembles that of C++ and Java. However, it integrates several design elements from dynamic languages such as Python and Smalltalk. Like those languages, CorbaScript treats all values as objects and supports dynamic type checking at runtime. Source code is translated into pseudocode executed by a dedicated Virtual Object-Oriented Machine that includes a simple reference-counting garbage collector.",
    "link": "https://en.wikipedia.org/wiki/CorbaScript"
  },
  {
    "title": "DIBOL",
    "slug": "dibol",
    "content": "DIBOL or Digital's Business Oriented Language is a general-purpose, procedural, imperative programming language that was designed for use in Management Information Systems (MIS) software development. It was developed from 1970 to 1993.\nDIBOL has a syntax similar to FORTRAN and BASIC, along with BCD arithmetic. It shares the COBOL program structure of separate data and procedure divisions. Unlike Fortran's numeric labels (for GOTO), DIBOL's were alphanumeric; the language supported a counterpart to computed goto.",
    "link": "https://en.wikipedia.org/wiki/DIBOL"
  },
  {
    "title": "DataFlex",
    "slug": "dataflex",
    "content": "DataFlex is an object-oriented high-level programming language and a fourth generation visual tool for developing Windows, web and mobile software applications on one framework-based platform. It was introduced and developed by Data Access Corporation beginning in 1982.",
    "link": "https://en.wikipedia.org/wiki/DataFlex"
  },
  {
    "title": "Factor (programming language)",
    "slug": "factor-programming-language",
    "content": "Factor is a stack-oriented programming language created by Slava Pestov. Factor is dynamically typed and has automatic memory management, as well as powerful metaprogramming features. The language has a single implementation featuring a self-hosted optimizing compiler and an interactive development environment. The Factor distribution includes a large standard library.",
    "link": "https://en.wikipedia.org/wiki/Factor_(programming_language)"
  },
  {
    "title": "General-purpose programming language",
    "slug": "generalpurpose-programming-language",
    "content": "In computer software, a general-purpose programming language (GPL) is a programming language for building software in a wide variety of application domains. Conversely, a domain-specific programming language (DSL) is used within a specific area. For example, Python is a GPL, while SQL is a DSL for querying relational databases.",
    "link": "https://en.wikipedia.org/wiki/General-purpose_programming_language"
  },
  {
    "title": "ELAN (programming language)",
    "slug": "elan-programming-language",
    "content": "ELAN is an interpreted educational programming language for learning and teaching systematic programming. (Note: In May 2023 design commenced on a new programming language named 'Elan' also designed for teaching and learning programming in schools, but it has no historical connection to the 'ELAN' language described here.)\nIt was developed in 1974 by C.H.A. Koster and a group at Technische Universität Berlin as an alternative to BASIC in teaching, and approved for use in secondary schools in Germany by the \"Arbeitskreis Schulsprache\". It was in use until the late 1980s in a number of schools in Germany, Belgium, the Netherlands, and Hungary for informatics teaching in secondary education, and used at the Radboud University Nijmegen in the Netherlands for teaching systematic programming to students from various disciplines and in teacher courses.\nThe language design focuses strongly on structured programming, and has a special construction for stepwise refinement, allowing students to focus on top-down design, and bottom-up coding.\nThe microkernel operating system Eumel began as a runtime system (environment) for ELAN.",
    "link": "https://en.wikipedia.org/wiki/ELAN_(programming_language)"
  },
  {
    "title": "F (programming language)",
    "slug": "f-programming-language",
    "content": "F is a modular, compiled, numeric programming language, designed for scientific programming and scientific computation. F was developed as a modern Fortran, thus making it a subset of Fortran 95. It combines both numerical and data abstraction features from these languages. F is also backwards compatible with Fortran 77, allowing calls to Fortran 77 programs. F was implemented on top of compilers from NAG, Fujitsu, Salford Software and Absoft. It was later included in the g95 compiler.",
    "link": "https://en.wikipedia.org/wiki/F_(programming_language)"
  },
  {
    "title": "E (programming language)",
    "slug": "e-programming-language",
    "content": "E is an object-oriented programming language for secure distributed computing, created by Mark S. Miller, Dan Bornstein, Douglas Crockford, Chip Morningstar and others at Electric Communities in 1997. E is mainly descended from the concurrent language Joule and from Original-E, a set of extensions to Java for secure distributed programming. E combines message-based computation with Java-like syntax. A concurrency model based on event loops and promises ensures that deadlock can never occur.",
    "link": "https://en.wikipedia.org/wiki/E_(programming_language)"
  },
  {
    "title": "FreeBASIC",
    "slug": "freebasic",
    "content": "FreeBASIC is a free and open source multiplatform compiler and programming language based on BASIC licensed under the GNU GPL  for Microsoft Windows, protected-mode MS-DOS (DOS extender), Linux, FreeBSD and Xbox.  The Xbox version is no longer maintained.\nAccording to its official website, FreeBASIC provides syntax compatibility with programs originally written in Microsoft QuickBASIC (QB).  Unlike QuickBASIC, however, FreeBASIC is a command line only compiler, unless users manually install an external integrated development environment (IDE) of their choice.",
    "link": "https://en.wikipedia.org/wiki/FreeBASIC"
  },
  {
    "title": "KOMPILER",
    "slug": "kompiler",
    "content": "In computing, the KOMPILER was one of the first language compilation and runtime systems for International Business Machines' IBM 701, the fastest commercial U.S. computer available in 1955.\nInformation on KOMPILER is listed on page 16 of Volume 2, Number 5 (May 1959) of the Communications of the ACM. Known versions are KOMPILER 2 for IBM 701 and KOMPILER 3 for the IBM 704. KOMPILER was eventually replaced by a Fortran compiler on the IBM 704.",
    "link": "https://en.wikipedia.org/wiki/KOMPILER"
  },
  {
    "title": "Lisp (programming language)",
    "slug": "lisp-programming-language",
    "content": "Lisp (historically LISP, an abbreviation of \"list processing\") is a family of programming languages with a long history and a distinctive, fully parenthesized prefix notation.\nOriginally specified in the late 1950s, it is the second-oldest high-level programming language still in common use, after Fortran. Lisp has changed since its early days, and many dialects have existed over its history. Today, the best-known general-purpose Lisp dialects are Common Lisp, Scheme, Racket, and Clojure.\nLisp was originally created as a practical mathematical notation for computer programs, influenced by (though not originally derived from) the notation of Alonzo Church's lambda calculus. It quickly became a favored programming language for artificial intelligence (AI) research. As one of the earliest programming languages, Lisp pioneered many ideas in computer science, including tree data structures, automatic storage management, dynamic typing, conditionals, higher-order functions, recursion, the self-hosting compiler, and the read–eval–print loop.\nThe name LISP derives from \"List Processor\". Linked lists are one of Lisp's major data structures, and Lisp source code is made of lists. Thus, Lisp programs can manipulate source code as a data structure, giving rise to the macro systems that allow programmers to create new syntax or new domain-specific languages embedded in Lisp.\nThe interchangeability of code and data gives Lisp its instantly recognizable syntax. All program code is written as s-expressions, or parenthesized lists. A function call or syntactic form is written as a list with the function or operator's name first, and the arguments following; for instance, a function f that takes three arguments would be called as (f arg1 arg2 arg3).",
    "link": "https://en.wikipedia.org/wiki/Lisp_(programming_language)"
  },
  {
    "title": "Logo (programming language)",
    "slug": "logo-programming-language",
    "content": "Logo is an educational programming language, designed in 1967 by Wally Feurzeig, Seymour Papert, and Cynthia Solomon. The name was coined by Feurzeig while he was at Bolt, Beranek and Newman, and derives from the Greek logos, meaning 'word' or 'thought'.\nA general-purpose language, Logo is widely known for its use of turtle graphics, in which commands for movement and drawing produced line or vector graphics, either on screen or with a small robot termed a turtle. The language was conceived to teach concepts of programming related to Lisp and only later to enable what Papert called \"body-syntonic reasoning\", where students could understand, predict, and reason about the turtle's motion by imagining what they would do if they were the turtle. There are substantial differences among the many dialects of Logo, and the situation is confused by the regular appearance of turtle graphics programs that are named Logo.\nLogo is a multi-paradigm adaptation and dialect of Lisp, a functional programming language. There is no standard Logo, but UCBLogo has the facilities for handling lists, files, I/O, and recursion in scripts, and can be used to teach all computer science concepts, as UC Berkeley lecturer Brian Harvey did in his Computer Science Logo Style trilogy.\nLogo is usually an interpreted language, although compiled Logo dialects (such as Lhogho and Liogo) have been developed. Logo is not case-sensitive but retains the case used for formatting purposes.",
    "link": "https://en.wikipedia.org/wiki/Logo_(programming_language)"
  },
  {
    "title": "Python (programming language)",
    "slug": "python-programming-language",
    "content": "Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation. Python is dynamically type-checked and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming.\nGuido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language. Python 3.0, released in 2008, was a major revision and not completely backward-compatible with earlier versions. Beginning with Python 3.5, capabilities and keywords for typing were added to the language, allowing optional static typing. As of 2026, the Python Software Foundation supports Python 3.10, 3.11, 3.12, 3.13, and 3.14, following the project's annual release cycle and five-year support policy. Python 3.15 is currently in the alpha development phase, and the stable release is expected to come out in October 2026.\"Earlier versions in the 3.x series have reached end-of-life and no longer receive security updates. \nPython has gained widespread use in the machine learning community. It is widely taught as an introductory programming language. Since 2003, Python has consistently ranked in the top ten of the most popular programming languages in the TIOBE Programming Community Index, which ranks based on searches in 24 platforms.",
    "link": "https://en.wikipedia.org/wiki/Python_(programming_language)"
  },
  {
    "title": "Perl",
    "slug": "perl",
    "content": "Perl is a high-level, general-purpose, interpreted, dynamic programming language. Though Perl is not officially an acronym, there are various backronyms in use, including \"Practical Extraction and Reporting Language\".\nPerl was developed by Larry Wall in 1987 as a general-purpose Unix scripting language to make report processing easier. Since then, it has undergone many changes and revisions. Perl originally was not capitalized and the name was changed to being capitalized by the time Perl 4 was released. The latest release is Perl 5, first released in 1994. From 2000 to October 2019 a sixth version of Perl was in development; the sixth version's name was changed to Raku. Both languages continue to be developed independently by different development teams which liberally borrow ideas from each other.\nPerl borrows features from other programming languages including C, sh, AWK, and sed. It provides text processing facilities without the arbitrary data-length limits of many contemporary Unix command line tools. Perl is a highly expressive programming language: source code for a given algorithm can be short and highly compressible.\nPerl gained widespread popularity in the mid-1990s as a CGI scripting language, in part due to its powerful regular expression and string parsing abilities. In addition to CGI, Perl 5 is used for system administration, network programming, finance, bioinformatics, and other applications, such as for graphical user interfaces (GUIs). It has been nicknamed \"the Swiss Army chainsaw of scripting languages\" because of its flexibility and power. In 1998, it was also referred to as the \"duct tape that holds the Internet together\", in reference to both its ubiquitous use as a glue language and its perceived inelegance.",
    "link": "https://en.wikipedia.org/wiki/Perl"
  },
  {
    "title": "PHP",
    "slug": "php",
    "content": "PHP is a general-purpose scripting language geared towards web development. It was  created by Danish-Canadian programmer Rasmus Lerdorf in 1993 and released in 1995. The PHP reference implementation is now produced by the PHP Group. PHP was originally an abbreviation of Personal Home Page, but it now stands for the recursive backronym PHP: Hypertext Preprocessor.\nPHP code is usually processed on a web server by a PHP interpreter implemented as a module, a daemon or a Common Gateway Interface (CGI) executable. On a web server, the result of the interpreted and executed PHP code—which may be any type of data, such as generated HTML or binary image data—can form the whole or part of an HTTP response. Various web template systems, web content management systems, and web frameworks exist that can be employed to orchestrate or facilitate the generation of that response. Additionally, PHP can be used for programming tasks outside the web context, though non-web uses are rare. PHP code can also be directly executed from the command line.\nThe standard PHP interpreter, powered by the Zend Engine, is free software released under the PHP License. PHP has been widely ported and can be deployed on most web servers on a variety of operating systems and platforms.",
    "link": "https://en.wikipedia.org/wiki/PHP"
  },
  {
    "title": "Lua",
    "slug": "lua",
    "content": "Lua  is a lightweight, high-level, multi-paradigm programming language designed mainly for embedded use in applications. Lua is cross-platform software, since the interpreter of compiled bytecode is written in ANSI C, and Lua has a relatively simple C application programming interface (API) to embed it into applications.\nLua originated in 1993 as a language for extending software applications to meet the increasing demand for customization at the time. It provided the basic facilities of most procedural programming languages, but more complicated or domain-specific features were not included; rather, it included mechanisms for extending the language, allowing programmers to implement such features. As Lua was intended to be a general embeddable extension language, the designers of Lua focused on improving its speed, portability, extensibility and ease-of-use in development.",
    "link": "https://en.wikipedia.org/wiki/Lua"
  },
  {
    "title": "PureBasic",
    "slug": "purebasic",
    "content": "PureBasic is a commercially distributed procedural computer programming language and integrated development environment based on BASIC and developed by Fantaisie Software for Windows, Linux, macOS and Raspberry Pi. An Amiga version is available, although it has been discontinued and some parts of it are released as open-source. The first public release of PureBasic for Windows was on 17 December 2000. It has been continually updated ever since.\nPureBasic has a \"lifetime license model\". As cited on the website, the first PureBasic user (who registered in 1998) still has free access to new updates and this is not going to change.\nPureBasic compiles directly to IA-32, x86-64, arm32 and arm64, PowerPC or 680x0  instruction sets, generating small standalone executables and DLLs which need no runtime libraries beyond the standard system libraries. Programs developed without using the platform-specific application programming interfaces (APIs) can be built easily from the same source file with little or no modification.\nPureBasic supports inline assembly, allowing the developer to include FASM assembler commands within PureBasic source code, while using the variables declared in PureBasic source code, enabling experienced programmers to improve the speed of speed-critical sections of code. PureBasic supports and has integrated the OGRE 3D Environment. Other 3D environments such as the Irrlicht Engine are unofficially supported.\nSince version 6.00 (June 2022), in addition to compilation using ASM, PureBasic offers compilation with a C backend. This enables access to new platforms (e.g. Raspberry) and should make it easier to add new libraries in the future.",
    "link": "https://en.wikipedia.org/wiki/PureBasic"
  },
  {
    "title": "MATH-MATIC",
    "slug": "mathmatic",
    "content": "MATH-MATIC is the marketing name for the AT-3 (Algebraic Translator 3) compiler, an early programming language for the UNIVAC I and UNIVAC II.\nMATH-MATIC was written beginning around 1955 by a team led by Charles Katz under the direction of Grace Hopper. A preliminary manual was produced in 1957 and a final manual the following year.\nSyntactically, MATH-MATIC was similar to Univac's contemporaneous business-oriented language, FLOW-MATIC, differing in providing algebraic-style expressions and floating-point arithmetic, and arrays rather than record structures.",
    "link": "https://en.wikipedia.org/wiki/MATH-MATIC"
  },
  {
    "title": "Pico (programming language)",
    "slug": "pico-programming-language",
    "content": "Pico is a programming language developed at the Software Languages Lab at Vrije Universiteit Brussel, intended to be simple, powerful, extensible, and easy to read. The language was created to introduce the essentials of programming to non-computer science students.\nPico can be seen as an effort to generate a palatable and enjoyable language for people who do not want to study hard for the elegance and power of a language. They have done it by adapting Scheme's semantics.\nWhile designing Pico, the Software Languages Lab was inspired by the Abelson and Sussman's book \"Structure and Interpretation of Computer Programs\". Furthermore, they were influenced by the teaching of programming at high school or academic level.\nPico should be interpreted as 'small', the idea was to create a small language for educational purposes.",
    "link": "https://en.wikipedia.org/wiki/Pico_(programming_language)"
  },
  {
    "title": "PL/M",
    "slug": "plm",
    "content": "PL/M, an acronym for Programming Language for Microcomputers, is a high-level language conceived and developed by Gary Kildall in 1973 for Hank Smith at Intel for the Intel 8008. It was later expanded for the newer Intel 8080.\nThe 8080 had enough power to run the PL/M compiler, but lacked a suitable form of mass storage. In an effort to port the language from the PDP-10 to the 8080, Kildall used PL/M to write a disk operating system that allowed a floppy disk to be used. This was the basis of CP/M.",
    "link": "https://en.wikipedia.org/wiki/PL/M"
  },
  {
    "title": "Processing",
    "slug": "processing",
    "content": "Processing is a free graphics library and integrated development environment (IDE) built for the electronic arts, new media art, and visual design communities with the purpose of teaching non-programmers the fundamentals of computer programming in a visual context.\nProcessing uses the Java programming language, with additional simplifications such as additional classes and aliased mathematical functions and operations. It also provides a graphical user interface for simplifying the compilation and execution stage.\nThe Processing language and IDE have been the precursor to other projects including Arduino and Wiring.",
    "link": "https://en.wikipedia.org/wiki/Processing"
  },
  {
    "title": "Joy (programming language)",
    "slug": "joy-programming-language",
    "content": "The Joy programming language in computer science is a purely functional programming language that was produced by Manfred von Thun of La Trobe University in Melbourne, Australia. Joy is based on composition of functions rather than lambda calculus. It was inspired by the function-level programming style of John Backus's FP.\nIt has turned out to have many similarities to Forth, due not to design but to an independent evolution and convergence.",
    "link": "https://en.wikipedia.org/wiki/Joy_(programming_language)"
  },
  {
    "title": "K (programming language)",
    "slug": "k-programming-language",
    "content": "K is a proprietary array processing programming language developed by Arthur Whitney and commercialized by KX Systems. The language serves as the foundation for kdb+, an in-memory, column-based database, and other related financial products. The language, originally developed in 1993, is a variant of APL and contains elements of Scheme. Advocates of the language emphasize its speed, facility in handling arrays, and expressive syntax.",
    "link": "https://en.wikipedia.org/wiki/K_(programming_language)"
  },
  {
    "title": "Linda (coordination language)",
    "slug": "linda-coordination-language",
    "content": "In computer science, Linda is a coordination model that aids communication in parallel computing environments. Developed by David Gelernter, it is meant to be used alongside a full-fledged computation language like Fortran or C where Linda's role is to \"create computational activities and to support communication among them\".",
    "link": "https://en.wikipedia.org/wiki/Linda_(coordination_language)"
  },
  {
    "title": "POP-2",
    "slug": "pop2",
    "content": "POP-2 (also called POP2) is a programming language developed around 1970 from the earlier language POP-1 (developed by Robin Popplestone in 1968, originally named COWSEL) by Robin Popplestone and Rod Burstall at the University of Edinburgh. It drew roots from many sources: the languages Lisp and ALGOL 60, and theoretical ideas from Peter J. Landin. It used an incremental compiler, which gave it some of the flexibility of an interpreted language, including allowing new function definitions at run time and modification of function definitions while a program runs (both of which are features of dynamic compilation), without the overhead of an interpreted language.",
    "link": "https://en.wikipedia.org/wiki/POP-2"
  },
  {
    "title": "Multi-adjoint logic programming",
    "slug": "multiadjoint-logic-programming",
    "content": "Multi-adjoint logic programming defines syntax and semantics of a logic programming program in such a way that the underlying maths justifying the results are a residuated lattice and/or MV-algebra.\nThe definition of a multi-adjoint logic program is given, as usual in fuzzy logic programming, as a set of weighted rules and facts of a given formal language F. Notice that the use of different implications is allowed in these rules.\nDefinition: A multi-adjoint logic program is a set P of rules of the form <(A ←i B), δ> such that:\n1. The rule (A ←i B) is a formula of F;\n2. The confidence factor δ is an element (a truth-value) of L;\n3. The head A is an atom;\n4. The body B is a formula built from atoms B1, …, Bn (n ≥ 0) by the use of conjunctors, disjunctors, and aggregators.\n5. Facts are rules with body ┬.\n6. A query (or goal) is an atom intended as a question ?A prompting the system.",
    "link": "https://en.wikipedia.org/wiki/Multi-adjoint_logic_programming"
  },
  {
    "title": "Little b (programming language)",
    "slug": "little-b-programming-language",
    "content": "Little b is a domain-specific programming language, more specifically, a modeling language, designed to build modular mathematical models of biological systems.  It was designed and authored by Aneil Mallavarapu.  Little b is being developed in the Virtual Cell Program at Harvard Medical School, headed by mathematician Jeremy Gunawardena.\nThis language is based on Lisp and is meant to allow modular programming to model biological systems.  It will allow more flexibility to facilitate rapid change that is required to accurately capture complex biological systems.\nThe language draws on techniques from artificial intelligence and symbolic mathematics, and provides  syntactic conveniences derived from object-oriented languages.  The language was originally denoted with a lowercase b (distinguishing it from B, the predecessor to the widely used C programming language), but the name was eventually changed to \"little b\" to avoid confusion and to pay homage to Smalltalk.",
    "link": "https://en.wikipedia.org/wiki/Little_b_(programming_language)"
  },
  {
    "title": "Kinetic Rule Language",
    "slug": "kinetic-rule-language",
    "content": "Kinetic Rule Language (KRL) is a rule-based programming language for creating applications on the Live Web. KRL programs, or rulesets, comprise a number of rules that respond to particular events.  KRL has been promoted as language for building personal clouds.\nKRL is part of an open-source project called KRE, for Kinetic Rules Engine, developed by Kynetx, Inc.",
    "link": "https://en.wikipedia.org/wiki/Kinetic_Rule_Language"
  },
  {
    "title": "PIC (markup language)",
    "slug": "pic-markup-language",
    "content": "In computing, Pic is a domain-specific programming language by Brian Kernighan for specifying line diagrams.\nThe language contains predefined basic linear objects: line, move, arrow, and spline, the planar\nobjects box, circle, ellipse, arc, and definable composite elements.\nObjects are placed with respect to other objects or absolute coordinates.\nA liberal interpretation of the input invokes\ndefault parameters when objects are incompletely specified.\nAn interpreter translates this description into\nconcrete drawing commands in a variety of possible output formats.\nPic is a procedural programming language, with variable assignment, macros, conditionals, and looping. The language is an example of a little language originally intended for the comfort of non-programmers in the Unix environment (Bentley 1988).",
    "link": "https://en.wikipedia.org/wiki/PIC_(markup_language)"
  },
  {
    "title": "Rebol",
    "slug": "rebol",
    "content": "Rebol ( REB-əl; historically REBOL) is a cross-platform data exchange language and a multi-paradigm dynamic programming language designed by Carl Sassenrath for network communications and distributed computing.  It introduces the concept of dialecting: small, optimized, domain-specific languages for code and data, which is also the most notable property of the language according to its designer Carl Sassenrath:\n\nAlthough it can be used for programming, writing functions, and performing processes, its greatest strength is the ability to easily create domain-specific languages or dialects\nDouglas Crockford, known for his involvement in the development of JavaScript, has described Rebol as \"a more modern language, but with some very similar ideas to  Lisp, in that it's all built upon a representation of data which is then executable as programs\" and as one of JSON's influences.\nOriginally, the language and its official implementation were proprietary and closed source, developed by REBOL Technologies. Following discussion with Lawrence Rosen, the Rebol version 3 interpreter was released under the Apache 2.0 license on December 12, 2012. Older versions are only available in binary form, and no source release for them is planned.\nRebol has been used to program Internet applications (both client- and server-side), database applications, utilities, and multimedia applications.",
    "link": "https://en.wikipedia.org/wiki/Rebol"
  },
  {
    "title": "Smalltalk",
    "slug": "smalltalk",
    "content": "Smalltalk is a purely object-oriented programming language that was originally created in the 1970s for educational use, specifically for constructionist learning, but later found use in business. It was created at Xerox PARC by Learning Research Group (LRG) scientists, including Alan Kay, Dan Ingalls, Adele Goldberg, Ted Kaehler, Diana Merry, and Scott Wallace.\nIn Smalltalk, executing programs are built of opaque, atomic objects, which are instances of template code stored in classes. These objects intercommunicate by passing of messages, via an intermediary virtual machine environment (VM). A relatively small number of objects, called primitives, are not amenable to live redefinition, sometimes being defined independently of the Smalltalk programming environment.\nHaving undergone significant industry development toward other uses, including business and database functions, Smalltalk is still in use today. When first publicly released, Smalltalk-80 presented numerous foundational ideas for the nascent field of object-oriented programming.\nSince inception, the language provided interactive programming via an integrated development environment. This requires reflection and late binding in the language execution of code. Later development has led to at least one instance of Smalltalk execution environment which lacks such an integrated graphical user interface or front-end.\nSmalltalk-like languages are in active development and have gathered communities of users around them. American National Standards Institute (ANSI) Smalltalk was ratified in 1998 and represents the standard version of Smalltalk.\nSmalltalk took second place for \"most loved programming language\" in the Stack Overflow Developer Survey in 2017, but it was not among the 26 most loved programming languages of the 2018 survey.",
    "link": "https://en.wikipedia.org/wiki/Smalltalk"
  },
  {
    "title": "Simula",
    "slug": "simula",
    "content": "Simula is the name of two simulation programming languages, Simula I and Simula 67, developed in the 1960s at the Norwegian Computing Center in Oslo, by Ole-Johan Dahl and Kristen Nygaard. Syntactically, it is an approximate superset of ALGOL 60,\n\nand was also influenced by the design of SIMSCRIPT.\nSimula 67 introduced objects, classes, inheritance and subclasses, virtual procedures, coroutines, and discrete event simulation, and featured garbage collection. Other forms of subtyping (besides inheriting subclasses) were introduced in Simula derivatives.\nSimula is considered the first object-oriented programming language. As its name suggests, the first Simula version by 1962 was designed for doing simulations; Simula 67 though was designed to be a general-purpose programming language and provided the framework for many of the features of object-oriented languages today.\nSimula has been used in a wide range of applications such as simulating very-large-scale integration (VLSI) designs, process modeling, communication protocols, algorithms, and other applications such as typesetting, computer graphics, and education.\nComputer scientists such as Bjarne Stroustrup, creator of C++, and James Gosling, creator of Java, have acknowledged Simula as a major influence. Simula-type objects are reimplemented in C++, Object Pascal, Java, C#, and many other languages.",
    "link": "https://en.wikipedia.org/wiki/Simula"
  },
  {
    "title": "SNOBOL",
    "slug": "snobol",
    "content": "SNOBOL (StriNg Oriented and symBOlic Language) is a series of programming languages developed between 1962 and 1967 at AT&T Bell Laboratories by David J. Farber, Ralph Griswold and Ivan P. Polonsky, culminating in SNOBOL4. It was one of a number of text-string-oriented languages developed during the 1950s and 1960s; others included COMIT and TRAC. Despite the similar name, it is entirely unlike COBOL.\nSNOBOL4 stands apart from most programming languages of its era by having patterns as a first-class data type, a data type whose values can be manipulated in all ways permitted to any other data type in the programming language, and by providing operators for pattern concatenation and alternation. SNOBOL4 patterns are a type of object and admit various manipulations, much like later object-oriented languages such as JavaScript whose patterns are known as regular expressions. In addition SNOBOL4 strings generated during execution can be treated as programs and either interpreted or compiled and executed (as in the eval function of other languages).\nSNOBOL4 was quite widely taught in larger U.S. universities in the late 1960s and early 1970s and was widely used in the 1970s and 1980s as a text manipulation language in the humanities.\nIn the 1980s and 1990s, its use faded as newer languages such as AWK and Perl made string manipulation by means of regular expressions fashionable. SNOBOL4 patterns include a way to express BNF grammars, which are equivalent to context-free grammars and more powerful than regular expressions. \nThe \"regular expressions\" in current versions of AWK and Perl are in fact extensions of regular expressions in the traditional sense, but regular expressions, unlike SNOBOL4 patterns, are not recursive, which gives a distinct computational advantage to SNOBOL4 patterns. (Recursive expressions did appear in Perl 5.10, though, released in December 2007.)\nThe later SL5 (1977) and Icon (1978) languages were designed by Griswold to combine the backtracking of SNOBOL4 pattern matching with more standard ALGOL-like structuring.",
    "link": "https://en.wikipedia.org/wiki/SNOBOL"
  },
  {
    "title": "XSLT",
    "slug": "xslt",
    "content": "XSLT (Extensible Stylesheet Language Transformations) is a language originally designed for transforming XML documents into other XML documents, or other formats such as HTML for web pages, plain text, or XSL Formatting Objects. These formats can be subsequently converted to formats such as PDF, PostScript, and PNG. Support for JSON and plain-text transformation was added in later updates to the XSLT 1.0 specification.\nXSLT 3.0 implementations support Java, .NET, C/C++, Python, PHP and NodeJS. An XSLT 3.0 JavaScript library can also be hosted within the web browser. Modern web browsers also include native support for XSLT 1.0.\nThe XSLT document transformation specifies how to transform an XML document into new document (usually XML, but other formats, such as plain text are supported). Typically, input documents are XML files, but anything from which the processor can build an XQuery and XPath Data Model can be used, such as relational database tables or geographical information systems.\nWhile XSLT was originally designed as a special-purpose language for XML transformation, the language is Turing-complete, making it theoretically capable of arbitrary computations.",
    "link": "https://en.wikipedia.org/wiki/XSLT"
  },
  {
    "title": "Squeak",
    "slug": "squeak",
    "content": "Squeak is an object-oriented, class-based, and reflective programming language. It was derived from Smalltalk-80 by a group that included some of Smalltalk-80's original developers, initially at Apple Computer, then at Walt Disney Imagineering, where it was intended for use in internal Disney projects. The group later was supported by HP Labs and SAP.\nSqueak runs on a stack virtual machine (VM), allowing for a high degree of portability. The Squeak system includes code for generating a new version of the VM on which it runs, along with a VM simulator written in Squeak.",
    "link": "https://en.wikipedia.org/wiki/Squeak"
  },
  {
    "title": "Self (programming language)",
    "slug": "self-programming-language",
    "content": "Self is a general-purpose, high-level, object-oriented programming language based on the concept of prototypes. Self began as a dialect of Smalltalk, being dynamically typed and using just-in-time compilation (JIT) with the prototype-based approach to objects: it was first used as an experimental test system for language design in the 1980s and 1990s. In 2006, Self was still being developed as part of the Klein project, which was a Self virtual machine written fully in Self. The latest version, 2024.1 was released in August 2024.\nSeveral just-in-time compilation techniques were pioneered and improved in Self research as they were required to allow a very high-level object-oriented language to perform at up to half the speed of optimized C. Much of the development of Self took place at Sun Microsystems, and the techniques they developed were later deployed for Java's HotSpot virtual machine.\nAt one point a version of Smalltalk was implemented in Self. Because it was able to use the JIT, this also gave extremely good performance.",
    "link": "https://en.wikipedia.org/wiki/Self_(programming_language)"
  },
  {
    "title": "R (programming language)",
    "slug": "r-programming-language",
    "content": "R is a programming language for statistical computing and data visualization. It has been widely adopted in the fields of data mining, bioinformatics, data analysis, and data science.\nThe core R language is extended by a large number of software packages, which contain reusable code, documentation, and sample data. Some of the most popular R packages are in the tidyverse collection, which enhances functionality for visualizing, transforming, and modelling data, as well as improves the ease of programming (according to the authors and users).\nR is free and open-source software distributed under the GNU General Public License. The language is implemented primarily in C, Fortran, and R itself. Precompiled executables are available for the major operating systems (including Linux, MacOS, and Microsoft Windows).\nIts core is an interpreted language with a native command line interface. In addition, multiple third-party applications are available as graphical user interfaces; such applications include RStudio (an integrated development environment),  Jupyter (a notebook interface), as well as Termux and Google Colab for mobile devices.",
    "link": "https://en.wikipedia.org/wiki/R_(programming_language)"
  },
  {
    "title": "XPL",
    "slug": "xpl",
    "content": "XPL, for expert's programming language is a programming language based on PL/I, a portable one-pass compiler written in its own language, and a parser generator tool for easily implementing similar compilers for other languages.  XPL was designed in 1967 as a way to teach compiler design principles and as starting point for students to build compilers for their own languages.\nXPL was designed and implemented by William M. McKeeman, David B. Wortman, James J. Horning and others at Stanford University. XPL was first announced at the 1968 Fall Joint Computer Conference.  The methods and compiler are described in detail in the 1971 textbook A Compiler Generator.\nThey called the combined work a 'compiler generator'.  But that implies little or no language- or target-specific programming is required to build a compiler for a new language or new target.  A better label for XPL is a translator writing system.  It helps to write a compiler with less new or changed programming code.",
    "link": "https://en.wikipedia.org/wiki/XPL"
  },
  {
    "title": "S (programming language)",
    "slug": "s-programming-language",
    "content": "S is a statistical programming language developed primarily by John Chambers and (in earlier versions) Rick Becker, Trevor Hastie, William Cleveland and Allan Wilks of Bell Laboratories.  The aim of the language, as expressed by John Chambers, is \"to turn ideas into software, quickly and faithfully\". It was formerly widely used by academic researchers., but has now been superseded by the partially backwards compatible R language, a part of the GNU free software project. S-PLUS was a widely used commercial implementation of S that was formerly sold by TIBCO Software.",
    "link": "https://en.wikipedia.org/wiki/S_(programming_language)"
  },
  {
    "title": "Raku (programming language)",
    "slug": "raku-programming-language",
    "content": "Raku is a member of the Perl family of programming languages. Formerly named Perl 6, it was renamed in October 2019. Raku introduces elements of many modern and historical languages. Compatibility with Perl was not a goal, though a compatibility mode is part of the specification. The design process for Raku began in 2000.",
    "link": "https://en.wikipedia.org/wiki/Raku_(programming_language)"
  },
  {
    "title": "Visual Prolog",
    "slug": "visual-prolog",
    "content": "Visual Prolog, previously known as PDC Prolog and Turbo Prolog, is a strongly typed object-oriented extension of Prolog. It was marketed by Borland as Turbo Prolog (version 1.0 in 1986 and version 2.0 in 1988). It is now developed and marketed by the Danish firm PDC that originally created it. Visual Prolog can build Microsoft Windows GUI-applications, console applications, DLLs (dynamic link libraries), and CGI-programs. It can also link to COM components and to databases by means of ODBC.\nVisual Prolog contains a compiler which generates x86 and x86-64 machine code. Unlike standard Prolog, programs written in Visual Prolog are statically typed. This allows some errors to be caught at compile-time instead of run-time.",
    "link": "https://en.wikipedia.org/wiki/Visual_Prolog"
  },
  {
    "title": "Tuple space",
    "slug": "tuple-space",
    "content": "A tuple space is an implementation of the  associative memory paradigm for parallel/distributed computing. It provides a repository of tuples that can be accessed concurrently. As an illustrative example, consider that there are a group of processors that produce pieces of data and a group of processors that use the data. Producers post their data as tuples in the space, and the consumers then retrieve data from the space that match a certain pattern. This is also known as the blackboard metaphor. Tuple space may be thought as a form of distributed shared memory.\nTuple spaces were the theoretical underpinning of the Linda language developed by David Gelernter and Nicholas Carriero at Yale University in 1986.\nImplementations of tuple spaces have also been developed for Java (JavaSpaces), Lisp, Lua, Prolog, Python, Ruby, Smalltalk, Tcl, and the .NET Framework.",
    "link": "https://en.wikipedia.org/wiki/Tuple_space"
  },
  {
    "title": "Web framework",
    "slug": "web-framework",
    "content": "A web framework (WF) or web application framework (WAF) is a software framework that is designed to support the development of web applications including web services, web resources, and web APIs. Web frameworks provide a standard way to build and deploy web applications on the World Wide Web. Web frameworks aim to automate the overhead associated with common activities performed in web development. For example, many web frameworks provide libraries for database access, templating frameworks, and session management, and they often promote code reuse. Although they often target development of dynamic web sites, they are also applicable to static websites.",
    "link": "https://en.wikipedia.org/wiki/Web_framework"
  },
  {
    "title": "Squirrel (programming language)",
    "slug": "squirrel-programming-language",
    "content": "Squirrel is a high level imperative, object-oriented programming language, designed to be a lightweight scripting language that fits in the size, memory bandwidth, and real-time requirements of applications like video games.\nMirthKit, a simple toolkit for making and distributing open source, cross-platform 2D games, uses Squirrel for its platform. It is used extensively by Code::Blocks for scripting and was also used in Final Fantasy Crystal Chronicles: My Life as a King. It is also used in Left 4 Dead 2, Portal 2, Team Fortress 2, Thimbleweed Park, and War Thunder for scripted events and in NewDark, an unofficial Thief 2: The Metal Age engine update, to facilitate additional, simplified means of scripting mission events, aside of the regular C scripting.",
    "link": "https://en.wikipedia.org/wiki/Squirrel_(programming_language)"
  },
  {
    "title": "Scala (programming language)",
    "slug": "scala-programming-language",
    "content": "Scala ( SKAH-lah) is a strongly statically typed high-level general-purpose programming language that supports both object-oriented programming and functional programming. Designed to be concise, many of Scala's design decisions are intended to address criticisms of Java.\nScala source code can be compiled to Java bytecode and run on a Java virtual machine (JVM). Scala can also be transpiled to JavaScript to run in a browser, or compiled directly to a native executable using Clang. When running on the JVM, Scala provides language interoperability with Java so that libraries written in either language may be referenced directly in Scala or Java code. Like Java, Scala is object-oriented, and uses a syntax termed curly-brace which is similar to the language C. Since Scala 3, there is also an option to use the off-side rule (indenting) to structure blocks, and its use is advised. Martin Odersky has said that this turned out to be the most productive change introduced in Scala 3.\nUnlike Java, Scala has many features of functional programming languages (like Scheme, Standard ML, and Haskell), including currying, immutability, lazy evaluation, and pattern matching. It also has an advanced type system supporting algebraic data types, covariance and contravariance, higher-order types (but not higher-rank types), anonymous types, operator overloading, optional parameters, named parameters, raw strings, and an experimental exception-only version of algebraic effects that can be seen as a more powerful version of Java's checked exceptions.\nThe name Scala is a portmanteau of scalable and language, signifying that it is designed to grow with the demands of its users.",
    "link": "https://en.wikipedia.org/wiki/Scala_(programming_language)"
  },
  {
    "title": "Tea (programming language)",
    "slug": "tea-programming-language",
    "content": "Tea is a high-level scripting language for the Java environment. It combines features of Scheme, Tcl, and Java.",
    "link": "https://en.wikipedia.org/wiki/Tea_(programming_language)"
  },
  {
    "title": "Structured text",
    "slug": "structured-text",
    "content": "Structured text, abbreviated as ST or STX, is one of the five languages supported by the IEC 61131-3 standard, designed for programmable logic controllers (PLCs). It is a high level language that is block structured and syntactically resembles Pascal, on which it is based. All of the languages share IEC61131 Common Elements. The variables and function calls are defined by the common elements so different languages within the IEC 61131-3 standard can be used in the same program.\nComplex statements and nested instructions are supported:\n\nIteration loops (REPEAT-UNTIL; WHILE-DO)\nConditional execution (IF-THEN-ELSE; CASE)\nFunctions (SQRT(), SIN())",
    "link": "https://en.wikipedia.org/wiki/Structured_text"
  },
  {
    "title": "S-PLUS",
    "slug": "splus",
    "content": "S-PLUS is a commercial implementation of the S programming language sold by TIBCO Software Inc.\nIt features object-oriented programming capabilities and advanced analytical algorithms. Its statistical analysis capabilities are commonly used by econometricians. The S-PLUS FinMetrics software package was developed for econometric time series analysis.\nDue to the increasing popularity of the open source S successor R, TIBCO Software released the TIBCO Enterprise Runtime for R (TERR) as an alternative R interpreter. It is available on Windows and UNIX operating systems.",
    "link": "https://en.wikipedia.org/wiki/S-PLUS"
  },
  {
    "title": "TreeDL",
    "slug": "treedl",
    "content": "Tree Description Language (TreeDL) is a computer language for description of strictly-typed tree data structures and operations on them. The main use of TreeDL is in the development of language-oriented tools (compilers, translators, etc.) for the description of a structure of abstract syntax trees. \nTree description can be used as\n\na documentation of interface between parser and other subsystems;\na source for generation of data types representing a tree in target programming languages;\na source for generation of various support code: visitors, walkers, factories, etc.\nTreeDL can be used with any parser generator that allows custom actions during parsing (for example, ANTLR, JavaCC).",
    "link": "https://en.wikipedia.org/wiki/TreeDL"
  },
  {
    "title": "Drupal",
    "slug": "drupal",
    "content": "Drupal () is a free and open-source web content management system (CMS) written in PHP and distributed under the GNU General Public License. Drupal provides an open-source back-end framework for at least 14% of the top 10,000 websites worldwide and 1.2% of the top 10 million websites—ranging from personal blogs to corporate, political, and government sites.  Drupal can also be used for knowledge management and for business collaboration. \nAs of March 2022, the Drupal community had more than 1.39 million members, including 124,000 users actively contributing, resulting in more than 50,000 free modules that extend and customize Drupal functionality, over 3,000 free themes that change the look and feel of Drupal, and at least 1,400 free distributions that allow users to quickly and easily set up a complex, use-specific Drupal in fewer steps.\nThe base of Drupal is known as Drupal core, contains basic features common to content-management systems. These include user account registration and maintenance, menu management, RSS feeds, taxonomy, page layout customization, and system administration. The Drupal core installation can serve as a simple website, a single- or multi-user blog, an Internet forum, or a community website providing for user-generated content.\nDrupal also describes itself as a web application framework. When compared with notable frameworks, Drupal meets most of the generally accepted feature requirements for such web frameworks.\nAlthough Drupal offers a sophisticated API for developers, basic Web-site installation and administration of the framework require no programming skills.\nDrupal runs on any computing platform that supports both a web server capable of running PHP and a database to store content and configuration.\nIn 2023/2024, Drupal received over 250,000 Euros from Germany's Sovereign Tech Fund.\nDrupal is officially recognized as a Digital Public Good.",
    "link": "https://en.wikipedia.org/wiki/Drupal"
  },
  {
    "title": "Apache Struts 1",
    "slug": "apache-struts-1",
    "content": "Apache Struts 1 is an open-source web application framework for developing Java EE web applications. It uses and extends the Java Servlet API to encourage developers to adopt a model–view–controller (MVC) architecture. It was originally created by Craig McClanahan and donated to the Apache Foundation in May 2000. Formerly located under the Apache Jakarta Project and known as Jakarta Struts, it became a top-level Apache project in 2005.\nThe WebWork framework spun off from Apache Struts aiming to offer enhancements and refinements while retaining the same general architecture of the original Struts framework. However, it was announced in December 2005 that Struts would re-merge with WebWork. WebWork 2.2 has been adopted as Apache Struts 2, which reached its first full release in February 2007.\nIn addition to the current and constantly evolving successor version Struts 2, a clone of Struts 1 exists since 2022, which updates the legacy framework of Struts 1 to a current Jakarta EE compatible stack.",
    "link": "https://en.wikipedia.org/wiki/Apache_Struts_1"
  },
  {
    "title": "Biopython",
    "slug": "biopython",
    "content": "Biopython is an open-source collection of non-commercial Python modules for computational biology and bioinformatics. It makes robust and well-tested code easily accessible to researchers. Python is an object-oriented programming language and is a suitable choice for automation of common tasks.  The availability of reusable libraries saves development time and lets researchers focus on addressing scientific questions. Biopython is constantly updated and maintained by a large team of volunteers across the globe.\nBiopython contains parsers for diverse bioinformatic sequence, alignment, and structure formats. Sequence formats include FASTA, FASTQ, GenBank, and EMBL. Alignment formats include Clustal, BLAST, PHYLIP, and NEXUS. Structural formats include the PDB, which contains the 3D atomic coordinates of the macromolecules. It has provisions to access information from biological databases like NCBI, Expasy, PBD, and BioSQL. This can be used in scripts or incorporated into their software. Biopython contains a standard sequence class, sequence alignment, and motif analysis tools. It also has clustering algorithms, a module for structural biology, and a module for phylogenetics analysis.",
    "link": "https://en.wikipedia.org/wiki/Biopython"
  },
  {
    "title": "ASP.NET",
    "slug": "aspnet",
    "content": "ASP.NET is a server-side web-application framework designed for web development to produce dynamic web pages. It was developed by Microsoft to allow programmers to build dynamic web sites, applications and services. The name stands for Active Server Pages Network Enabled Technologies.\nASP.NET was first announced to the public under the codename ASP+, and is a re-implementation of Microsoft's Active Server Pages (ASP) technology. ASP.NET is built on the Common Language Runtime (CLR), allowing programmers to write ASP.NET code using any supported .NET language. The ASP.NET SOAP extension framework allows ASP.NET components to process SOAP messages.\nIn 2016, Microsoft released ASP.NET Core as ASP.NET's successor. This new version is a re-implementation of ASP.NET as a modular web framework, together with other frameworks like Entity Framework. The new framework uses the new open-source .NET Compiler Platform (codename \"Roslyn\") and is cross platform. ASP.NET MVC, ASP.NET Web API, and ASP.NET Web Pages (a platform using only Razor pages) have merged into a unified MVC (model–view–controller) 6.",
    "link": "https://en.wikipedia.org/wiki/ASP.NET"
  },
  {
    "title": "Apache Cocoon",
    "slug": "apache-cocoon",
    "content": "Apache Cocoon, usually abbreviated as Cocoon, is a web application framework built around the concepts of Pipeline, separation of concerns, and component-based web development.  The framework focuses on XML and XSLT publishing and is built using the Java programming language.  Cocoon's use of XML is intended to improve compatibility of publishing formats, such as HTML and PDF. The content management systems Apache Lenya and Daisy have been created on top of the framework.  Cocoon is also commonly used as a data warehousing ETL tool or as middleware for transporting data between systems.",
    "link": "https://en.wikipedia.org/wiki/Apache_Cocoon"
  },
  {
    "title": "AppFuse",
    "slug": "appfuse",
    "content": "AppFuse was a full-stack framework for building web applications on the JVM. It was included in JBuilder.\nIn contrast to typical \"new project\" wizards, the AppFuse wizard generates multiple additional classes and files not only to implement various features but also to provide valuable examples for developers. This project comes pre-configured for database connectivity, appserver deployment, and user authentication, offering a ready-to-use framework for development.\nWhen AppFuse was first developed, it only supported Struts and Hibernate. In version 2.x, it supports Hibernate, iBATIS or JPA as persistence frameworks.  For implementing the MVC model, AppFuse is compatible with JSF, Spring MVC, Struts 2 or Tapestry.\nFeatures integrated into AppFuse includes the following:\n\nAuthentication and Authorization",
    "link": "https://en.wikipedia.org/wiki/AppFuse"
  },
  {
    "title": "Direct Web Remoting",
    "slug": "direct-web-remoting",
    "content": "Direct Web Remoting, or DWR, is a Java open-source library that helps developers write web sites that include Ajax technology. It allows code in a web browser to use Java functions running on a web server as if those functions were within the browser. The DWR project was started by Joe Walker in 2004, 1.0 released at August 29, 2005.",
    "link": "https://en.wikipedia.org/wiki/Direct_Web_Remoting"
  },
  {
    "title": "Apache Wicket",
    "slug": "apache-wicket",
    "content": "Apache Wicket, commonly referred to as Wicket, is a component-based web application framework for the Java programming language conceptually similar to JavaServer Faces and Tapestry.  It was originally written by Jonathan Locke in April 2004.  Version 1.0 was released in June 2005. It graduated into an Apache top-level project in June 2007.",
    "link": "https://en.wikipedia.org/wiki/Apache_Wicket"
  },
  {
    "title": "Apache Tapestry",
    "slug": "apache-tapestry",
    "content": "Apache Tapestry is an open-source component-oriented Java web application framework conceptually similar to JavaServer Faces and Apache Wicket. Tapestry was created by Howard Lewis Ship, and was adopted by the Apache Software Foundation as a top-level project in 2006.\nTapestry emphasizes simplicity, ease of use, and developer productivity. It adheres to the Convention over Configuration paradigm, eliminating almost all XML configuration. Tapestry uses a modular approach to web development by having a strong binding between each user interface component (object) on the web page and its corresponding Java class. This component-based architecture borrows many ideas from WebObjects.",
    "link": "https://en.wikipedia.org/wiki/Apache_Tapestry"
  },
  {
    "title": "Django (web framework)",
    "slug": "django-web-framework",
    "content": "Django ( JANG-goh; sometimes stylized as django) is a free and open-source, Python-based web framework that runs on a web server. It follows the model–template–views (MTV) architectural pattern. It is maintained by the Django Software Foundation (DSF), an independent organization established in the US as a 501(c)(3) non-profit.\nDjango's primary goal is to ease the creation of complex, database-driven websites. The framework emphasizes reusability and \"pluggability\" of components, less code, low coupling, rapid development, and the principle of don't repeat yourself. Python is used throughout, even for settings, files, and data models. Django also provides an optional administrative create, read, update and delete interface that is generated dynamically through introspection and configured via admin models.\nSome well-known sites that use Django include Instagram, Mozilla, Disqus, Bitbucket, Nextdoor, and Clubhouse.",
    "link": "https://en.wikipedia.org/wiki/Django_(web_framework)"
  },
  {
    "title": "Catalyst (software)",
    "slug": "catalyst-software",
    "content": "Catalyst is an open-source web application framework written in Perl. It closely follows the model–view–controller (MVC) architecture and supports a number of experimental web patterns. It is written using Moose, a modern object system for Perl. Its design is heavily inspired by frameworks such as Ruby on Rails, Maypole, and Spring.\nCatalyst can be used by web application developers to deal with code common to all web applications. It provides an interface for receiving page requests, dispatching page requests into developer-written code to process, and return of the requests. Catalyst also provides a standardised interface for data models, authentication, session management and other common web application elements.\nAll of these elements are implemented as plugins to a set of common interfaces, allowing the developer to change the specific method used (e.g. a session storing in shared memory versus as a database table, or using FastCGI versus operating as an within Apache's mod_perl) by changing the configuration of Catalyst to use a different plugin without altering the application code.\nCatalyst is primarily distributed through the CPAN, which is the official distribution channel for Perl libraries and applications.",
    "link": "https://en.wikipedia.org/wiki/Catalyst_(software)"
  },
  {
    "title": "Echo (framework)",
    "slug": "echo-framework",
    "content": "Echo is a web application framework created by the company NextApp. The latest iteration, Echo3, allows writing applications in either server-side Java or client-side JavaScript. Server-side applications do not require developer knowledge of HTML, HTTP, or JavaScript. Client-side JavaScript-based applications do not require a server, but can communicate with one via AJAX.\nIt is free software licensed under the terms of the Mozilla Public License (MPL).",
    "link": "https://en.wikipedia.org/wiki/Echo_(framework)"
  },
  {
    "title": "CakePHP",
    "slug": "cakephp",
    "content": "CakePHP is an open-source web framework. It follows the model–view–controller (MVC) approach and is written in PHP, modeled after the concepts of Ruby on Rails, and distributed under the MIT License.\nCakePHP uses well-known software engineering concepts and software design patterns, such as convention over configuration, model–view–controller, active record, association data mapping, and front controller.",
    "link": "https://en.wikipedia.org/wiki/CakePHP"
  },
  {
    "title": "Apache Shale",
    "slug": "apache-shale",
    "content": "Shale is a web application framework maintained by the Apache Software Foundation. It is fundamentally based on JavaServer Faces. As of May 2009 Apache Shale has been retired and moved to the Apache Attic.",
    "link": "https://en.wikipedia.org/wiki/Apache_Shale"
  },
  {
    "title": "ATL Server",
    "slug": "atl-server",
    "content": "ATL Server is a technology originally developed by Microsoft for developing web-based applications. It uses a tag replacement engine written in C++ to render web pages. It draws on the existing technologies like ISAPI and the Active Template Library, and includes a template library which is dedicated for use with developing Web-based applications.  \nATL Server first appeared with Visual Studio .NET 2003. It was included in Visual Studio 2005 but is no longer supported since the release of Visual Studio 2008. Most of the ATL Server code base has been released as a shared source project on CodePlex, a Microsoft-run code sharing web site.\nA typical ATL server application consists of at least one ISAPI extension DLL along with one or a number of Server Response Files (.srf) and their associated application DLL files which provide the application functionality.",
    "link": "https://en.wikipedia.org/wiki/ATL_Server"
  },
  {
    "title": "Comparison of server-side web frameworks",
    "slug": "comparison-of-serverside-web-frameworks",
    "content": "This is a comparison of notable web frameworks, software used to build and deploy web applications. This article focuses on frameworks used for building the backend.",
    "link": "https://en.wikipedia.org/wiki/Comparison_of_server-side_web_frameworks"
  },
  {
    "title": "Castle Project",
    "slug": "castle-project",
    "content": "Castle Project (or Castle for short) is an open-source application framework for CLI platform implementations (e.g., .NET Framework). It was released on November 6, 2014. The project was founded by a member of the Apache Avalon and the Apache Excalibur projects.",
    "link": "https://en.wikipedia.org/wiki/Castle_Project"
  },
  {
    "title": "Ext JS",
    "slug": "ext-js",
    "content": "Ext JS is a JavaScript application framework for building interactive cross-platform web applications using techniques such as Ajax, DHTML and DOM scripting. It can be used as a simple component framework (for example, to create dynamic grids on otherwise static pages) but also as a full framework for building single-page applications (SPAs).\nOriginally built as an add-on library extension of YUI by Jack Slocum on April 15, 2007, Ext JS has had no dependencies on external libraries beginning with version 1.1. Nowadays, Ext JS can be used both as a single script (with all classes and components in one file) or by building the application with the Sencha CMD.",
    "link": "https://en.wikipedia.org/wiki/Ext_JS"
  },
  {
    "title": "Barracuda (web framework)",
    "slug": "barracuda-web-framework",
    "content": "Barracuda MVC was an open-source web application framework for developing Java EE web applications that was an alternative to struts.  The project is no longer active.",
    "link": "https://en.wikipedia.org/wiki/Barracuda_(web_framework)"
  },
  {
    "title": "Jakarta EE",
    "slug": "jakarta-ee",
    "content": "Jakarta EE, formerly Java Platform, Enterprise Edition (Java EE) and Java 2 Platform, Enterprise Edition (J2EE), is a set of specifications, extending Java SE with specifications for enterprise features such as distributed computing and web services. Jakarta EE applications are run on reference runtimes, which can be microservices or application servers, which handle transactions, security, scalability, concurrency and management of the components they are deploying.\nJakarta EE is defined by its specification. The specification defines APIs (application programming interface) and their interactions. As with other Java Community Process specifications, providers must meet certain conformance requirements in order to declare their products as Jakarta EE compliant.\nExamples of contexts in which Jakarta EE referencing runtimes are used are: e-commerce, accounting, banking information systems.",
    "link": "https://en.wikipedia.org/wiki/Jakarta_EE"
  },
  {
    "title": "Plone (software)",
    "slug": "plone-software",
    "content": "Plone is a free and open source content management system (CMS) built on top of the Zope application server. Plone is positioned as an enterprise CMS and is commonly used for intranets and as part of the web presence of large organizations. High-profile public sector users include the U.S. Federal Bureau of Investigation, Brazilian Government, United Nations, City of Bern (Switzerland), New South Wales Government (Australia), and European Environment Agency. Plone's proponents cite its security track record and its accessibility as reasons to choose Plone.\nPlone has a long tradition of development occurring in so-called \"sprints\", in-person meetings of developers over the course of several days, the first occurring in 2003 and nine occurring in 2014. The largest sprint of the year is the sprint immediately following the annual conference. Certain other sprints are considered strategic so are funded directly by the Plone Foundation, although very few attendees are sponsored directly. The Plone Foundation also holds and enforces all copyrights and trademarks in Plone, and is assisted by legal counsel from the Software Freedom Law Center.",
    "link": "https://en.wikipedia.org/wiki/Plone_(software)"
  },
  {
    "title": "NumPy",
    "slug": "numpy",
    "content": "NumPy (pronounced  NUM-py) is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays. The predecessor of NumPy, Numeric, was originally created by Jim Hugunin with contributions from several other developers. In 2005, Travis Oliphant created NumPy by incorporating features of the competing Numarray into Numeric, with extensive modifications. NumPy is open-source software and has many contributors. NumPy is fiscally sponsored by NumFOCUS.",
    "link": "https://en.wikipedia.org/wiki/NumPy"
  },
  {
    "title": "PEAR",
    "slug": "pear",
    "content": "The PHP Extension and Application Repository, or PEAR, is a repository of PHP software code.  Stig S. Bakken founded the PEAR project in 1999 to promote the re-use of code that performs common functions. The project seeks to provide a structured library of code, maintain a system for distributing code and for managing code packages, and promote a standard coding style. Though community-driven, the PEAR project has a PEAR Group which serves as the governing body and takes care of administrative tasks. Each PEAR code package comprises an independent project under the PEAR umbrella.  It has its own development team, versioning-control and documentation.",
    "link": "https://en.wikipedia.org/wiki/PEAR"
  },
  {
    "title": "Oracle Application Express",
    "slug": "oracle-application-express",
    "content": "Oracle APEX (Oracle Application Express) is a low-code application development platform developed by Oracle Corporation. APEX is used for developing and deploying cloud, mobile and desktop applications. It has a web-based integrated development environment (IDE) that includes tools such as wizards, drag-and-drop layout builders, and property editors.",
    "link": "https://en.wikipedia.org/wiki/Oracle_Application_Express"
  },
  {
    "title": "IBM WebSphere Application Server",
    "slug": "ibm-websphere-application-server",
    "content": "WebSphere Application Server (WAS) is a software product that performs the role of a web application server. More specifically, it is a software framework and middleware that hosts Java-based web applications. It is the flagship product within IBM's WebSphere software suite. It was initially created by Donald F. Ferguson, who later became CTO of Software for Dell. The first version was launched in 1998. This project was an offshoot from IBM HTTP Server team starting with the Domino Go web server.",
    "link": "https://en.wikipedia.org/wiki/IBM_WebSphere_Application_Server"
  },
  {
    "title": "Horde (software)",
    "slug": "horde-software",
    "content": "Horde is a free web-based groupware. The components of this groupware rest on the Horde framework, a PHP-based framework provides all the elements required for rapid web application development. Horde offers applications such as the Horde IMP email client, a groupware package (calendar, notes, tasks, file manager), a wiki and a time and task tracking software.",
    "link": "https://en.wikipedia.org/wiki/Horde_(software)"
  },
  {
    "title": "Joomla",
    "slug": "joomla",
    "content": "Joomla (), also styled Joomla! (with an exclamation mark) and sometimes abbreviated as J!, is a free and open-source content management system (CMS) for publishing web content on websites. Web content applications include discussion forums, photo galleries, e-Commerce and user communities, and numerous other web-based applications. Joomla is developed by a community of volunteers supported with the legal, organisational and financial resources of Open Source Matters, Inc.\nJoomla is written in PHP, uses object-oriented programming techniques and simple software design patterns, and stores data in a Structured Query Language (MySQL/MariaDB) database. Joomla includes features such as page caching, RSS feeds, blogs, search, and support for language internationalisation. It is built on a model–view–controller web application framework that can be used independently of the CMS.\nAmong CMSes, Joomla ranks fifth or sixth in global market share.",
    "link": "https://en.wikipedia.org/wiki/Joomla"
  },
  {
    "title": "IBM WebSphere Application Server Community Edition",
    "slug": "ibm-websphere-application-server-community-edition",
    "content": "WebSphere Application Server Community Edition (WASCE) was a free-of-charge, certified Java EE 6 application server for building and managing Java applications. Until September 30, 2016, it was IBM's supported distribution of Apache Geronimo that used Tomcat for servlet container and Axis 2 for web services. Another difference from Apache Geronimo is that WASCE came with Db2 and Informix database drivers, better XML parser libraries (XML4J and XLXP) and contained the latest patches from unreleased upstream versions.\nOver 30 WASCE developers were committers in the Apache Geronimo project.",
    "link": "https://en.wikipedia.org/wiki/IBM_WebSphere_Application_Server_Community_Edition"
  },
  {
    "title": "List of Python software",
    "slug": "list-of-python-software",
    "content": "The Python programming language is actively used by many people, both in industry and academia, for a wide variety of purposes.",
    "link": "https://en.wikipedia.org/wiki/List_of_Python_software"
  },
  {
    "title": "Laminas",
    "slug": "laminas",
    "content": "Laminas Project (formerly Zend Framework or ZF) is an open source, object-oriented web application framework implemented in PHP 7 and licensed under the New BSD License. The framework is basically a collection of professional PHP-based packages. The framework uses various packages by the use of Composer as part of its package dependency managers; some of them are PHPUnit for testing all packages, Travis CI for continuous Integration Services. Laminas provides to users a support of the model–view–controller (MVC) in combination with Front Controller solution. MVC implementation in Laminas has five main areas. The router and dispatcher functions to decide which controller to run based on data from URL, and controller functions in combination with the model and view to develop and create the final web page.\nOn 17 April 2019 it was announced that the framework is transitioning into an open source project hosted by the Linux Foundation to be known as Laminas.",
    "link": "https://en.wikipedia.org/wiki/Laminas"
  },
  {
    "title": "Grails (framework)",
    "slug": "grails-framework",
    "content": "Grails is an open source web application framework that uses the Apache Groovy programming language (which is in turn based on the Java platform). It is intended to be a high-productivity framework by following the \"coding by convention\" paradigm, providing a stand-alone development environment and hiding much of the configuration detail from the developer.\nGrails was previously known as \"Groovy on Rails\"; in March 2006 that name was dropped in response to a request by David Heinemeier Hansson, founder of the Ruby on Rails framework. Work began in July 2005, with the 0.1 release on March 29, 2006, and the 1.0 release announced on February 18, 2008.",
    "link": "https://en.wikipedia.org/wiki/Grails_(framework)"
  },
  {
    "title": "JQuery",
    "slug": "jquery",
    "content": "jQuery is a JavaScript library designed to simplify HTML DOM tree traversal and manipulation, as well as event handling, CSS animations, and Ajax. It is free, open-source software using the permissive MIT License. As of August 2022, jQuery is used by 77% of the 10 million most popular websites. Web analysis indicates that it is the most widely deployed JavaScript library by a large margin, having at least three to four times more usage than any other JavaScript library.\njQuery's syntax is designed to make it easier to navigate a document, select DOM elements, create animations, handle events, and develop Ajax applications. jQuery also provides capabilities for developers to create plug-ins on top of the JavaScript library. This enables developers to create abstractions for low-level interaction and animation, advanced effects and high-level, theme-able widgets. The modular approach to the jQuery library allows the creation of powerful dynamic web pages and Web applications.\nThe set of jQuery core features—DOM element selections, traversal, and manipulation—enabled by its selector engine (named \"Sizzle\" from v1.3), created a new \"programming style\", fusing algorithms and DOM data structures. This style influenced the architecture of other JavaScript frameworks like YUI v3 and Dojo, later stimulating the creation of the standard Selectors API.\nMicrosoft and Nokia bundle jQuery on their platforms. Microsoft includes it with Visual Studio for use within Microsoft's ASP.NET AJAX and ASP.NET MVC frameworks while Nokia has integrated it into the Web Run-Time widget development platform.",
    "link": "https://en.wikipedia.org/wiki/JQuery"
  },
  {
    "title": "MooTools",
    "slug": "mootools",
    "content": "MooTools (My Object-Oriented Tools) is a lightweight, object-oriented JavaScript framework. It is released under the free, open-source MIT License.",
    "link": "https://en.wikipedia.org/wiki/MooTools"
  },
  {
    "title": "Pandesic",
    "slug": "pandesic",
    "content": "Pandesic ( pan-DESS-ik) was an Intel-SAP joint venture founded in August 1997 intended to sell software and hardware to support e-commerce. In July 2000, it was shut down after failing to find \"a timely road to profitability\".\nThe company's failings inspired a Harvard Business School case study.",
    "link": "https://en.wikipedia.org/wiki/Pandesic"
  },
  {
    "title": "JBoss Seam",
    "slug": "jboss-seam",
    "content": "Seam was a web application framework developed by JBoss, a division of Red Hat.",
    "link": "https://en.wikipedia.org/wiki/JBoss_Seam"
  },
  {
    "title": "Obidos (software)",
    "slug": "obidos-software",
    "content": "Obidos was the name used by Amazon.com for their original page rendering engine, and appears in many of their URLs such as https://www.amazon.com/exec/obidos/ASIN/0596515162. Obidos was phased out in 2006 and replaced by the Gurupa engine.\nAmazon.com subsequently used the name for their building at 551 Boren Ave N, Seattle, WA  98109, United States.\nIt was named after the town of Óbidos in Brazil near the swiftest point on the Amazon River, which is in turn named after the town of Óbidos, Portugal.",
    "link": "https://en.wikipedia.org/wiki/Obidos_(software)"
  },
  {
    "title": "Merb",
    "slug": "merb",
    "content": "Merb is a discontinued model–view–controller web framework in Ruby, notable as a precursor to Rails 3. It brought increased focus on speed and modularity to Rails 3. The name Merb is a contraction of \"Mongrel\" and \"Erb\".",
    "link": "https://en.wikipedia.org/wiki/Merb"
  },
  {
    "title": "Lift (web framework)",
    "slug": "lift-web-framework",
    "content": "Lift is a free and open-source web framework that is designed for the Scala programming language. It was originally created by David Pollak who was dissatisfied with certain aspects of the Ruby on Rails framework. Lift was launched as an open source project on 26 February 2007 under the Apache License 2.0. A commercially popular web platform often cited as being developed using Lift is Foursquare.",
    "link": "https://en.wikipedia.org/wiki/Lift_(web_framework)"
  },
  {
    "title": "ICEfaces",
    "slug": "icefaces",
    "content": "ICEfaces is an open-source Software development kit that extends JavaServer Faces (JSF) by employing Ajax.  It is used to construct rich Internet applications (RIA) using the Java programming language.  With ICEfaces, the coding for interaction and Ajax on the client side is programmed in Java, rather than in JavaScript, or with plug-ins.",
    "link": "https://en.wikipedia.org/wiki/ICEfaces"
  },
  {
    "title": "Database",
    "slug": "database",
    "content": "In computing, a database is an organized collection of data or a type of data store based on the use of a database management system (DBMS), the software that interacts with end users, applications, and the database itself to capture and analyze the data. The DBMS additionally encompasses the core facilities provided to administer the database. The sum total of the database, the DBMS and the associated applications can be referred to as a database system. Often the term \"database\" is also used loosely to refer to any of the DBMS, the database system or an application associated with the database.\nBefore digital storage and retrieval of data became widespread, index cards were used for data storage in a wide range of applications and environments: in the home to record and store recipes, shopping lists, contact information and other organizational data; in business to record presentation notes, project research and notes, and contact information; in schools as flash cards or other visual aids; and in academic research to hold data such as bibliographical citations or notes in a card file. Professional book indexers used index cards in the creation of book indexes until they were replaced by indexing software in the 1980s and 1990s.\nSmall databases can be stored on a file system, while large databases are hosted on computer clusters or cloud storage. The design of databases spans formal techniques and practical considerations, including data modeling, efficient data representation and storage, query languages, security and privacy of sensitive data, and distributed computing issues, including supporting concurrent access and fault tolerance.\nComputer scientists may classify database management systems according to the database models that they support. Relational databases became dominant in the 1980s. These model data as rows and columns in a series of tables, and the vast majority use SQL for writing and querying data. In the 2000s, non-relational databases became popular, collectively referred to as NoSQL, because they use different query languages.",
    "link": "https://en.wikipedia.org/wiki/Database"
  },
  {
    "title": "SciPy",
    "slug": "scipy",
    "content": "SciPy (pronounced  \"sigh pie\") is a free and open-source Python library used for scientific computing and technical computing.\nSciPy contains modules for optimization, linear algebra, integration, interpolation, special functions, fast Fourier transform, signal and image processing, ordinary differential equation solvers and other tasks common in science and engineering.\nSciPy is also a family of conferences for users and developers of these tools: SciPy (in the United States), EuroSciPy (in Europe) and SciPy.in (in India). Enthought originated the SciPy conference in the United States and continues to sponsor many of the international conferences as well as host the SciPy website.\nThe SciPy library is currently distributed under the BSD license, and its development is sponsored and supported by an open community of developers. It is also supported by NumFOCUS, a community foundation for supporting reproducible and accessible science.",
    "link": "https://en.wikipedia.org/wiki/SciPy"
  },
  {
    "title": "WebObjects",
    "slug": "webobjects",
    "content": "WebObjects is a discontinued Java web application server and a server-based web application framework originally developed by NeXT Software, Inc.\nWebObject's hallmark features are its object-orientation, database connectivity, and prototyping tools. Applications created with WebObjects can be deployed as web sites, Java WebStart desktop applications, and/or standards-based web services.\nThe deployment runtime is pure Java, allowing developers to deploy WebObjects applications on platforms that support Java. One can use the included WebObjects Java SE application server or deploy on third-party Java EE application servers such as JBoss, Apache Tomcat, WebLogic Server or IBM WebSphere.\nWebObjects was maintained by Apple until its official discontinuation in 2016. However, because Apple has stopped maintaining the software, it now is instead maintained by an online community of volunteers. This community calls it \"Project Wonder\".",
    "link": "https://en.wikipedia.org/wiki/WebObjects"
  },
  {
    "title": "XOOPS",
    "slug": "xoops",
    "content": "XOOPS  is a free open-source content management system (CMS), written in PHP. It uses a modular architecture allowing users to customize, update and theme their websites. XOOPS is released under the terms of the GNU General Public License (GPL) and is free to use, modify and redistribute.",
    "link": "https://en.wikipedia.org/wiki/XOOPS"
  },
  {
    "title": "Ruby on Rails",
    "slug": "ruby-on-rails",
    "content": "Ruby on Rails (simplified as Rails) is a server-side web application framework written in Ruby under the MIT License. Rails is a model–view–controller (MVC) framework, providing default structures for a database, a web service, and web pages. It encourages and facilitates the use of web standards such as JSON or XML for data transfer and HTML, CSS and JavaScript for user interfacing. In addition to MVC, Rails emphasizes the use of other well-known software engineering patterns and paradigms, including convention over configuration (CoC), don't repeat yourself (DRY), and the active record pattern.\nRuby on Rails' emergence in 2005 greatly influenced web app development, through innovative features such as seamless database table creations, migrations, and scaffolding of views to enable rapid application development. Ruby on Rails' influence on other web frameworks remains apparent today, with many frameworks in other languages borrowing its ideas, including Django in Python; Catalyst in Perl; Laravel, CakePHP and Yii  in PHP; Grails in Groovy; Phoenix in Elixir; Play in Scala; and Sails.js in Node.js.\nWell-known sites that use Ruby on Rails include Airbnb, Archive of Our Own, Crunchbase, Dribbble, GitHub, Twitch and Shopify.",
    "link": "https://en.wikipedia.org/wiki/Ruby_on_Rails"
  },
  {
    "title": "Database dump",
    "slug": "database-dump",
    "content": "A database dump contains a record of the table structure and/or the data from a database and is usually in the form of a list of SQL statements (\"SQL dump\"). A database dump is most often used for backing up a database so that its contents can be restored in the event of data loss. Corrupted databases can often be recovered by analysis of the dump. Database dumps are often published by free content projects, to facilitate reuse, forking, offline use, and long-term digital preservation.\nDumps can be transported into environments with Internet blackouts or otherwise restricted Internet access, as well as facilitate local searching of the database using sophisticated tools such as grep.",
    "link": "https://en.wikipedia.org/wiki/Database_dump"
  },
  {
    "title": "Solution stack",
    "slug": "solution-stack",
    "content": "In computing, a solution stack, also called software stack and tech stack is a set of software subsystems or components needed to create a complete platform such that no additional software is needed to support applications. Applications are said to “run on” or “run on top of” the resulting platform.\nFor example, to develop a web application, the architect defines the stack as the target operating system, web server, database, and programming language. Another version of a software stack is operating system, middleware, database, and applications. Regularly, the components of a software stack are developed by different developers independently of one another.\nSome components/subsystems of an overall system are chosen together often enough that the particular set is referred to by a name representing the whole, rather than by naming the parts. Typically, the name is an acronym representing the individual components.\nThe term “solution stack” has, historically, occasionally included hardware components as part of a final product, mixing both the hardware and software in layers of support.\nA full-stack developer is expected to be able to work in all the layers of the application (front-end and back-end). A full-stack developer can be defined as a developer or an engineer who works with both the front and back end development of a website, web application or desktop application. This means they can lead platform builds that involve databases, user-facing websites, and working with clients during the planning phase of projects.",
    "link": "https://en.wikipedia.org/wiki/Solution_stack"
  },
  {
    "title": "Catalog server",
    "slug": "catalog-server",
    "content": "A catalog server provides a single point of access that allows users to centrally search for information across a distributed network. In other words, it indexes databases, files and information across large network and allows keywords, Boolean and other searches. If you need to provide a comprehensive searching service for your intranet, extranet or even the Internet, a catalog server is a standard solution.",
    "link": "https://en.wikipedia.org/wiki/Catalog_server"
  },
  {
    "title": "Symfony",
    "slug": "symfony",
    "content": "Symfony is a free and open-source PHP web application framework and a set of reusable PHP component libraries. It was published as free software on October 18, 2005, and released under the MIT License.",
    "link": "https://en.wikipedia.org/wiki/Symfony"
  },
  {
    "title": "Commitment ordering",
    "slug": "commitment-ordering",
    "content": "Commitment ordering (CO) is a class of interoperable serializability techniques in concurrency control of databases, transaction processing, and related applications. It allows optimistic (non-blocking) implementations. With the proliferation of multi-core processors, CO has also been increasingly utilized in concurrent programming, transactional memory, and software transactional memory (STM) to achieve serializability optimistically. CO is also the name of the resulting transaction schedule (history) property, defined in 1988 with the name dynamic atomicity. In a CO compliant schedule, the chronological order of commitment events of transactions is compatible with the precedence order of the respective transactions. CO is a broad special case of conflict serializability and effective means (reliable, high-performance, distributed, and scalable) to achieve global serializability (modular serializability) across any collection of database systems that possibly use different concurrency control mechanisms (CO also makes each system serializability compliant, if not already).\nEach not-CO-compliant database system is augmented with a CO component (the commitment order coordinator—COCO) which orders the commitment events for CO compliance, with neither data-access nor any other transaction operation interference. As such, CO provides a low overhead, general solution for global serializability (and distributed serializability), instrumental for global concurrency control (and distributed concurrency control) of multi-database systems and other transactional objects, possibly highly distributed (e.g., within cloud computing, grid computing, and networks of smartphones). An atomic commitment protocol (ACP; of any type) is a fundamental part of the solution, utilized to break global cycles in the conflict (precedence, serializability) graph. CO is the most general property (a necessary condition) that guarantees global serializability, if the database systems involved do not share concurrency control information beyond atomic commitment protocol (unmodified) messages and have no knowledge of whether transactions are global or local (the database systems are autonomous). Thus CO (with its variants) is the only general technique that does not require the typically costly distribution of local concurrency control information (e.g., local precedence relations, locks, timestamps, or tickets). It generalizes the popular strong strict two-phase locking (SS2PL) property, which in conjunction with the two-phase commit protocol (2PC), is the de facto standard to achieve global serializability across (SS2PL based) database systems. As a result, CO compliant database systems (with any different concurrency control types) can transparently join such SS2PL based solutions for global serializability.\nIn addition, locking based global deadlocks are resolved automatically in a CO based multi-database environment, a vital side-benefit (including the special case of a completely SS2PL based environment; a previously unnoticed fact for SS2PL).\nFurthermore, strict commitment ordering (SCO; Raz 1991c), the intersection of Strictness and CO, provides better performance (shorter average transaction completion time and resulting in better transaction throughput) than SS2PL whenever read-write conflicts are present (identical blocking behavior for write-read and write-write conflicts; comparable locking overhead). The advantage of SCO is especially during lock contention. Strictness allows both SS2PL and SCO to use the same effective database recovery mechanisms.\nTwo major generalizing variants of CO exist, extended CO (ECO; Raz 1993a) and multi-version CO (MVCO; Raz 1993b). They also provide global serializability without local concurrency control information distribution, can be combined with any relevant concurrency control, and allow optimistic (non-blocking) implementations. Both use additional information for relaxing CO constraints and achieving better concurrency and performance. Vote ordering (VO or Generalized CO (GCO); Raz 2009) is a container schedule set (property) and technique for CO and all its variants. Local VO is necessary for guaranteeing global serializability if the atomic commitment protocol (ACP) participants do not share concurrency control information (have the generalized autonomy property). CO and its variants inter-operate transparently, guaranteeing global serializability and automatic global deadlock resolution together in a mixed, heterogeneous environment with different variants.",
    "link": "https://en.wikipedia.org/wiki/Commitment_ordering"
  },
  {
    "title": "Spring Framework",
    "slug": "spring-framework",
    "content": "The Spring Framework is an application framework and inversion of control container for the Java platform. The framework's core features can be used by any Java application, but there are extensions for building web applications on top of the Jakarta EE platform. The framework does not impose any specific programming model. The framework has become popular in the Java community as an addition to the Enterprise JavaBeans (EJB) model. The Spring Framework is free and open source software.",
    "link": "https://en.wikipedia.org/wiki/Spring_Framework"
  },
  {
    "title": "Seaside (software)",
    "slug": "seaside-software",
    "content": "Seaside, an acronym that stands for “Squeak Enterprise Aubergines Server with Integrated Development Environment,” is computer software, a web framework to develop web applications in the programming language Smalltalk. It is distributed as free and open-source software under an MIT License.\nSeaside provides a component architecture in which web pages are built as trees of individual, stateful components, each encapsulating a small part of a page. Seaside uses continuations to model multiple independent flows between different components. Thus, it is a continuation-based web framework based on the ability to manipulate the execution stack of some implementations of Smalltalk.",
    "link": "https://en.wikipedia.org/wiki/Seaside_(software)"
  },
  {
    "title": "Stripes (framework)",
    "slug": "stripes-framework",
    "content": "Stripes is an open source web application framework based on the model–view–controller (MVC) pattern. It aims to be a lighter weight framework than Struts by using Java technologies such as annotations and generics that were introduced in Java 1.5, to achieve \"convention over configuration\". This emphasizes the idea that a set of simple conventions used throughout the framework reduce configuration overhead. In practice, this means that Stripe applications barely need any configuration files, thus reducing development and maintenance work. It has been dormant since 2016.",
    "link": "https://en.wikipedia.org/wiki/Stripes_(framework)"
  },
  {
    "title": "Qcodo",
    "slug": "qcodo",
    "content": "Qcodo is an open-source PHP web application framework which builds an object-relational model (ORM), CRUD (create, retrieve, update, delete) UI pages, and AJAX hooks from an existing data model. It additionally includes a tightly integrated HTML and JavaScript form toolkit which interfaces directly with the generated entities. It is a robust, comprehensive framework which can be utilized by small and large Web applications alike.",
    "link": "https://en.wikipedia.org/wiki/Qcodo"
  },
  {
    "title": "Silverstripe CMS",
    "slug": "silverstripe-cms",
    "content": "Silverstripe CMS is a free and open source content management system (CMS) and framework for creating and maintaining websites and web applications. It provides an out of the box web-based administration panel that enables users to make modifications to parts of the website, which includes a WYSIWYG website editor. The core of the software is Silverstripe Framework, a PHP Web application framework.\nSilverstripe CMS is released under the terms of the BSD License.",
    "link": "https://en.wikipedia.org/wiki/Silverstripe_CMS"
  },
  {
    "title": "Sun Web Developer Pack",
    "slug": "sun-web-developer-pack",
    "content": "The Sun Web Developer Pack (SWDP) is a collection of open source software released by Sun Microsystems for developing web applications that run on Java EE application servers. The SWDP is targeted at software developers interested in writing web applications that use Web 2.0 technologies such as Ajax, REST, Atom, and JavaScript.",
    "link": "https://en.wikipedia.org/wiki/Sun_Web_Developer_Pack"
  },
  {
    "title": "Central Equipment Identity Register",
    "slug": "central-equipment-identity-register",
    "content": "A Central Equipment Identity Register (CEIR) is a database of mobile equipment identifiers (IMEI – for networks of GSM standard, MEID – for networks of CDMA standard). Such an identifier is assigned to each SIM slot of the mobile device. Different kinds of IMEIs could be, White, for devices that are allowed to register in the cellular network; Black, for devices that are prohibited to register in the cellular network; and Grey, for devices in intermediate status (when it is not yet defined in which of the lists - black or white - the device should be placed).\nDepending on the rules of mobile equipment registration in a country the CEIR database may contain other lists or fields beside IMEI. For example, the subscriber number (MSISDN), which is bound to the IMEI, the ID of the individual (passport data, National ID, etc.) who registered IMEI in the database, details of the importer who brought the device into the country, etc.",
    "link": "https://en.wikipedia.org/wiki/Central_Equipment_Identity_Register"
  },
  {
    "title": "WebSphere sMash",
    "slug": "websphere-smash",
    "content": "WebSphere sMash was a development and runtime environment from IBM for the creation of dynamic web applications using the scripting languages Apache Groovy and PHP. It contained a PHP runtime written in Java.\nProject Zero was the experimental software development community in which new versions of WebSphere sMash were incubated. WebSphere sMash was withdrawn from sale in 2012, with support discontinued in 2014.\nWebSphere Smash integrated with Eclipse and produced REST-style services on top of Groovy or PHP\n.",
    "link": "https://en.wikipedia.org/wiki/WebSphere_sMash"
  },
  {
    "title": "WaveMaker",
    "slug": "wavemaker",
    "content": "WaveMaker is a Java-based low-code development platform designed for building software applications and platforms. The company, WaveMaker Inc., is based in Mountain View, California. The platform is intended to assist enterprises in speeding up their application development and IT modernization initiatives through low-code capabilities. Additionally, for independent software vendors (ISVs), WaveMaker serves as a customizable low-code component that integrates into their products.\nThe WaveMaker Platform is a licensed software platform allowing organizations to establish their own end-to-application platform-as-a-service (PaaS) for the creation and operation of custom apps. It allows developers and business users to create apps that are customizable. These applications can seamlessly consume APIs, visualize data, and automatically adapt to multi-device responsive interfaces.\nWaveMaker's low-code platform allows organizations to deploy applications on either public or private cloud infrastructure. Containers can be deployed on top of virtual machines or directly on bare metal. The software features a graphical user interface (GUI) console for managing IT app infrastructure, leveraging the capabilities of Docker containerization.\nThe solution offers functionalities for automating application deployment, managing the application lifecycle, overseeing release management, and controlling deployment workflows and access permissions:\n\nApps for web, tablet, and smartphone interfaces\nEnterprise technologies like Java, Hibernate, Spring, AngularJS, JQuery\nDocker-provided APIs and CLI\nSoftware stack packaging, container provisioning, stack and app upgrading, replication, and fault tolerance",
    "link": "https://en.wikipedia.org/wiki/WaveMaker"
  },
  {
    "title": "Concurrency control",
    "slug": "concurrency-control",
    "content": "In information technology and computer science,  especially in the fields of computer programming, operating systems, multiprocessors, and databases, concurrency control ensures that correct results for concurrent operations are generated, while getting those results as quickly as possible.\nComputer systems, both software and hardware, consist of modules, or components. Each component is designed to operate correctly, i.e., to obey or to meet certain consistency rules. When components that operate concurrently interact by messaging or by sharing accessed data (in memory or storage), a certain component's consistency may be violated by another component. The general area of concurrency control provides rules, methods, design methodologies, and theories to maintain the consistency of components operating concurrently while interacting, and thus the consistency and correctness of the whole system. Introducing concurrency control into a system means applying operation constraints which typically result in some performance reduction. Operation consistency and correctness should be achieved with as good as possible efficiency, without reducing performance below reasonable levels. Concurrency control can require significant additional complexity and overhead in a concurrent algorithm compared to the simpler sequential algorithm.\nFor example, a failure in concurrency control can result in data corruption from torn read or write operations.",
    "link": "https://en.wikipedia.org/wiki/Concurrency_control"
  },
  {
    "title": "Foreign key",
    "slug": "foreign-key",
    "content": "A foreign key is a set of attributes in a table that refers to the primary key of another table, linking these two tables. In the context of relational databases, a foreign key is subject to an inclusion dependency constraint that the tuples consisting of the foreign key attributes in one relation, R, must also exist in some other (not necessarily distinct) relation, S; furthermore that those attributes must also be a candidate key in S.\nIn other words, a foreign key is a set of attributes that references a candidate key. For example, a table called TEAM may have an attribute, MEMBER_NAME, which is a foreign key referencing a candidate key, PERSON_NAME, in the PERSON table. Since MEMBER_NAME is a foreign key, any value existing as the name of a member in TEAM must also exist as a person's name in the PERSON table; in other words, every member of a TEAM is also a PERSON.",
    "link": "https://en.wikipedia.org/wiki/Foreign_key"
  },
  {
    "title": "Database transaction schedule",
    "slug": "database-transaction-schedule",
    "content": "In the fields of databases and transaction processing (transaction management), a schedule (or history) of a system is an abstract model to describe the order of executions in a set of transactions running in the system. Often it is a list of operations (actions) ordered by time, performed by a set of transactions that are executed together in the system. If the order in time between certain operations is not determined by the system, then a partial order is used. Examples of such operations are requesting a read operation, reading, writing, aborting, committing, requesting a lock, locking, etc. Often, only a subset of the transaction operation types are included in a schedule. \nSchedules are fundamental concepts in database concurrency control theory. In practice, most general purpose database systems employ conflict-serializable and strict recoverable schedules.",
    "link": "https://en.wikipedia.org/wiki/Database_transaction_schedule"
  },
  {
    "title": "Database design",
    "slug": "database-design",
    "content": "Database design is the organization of data according to a database model. The designer determines what data must be stored and how the data elements interrelate. With this information, they can begin to fit the data to the database model. A database management system manages the data accordingly.\nDatabase design is a process that consists of several steps.",
    "link": "https://en.wikipedia.org/wiki/Database_design"
  },
  {
    "title": "IDMS",
    "slug": "idms",
    "content": "The Integrated Database Management System (IDMS)  is a network model (CODASYL) database management system for mainframes. It was first developed at BFGoodrich and later marketed by Cullinane Database Systems (renamed Cullinet in 1983). Since 1989 the product has been owned by Computer Associates (now CA Technologies), who renamed it Advantage CA-IDMS and later simply to CA IDMS. In 2018 Broadcom acquired CA Technologies, renaming it back to IDMS.",
    "link": "https://en.wikipedia.org/wiki/IDMS"
  },
  {
    "title": "Data store",
    "slug": "data-store",
    "content": "A  data store is a repository for persistently storing and managing collections of data which include not just repositories like databases, but also simpler store types such as simple files, emails, etc.\nA database is a collection of data that is managed by a database management system (DBMS), though the term can sometime more generally refer to any collection of data that is stored and accessed electronically. A file is a series of bytes that is managed by a file system. Thus, any database or file is a series of bytes that, once stored, is called a data store.\nMATLAB and Cloud Storage systems like VMware, Firefox OS use datastore as a term for abstracting collections of data inside their respective applications.",
    "link": "https://en.wikipedia.org/wiki/Data_store"
  },
  {
    "title": "Database publishing",
    "slug": "database-publishing",
    "content": "Database publishing is an area of automated media production in which specialized techniques are used to generate paginated documents from source data residing in traditional databases such as product information management (PIM), digital asset management (DAM), and enterprise resource planning (ERP) platforms. Common examples are mail order catalogues, direct marketing, report generation, price lists and telephone directories. The database content can be in the form of text and pictures but can also contain metadata related to formatting and special rules that may apply to the document generation process. Database publishing can be incorporated into larger workflows as a component, where documents are created, approved, revised and released.\nThe basic idea is using database contents like product information, article and price information to fill out pre-formatted template documents. Templates are typically created in a normal desktop layout application where certain boxes or text are designated as placeholders. These placeholders are then targeted with new content which flows in from the database. This allows for quick generation of final output and, in case of changes to the database, quickly perform updates, with limited or no manual intervention. This process is facilitated by specialized software solutions that automate the integration of database content into templates, like InBetween software solution. Such software automates the creation of documents such as catalogs and price lists by integrating product data from various sources.\nAnother model of database publishing is found in many web-to-print sites where users browse templates from an online catalog (such as business cards or brochures), personalize the selected template by filling in a form and then view the rendered result. In this case the initial source of data is from user input, but it is captured in a database so that if the same user revisits the site later, they can resume editing where they left off. The form is then pre-filled from the database-stored variables the user entered before.\nThe main layout applications for this workflow are Datalogics Pager, Adobe FrameMaker / InDesign, QuarkXPress, Xyvision, Arbortext Advanced Print Publisher (formerly 3B2) and priint:suite. Generally, these layout applications have a corresponding server version, which receives commands via web interfaces rather than desktop interaction. QuarkXPress Server and Adobe InDesign Server both take full advantage of the design features available in their respective desktop versions.\nThese applications make their broad spectrum of features available for extension and integration with vertical products, that can be developed either internally, through some form of scripting (e.g. JavaScript or AppleScript for InDesign), or externally, through some API and corresponding developer kits.\nOther variants of database publishing are the rendering of content for direct PDF output. This approach prevents manual intervention on the final output, since PDF is not (comfortably) editable. This may not be perceived as a limitation in situations like report generation where manual editability is not needed or not desired.",
    "link": "https://en.wikipedia.org/wiki/Database_publishing"
  },
  {
    "title": "Data access layer",
    "slug": "data-access-layer",
    "content": "A data access layer (DAL) in computer software is a layer of a computer program which provides simplified access to data stored in persistent storage of some kind, such as an entity-relational database. This acronym is prevalently used in Microsoft environments.\nFor example, the DAL might return a reference to an object (in terms of object-oriented programming) complete with its attributes instead of a row of fields from a database table.  This allows the client (or user) modules to be created with a higher level of abstraction.  This kind of model could be implemented by creating a class of data access methods that directly reference a corresponding set of database stored procedures. Another implementation could potentially retrieve or write records to or from a file system. The DAL hides this complexity of the underlying data store from the external world.\nFor example, instead of using commands such as insert, delete, and update to access a specific table in a database, a class and a few stored procedures could be created in the database.  The procedures would be called from a method inside the class, which would return an object containing the requested values.  Or, the insert, delete and update commands could be executed within simple functions like registeruser or loginuser stored within the data access layer.\nAlso, business logic methods from an application can be mapped to the data access layer. So, for example, instead of making a query into a database to fetch all users from several tables, the application can call a single method from a DAL which abstracts those database calls.\nApplications using a data access layer can be either database server dependent or independent. If the data access layer supports multiple database types, the application becomes able to use whatever databases the DAL can talk to.  In either circumstance, having a data access layer provides a centralized location for all calls into the database, and thus makes it easier to port the application to other database systems (assuming that 100% of the database interaction is done in the DAL for a given application).\nObject–relational mapping (ORM) tools provide data layers in this fashion, following the Active Record or Data Mapper patterns. The ORM/active-record model is popular with web frameworks.",
    "link": "https://en.wikipedia.org/wiki/Data_access_layer"
  },
  {
    "title": "Database machine",
    "slug": "database-machine",
    "content": "A database machines or back end processor is a computer or special hardware that stores and retrieves data from a database. It is specially designed for database access and is tightly coupled to the main (front-end) computer(s) by a high-speed channel, whereas a database server is a general-purpose computer that holds a database and it's loosely coupled via a local area network to its clients.\nDatabase machines can retrieve large amount of data using hundreds to thousands of microprocessors with database software. The front end processor asks the back end (typically sending a query expressed in a query language) the data and further processes it. The back end processor on the other hand analyzes and stores the data from the front end processor. Back end processors result in higher performance, increasing host main memory, increasing database recovery and security, and decreasing cost to manufacture.",
    "link": "https://en.wikipedia.org/wiki/Database_machine"
  },
  {
    "title": "Data redundancy",
    "slug": "data-redundancy",
    "content": "In computer main memory, auxiliary storage and computer buses, data redundancy is the existence of data that is additional to the actual data and permits correction of errors in stored or transmitted data. The additional data can simply be a complete copy of the actual data (a type of repetition code), or only select pieces of data that allow detection of errors and reconstruction of lost or damaged data up to a certain level.\nFor example, by including computed check bits, ECC memory is capable of detecting and correcting single-bit errors within each memory word, while RAID 1 combines two hard disk drives (HDDs) into a logical storage unit that allows stored data to survive a complete failure of one drive.  Data redundancy can also be used as a measure against silent data corruption; for example, file systems such as Btrfs and ZFS use data and metadata checksumming in combination with copies of stored data to detect silent data corruption and repair its effects.",
    "link": "https://en.wikipedia.org/wiki/Data_redundancy"
  },
  {
    "title": "Database refactoring",
    "slug": "database-refactoring",
    "content": "A database refactoring is a simple change to a database schema that improves its design while retaining both its behavioral and informational semantics.  Database refactoring does not change the way data is interpreted or used and does not fix bugs or add new functionality.  Every refactoring to a database leaves the system in a working state, thus not causing maintenance lags, provided the meaningful data exists in the production environment.   \nA database refactoring is conceptually more difficult than a code refactoring; code refactorings only need to maintain behavioral semantics while database refactorings also must maintain informational semantics.\nA database schema is typically refactored for one of several reasons:\n\nTo develop the schema in an evolutionary manner in parallel with the evolutionary design of the rest of the system.\nTo fix design problems with an existing legacy database schema. Database refactorings are often motivated by the desire for database normalization of an existing production database, typically to \"clean up\" the design of the database.\nTo implement what would be a large (and potentially risky) change as a series of small, low-risk changes.",
    "link": "https://en.wikipedia.org/wiki/Database_refactoring"
  },
  {
    "title": "Database connection",
    "slug": "database-connection",
    "content": "A database connection is a facility in computer science that allows client software to talk to database server software, whether on the same machine or not.  A connection is required to send commands and receive answers, usually in the form of a result set.\nConnections are a key concept in data-centric programming. Since some DBMS engines require considerable time to connect, connection pooling was invented to improve performance.  No command can be performed against a database without an \"open and available\" connection to it.\nConnections are built by supplying an underlying driver or provider with a connection string, which is a way of addressing a specific database or server and instance as well as user authentication credentials (for example, Server=sql_box;Database=Common;User ID=uid;Pwd=password;).  Once a connection has been built it can be opened and closed at will, and properties (such as the command time-out length, or transaction, if one exists) can be set. The Connection String is composed of a set of key/value pairs as dictated by the data access interface and data provider being used.\nMany databases (such as PostgreSQL) only allow one operation to be performed at a time on each connection.  If a request for data (a SQL Select statement) is sent to the database and a result set is returned, the connection is open but not available for other operations until the client finishes consuming the result set. Other databases, like SQL Server 2005 (and later), do not impose this limitation. However, databases that provide multiple operations per connection usually incur far more overhead than those that permit only a single operation task at a time.",
    "link": "https://en.wikipedia.org/wiki/Database_connection"
  },
  {
    "title": "Identity column",
    "slug": "identity-column",
    "content": "An identity column is a column (also known as a field) in a database table that is made up of values generated by the database.  This is much like an AutoNumber field in Microsoft Access or a sequence in Oracle.  Because the concept is so important in database science, many RDBMS systems implement some type of generated key, although each has its own terminology. Today a popular technique for generating identity is to generate a random UUID. \nAn identity column differs from a primary key in that its values are managed by the server and usually cannot be modified.  In many cases an identity column is used as a primary key; however, this is not always the case.\nIt is a common misconception that an identity column will enforce uniqueness; however, this is not the case. If you want to enforce uniqueness on the column you must include the appropriate constraint too.\nIn Microsoft SQL Server you have options for both the seed (starting value) and the increment. By default the seed and increment are both 1.",
    "link": "https://en.wikipedia.org/wiki/Identity_column"
  },
  {
    "title": "Event condition action",
    "slug": "event-condition-action",
    "content": "Event condition action (ECA) is a short-cut for referring to the structure of active rules in event-driven architecture and active database systems.\nSuch a rule traditionally consisted of three parts:\n\nThe event part specifies the signal that triggers the invocation of the rule\nThe condition part is a logical test that, if satisfied or evaluates to true, causes the action to be carried out\nThe action part consists of updates or invocations on the local data\nThis structure was used by the early research in active databases which started to use the term ECA. Current state of the art ECA rule engines use many variations on rule structure. Also other features not considered by the early research is introduced, such as strategies for event selection into the event part.\nIn a memory-based rule engine, the condition could be some tests on local data and actions could be updates to object attributes. In a database system, the condition could simply be a query to the database, with the result set (if not null) being passed to the action part for changes to the database. In either case, actions could also be calls to external programs or remote procedures.\nNote that for database usage, updates to the database are regarded as internal events. As a consequence, the execution of the action part of an active rule can match the event part of the same or another active rule, thus triggering it. The equivalent in a memory-based rule engine would be to invoke an external method that caused an external event to trigger another ECA rule. \nECA rules can also be used in rule engines that use variants of the Rete algorithm for rule processing.",
    "link": "https://en.wikipedia.org/wiki/Event_condition_action"
  },
  {
    "title": "DUAL table",
    "slug": "dual-table",
    "content": "The DUAL table is a special one-row, one-column table present by default in Oracle and other database installations. In Oracle, the table has a single VARCHAR2(1) column called DUMMY that has a value of 'X'. It is suitable for use in selecting a pseudo column such as SYSDATE or USER.",
    "link": "https://en.wikipedia.org/wiki/DUAL_table"
  },
  {
    "title": "Connection string",
    "slug": "connection-string",
    "content": "In computing, a connection string is a string that specifies information about a data source and the means of connecting to it. It is passed in code to an underlying driver or provider in order to initiate the connection. Whilst commonly used for a database connection, the data source could also be a spreadsheet or text file.\nThe connection string may include attributes such as the name of the driver, server and database, as well as security information such as user name and password.",
    "link": "https://en.wikipedia.org/wiki/Connection_string"
  },
  {
    "title": "Data administration",
    "slug": "data-administration",
    "content": "Data administration or data resource management is an organizational function working in the areas of information systems and computer science that plans, organizes, describes and controls data resources. Data resources are usually stored in databases under a database management system or other software such as electronic spreadsheets. In many smaller organizations, data administration is performed occasionally, or is a small component of the database administrator’s work.\nIn the context of information systems development, data administration ideally begins at system conception, ensuring there is a data dictionary to help maintain consistency, avoid redundancy, and model the database so as to make it logical and usable, by means of data modeling, including database normalization techniques.",
    "link": "https://en.wikipedia.org/wiki/Data_administration"
  },
  {
    "title": "Global serializability",
    "slug": "global-serializability",
    "content": "In concurrency control of databases, transaction processing (transaction management), and other transactional distributed applications, global serializability (or modular serializability) is a property of a global schedule of transactions. A global schedule is the unified schedule of all the individual database (and other transactional object) schedules in a multidatabase environment (e.g., federated database). Complying with global serializability means that the global schedule is serializable, has the serializability property, while each component database (module) has a serializable schedule as well. In other words, a collection of serializable components provides overall system serializability, which is usually incorrect. A need in correctness across databases in multidatabase systems makes global serializability a major goal for global concurrency control (or modular concurrency control). With the proliferation of the Internet, Cloud computing, Grid computing, and small, portable, powerful computing devices (e.g., smartphones), as well as increase in systems management sophistication, the need for atomic distributed transactions and thus effective global serializability techniques, to ensure correctness in and among distributed transactional applications, seems to increase.\nIn a federated database system or any other more loosely defined multidatabase system, which are typically distributed in a communication network, transactions span multiple (and possibly distributed) databases. Enforcing global serializability in such system, where different databases may use different types of concurrency control, is problematic. Even if every local schedule of a single database is serializable, the global schedule of a whole system is not necessarily serializable. The massive communication exchanges of conflict information needed between databases to reach conflict serializability globally would lead to unacceptable performance, primarily due to computer and communication latency. Achieving global serializability effectively over different types of concurrency control has been open for several years.",
    "link": "https://en.wikipedia.org/wiki/Global_serializability"
  },
  {
    "title": "Distributed concurrency control",
    "slug": "distributed-concurrency-control",
    "content": "Distributed concurrency control is the concurrency control of a system distributed over a computer network (Bernstein et al. 1987, Weikum and Vossen 2001). \nIn database systems and transaction processing (transaction management) distributed concurrency control refers primarily to the concurrency control of a distributed database. It also refers to the concurrency control in a multidatabase (and other multi-transactional object) environment (e.g., federated database, grid computing, and cloud computing environments. A major goal for distributed concurrency control is distributed serializability (or global serializability for multidatabase systems). Distributed concurrency control poses special challenges beyond centralized one, primarily due to communication and computer latency. It often requires special techniques, like distributed lock manager over fast computer networks with low latency, like switched fabric (e.g., InfiniBand).\nThe most common distributed concurrency control technique is strong strict two-phase locking (SS2PL, also named rigorousness), which is also a common centralized concurrency control technique. SS2PL provides both the serializability and strictness. Strictness, a special case of recoverability, is utilized for effective recovery from failure. For large-scale distribution and complex transactions, distributed locking's typical heavy performance penalty (due to delays, latency) can be saved by using the atomic commitment protocol, which is needed in a distributed database for (distributed) transactions' atomicity.",
    "link": "https://en.wikipedia.org/wiki/Distributed_concurrency_control"
  },
  {
    "title": "Result set",
    "slug": "result-set",
    "content": "A result set is the set of results returned by a query, usually in the same format as the database the query is called on. For example, in SQL, which is used in conjunction with relational databases, it is the result of a SELECT query on a table or view and is itself a non-permanent table of rows, and could include metadata about the query such as the column names, and the types and sizes of each column. In an object database, the result set is usually a collection of objects from the database.\nDepending on the database, the number of rows in the result set may or may not be known. Usually, this number is not known up front because the result set is built on the fly. A cursor can be used by client applications to fetch a few rows of the result set at a time.",
    "link": "https://en.wikipedia.org/wiki/Result_set"
  },
  {
    "title": "Profit Impact of Market Strategy",
    "slug": "profit-impact-of-market-strategy",
    "content": "The Profit Impact of Market Strategy (PIMS) program is an empirical research initiative that analyzes the relationship between business strategy and performance outcomes. Launched at General Electric in the 1960s, the program maintains a database of 4,300 Strategic Business Units (\"SBU\") across multiple industries and geographies, yielding 12,600 observations (3-year snapshots) and over 25,000 business-years of longitudinal data. The database comprises 500 variables per SBU covering market position, customer value, cost structure, and competitive dynamics. Currently operated by pims.ai after a management buy-out, the program provides predictive analytics and benchmarking methodologies. Key strategic metrics include market share, product quality, investment intensity, and service quality, which the program correlates with financial performance outcomes.",
    "link": "https://en.wikipedia.org/wiki/Profit_Impact_of_Market_Strategy"
  },
  {
    "title": "Object Data Management Group",
    "slug": "object-data-management-group",
    "content": "The Object Data Management Group (ODMG) was conceived in the summer of 1991 at a breakfast with object database vendors that was organized by Rick Cattell of Sun Microsystems. In 1998, the ODMG changed its name from the Object Database Management Group to reflect the expansion of its efforts to include specifications for both object database and object–relational mapping products.\nThe primary goal of the ODMG was to put forward a set of specifications that allowed a developer to write portable applications for object database and object–relational mapping products.  In order to do that, the data schema, programming language bindings, and data manipulation and query languages needed to be portable.\nBetween 1993 and 2001, the ODMG published five revisions to its specification. The last revision was ODMG  version 3.0, after which the group disbanded.",
    "link": "https://en.wikipedia.org/wiki/Object_Data_Management_Group"
  },
  {
    "title": "IPUMS",
    "slug": "ipums",
    "content": "IPUMS, originally the Integrated Public Use Microdata Series, is the world's largest individual-level population database. IPUMS consists of microdata samples from United States (IPUMS-USA) and international (IPUMS-International) census records, as well as data from U.S. and international surveys. The records are converted into a consistent format and made available to researchers through a web-based data dissemination and analysis system.\nIPUMS is housed at the Institute for Social Research and Data Innovation (ISRDI), an interdisciplinary research center at the University of Minnesota, under the direction of Professor Steven Ruggles.",
    "link": "https://en.wikipedia.org/wiki/IPUMS"
  },
  {
    "title": "Index locking",
    "slug": "index-locking",
    "content": "In databases an index is a data structure, part of the database, used by a database system to efficiently navigate access to user data. Index data are system data distinct from  user data, and consist primarily of pointers. Changes in a database (by insert, delete, or modify operations), may require indexes to be updated  to maintain accurate user data accesses. Index locking is a technique used to maintain index integrity. A portion of an index is locked during a database transaction when this portion is being accessed by the transaction as a result of attempt to access related user data. Additionally, special database system transactions (not user-invoked transactions) may be invoked to maintain and modify an index, as part of a system's self-maintenance activities. When a portion of an index is locked by a transaction, other transactions may be blocked from accessing this index portion (blocked from modifying, and even from reading it, depending on lock type and needed operation). Index Locking Protocol guarantees that phantom read phenomenon won't occur. \nIndex locking protocol states:\n\nEvery relation must have at least one index.\nA transaction can access tuples only after finding them through one or more indices on the relation\nA transaction Ti that performs a lookup must lock all the index leaf nodes that it accesses, in S-mode, even if the leaf node does not contain any tuple satisfying the index lookup (e.g. for a range query, no tuple in a leaf is in the range)\nA transaction Ti that inserts, updates or deletes a tuple ti in a relation r must update all indices to r and it must obtain exclusive locks on all index leaf nodes affected by the insert/update/delete\nThe rules of the two-phase locking protocol must be observed.\n\nSpecialized concurrency control techniques exist for accessing indexes. These techniques depend on the index type, and take advantage of its structure. They are typically much more effective than applying to indexes common concurrency control methods applied to user data. Notable and  widely researched are specialized techniques for B-trees (B-Tree concurrency control) which are regularly used as database indexes.\nIndex locks are used to coordinate threads accessing indexes concurrently, and typically shorter-lived than the common transaction locks on user data. In professional literature, they are often called latches.",
    "link": "https://en.wikipedia.org/wiki/Index_locking"
  },
  {
    "title": "Relvar",
    "slug": "relvar",
    "content": "In relational databases, relvar is a term introduced by C. J. Date and Hugh Darwen as an abbreviation for relation variable in their 1995 paper The Third Manifesto, to avoid the confusion sometimes arising from the use of the term \"relation\", by the inventor of the relational model, E. F. Codd, for a variable to which a relation is assigned as well as for the relation itself.  The term is used in Date's well-known database textbook An Introduction to Database Systems and in various other books authored or coauthored by him.\nSome database textbooks use the term relation for both the variable and the data it contains.  Similarly, texts on SQL tend to use the term table for both purposes, though the qualified term base table is used in the standard for the variable.\nA closely related term often used in academic texts is relation schema, this being a set of attributes paired with a set of constraints, together defining a set of relations for the purpose of some discussion (typically, database normalization).  Constraints that mention just one relvar are termed relvar constraints, so relation schema can be regarded as a single term encompassing a relvar and its relvar constraints.",
    "link": "https://en.wikipedia.org/wiki/Relvar"
  },
  {
    "title": "Database index",
    "slug": "database-index",
    "content": "A database index is a data structure that improves the speed of data retrieval operations on a database table at the cost of additional writes and storage space to maintain the index data structure.  Indexes are used to quickly locate data without having to search every row in a database table every time said table is accessed.  Indexes can be created using one or more columns of a database table, providing the basis for both rapid random lookups and efficient access of ordered records.\nAn index is a copy of selected columns of data, from a table, that is designed to enable very efficient search.  An index normally includes a \"key\" or direct link to the original row of data from which it was copied, to allow the complete row to be retrieved efficiently.  Some databases extend the power of indexing by letting developers create indexes on column values that have been transformed by functions or expressions. For example, an index could be created on upper(last_name), which would only store the upper-case versions of the last_name field in the index. Another option sometimes supported is the use of partial index, where index entries are created only for those records that satisfy some conditional expression. A further aspect of flexibility is to permit indexing on user-defined functions, as well as expressions formed from an assortment of built-in functions.",
    "link": "https://en.wikipedia.org/wiki/Database_index"
  },
  {
    "title": "NNDB",
    "slug": "nndb",
    "content": "The Notable Names Database (NNDB) is an online database of biographical details of over 40,000 people. Soylent Communications, a sole proprietorship that also hosted the later defunct Rotten.com, describes NNDB as an \"intelligence aggregator\" of noteworthy persons, highlighting their interpersonal connections. The Rotten.com domain was registered in 1996 by former Apple and Netscape software engineer Thomas E. Dell, who was also known by his internet alias, \"Soylent\".",
    "link": "https://en.wikipedia.org/wiki/NNDB"
  },
  {
    "title": "Recordset",
    "slug": "recordset",
    "content": "A recordset is a data structure that consists of a group of database records, and can either come from a base table or as the result of a query to the table. \nThe concept is common to a number of platforms, notably Microsoft's Data Access Objects (DAO) and ActiveX Data Objects (ADO). The Recordset object contains a Fields collection, and a Properties collection. At any time, the Recordset object refers to only a single record within the set as the current record.",
    "link": "https://en.wikipedia.org/wiki/Recordset"
  },
  {
    "title": "International Road Traffic and Accident Database",
    "slug": "international-road-traffic-and-accident-database",
    "content": "The International Road Traffic and Accident Database (IRTAD) is an initiative dedicated to compiling and analyzing global road crash data. It is managed by the International Transport Forum (ITF) under the auspices of its permanent working group, which specializes in road safety, commonly referred to as the IRTAD Group. The primary objective of IRTAD is to provide a robust empirical basis for international comparisons in the field of road safety and to offer data to support the formulation of effective road safety policies.",
    "link": "https://en.wikipedia.org/wiki/International_Road_Traffic_and_Accident_Database"
  },
  {
    "title": "Materialized view",
    "slug": "materialized-view",
    "content": "In computing, a materialized view is a database object that contains the results of a query. For example, it may be a local copy of data located remotely, or may be a subset of the rows and/or columns of a table or join result, or may be a summary using an aggregate function.\nThe process of setting up a materialized view is sometimes called materialization. This is a form of caching the results of a query, similar to memoization of the value of a function in functional languages, and it is sometimes described as a form of precomputation. As with other forms of precomputation, database users typically use materialized views for performance reasons, i.e. as a form of optimization.\nMaterialized views that store data based on remote tables were also known as snapshots (deprecated Oracle terminology).\nIn any database management system following the relational model, a view is a virtual table representing the result of a database query. Whenever a query or an update addresses an ordinary view's virtual table, the DBMS converts these into queries or updates against the underlying base tables. A materialized view takes a different approach: the query result is cached as a concrete (\"materialized\") table (rather than a view as such) that may be updated from the original base tables from time to time. This enables much more efficient access, at the cost of extra storage and of some data being potentially out-of-date. Materialized views find use especially in data warehousing scenarios, where frequent queries of the actual base tables can be expensive.\nIn a materialized view, indexes can be built on any column. In contrast, in a normal view, it's typically only possible to exploit indexes on columns that come directly from (or have a mapping to) indexed columns in the base tables; often this functionality is not offered at all.",
    "link": "https://en.wikipedia.org/wiki/Materialized_view"
  },
  {
    "title": "Snapshot isolation",
    "slug": "snapshot-isolation",
    "content": "In databases, and transaction processing (transaction management), snapshot isolation is a guarantee that all reads made in a transaction will see a consistent snapshot of the database (in practice it reads the last committed values that existed at the time it started), and the transaction itself will successfully commit only if no updates it has made conflict with any concurrent updates made since that snapshot.\nSnapshot isolation has been adopted by several major database management systems, such as InterBase, Firebird, Oracle, MySQL, PostgreSQL, SQL Anywhere, MongoDB and Microsoft SQL Server (2005 and later). The main reason for its adoption is that it allows better performance than serializability, yet still avoids most of the concurrency anomalies that serializability avoids (but not all). In practice snapshot isolation is implemented within multiversion concurrency control (MVCC), where generational values of each data item (versions) are maintained: MVCC is a common way to increase concurrency and performance by generating a new version of a database object each time the object is written, and allowing transactions' read operations of several last relevant versions (of each object).  Snapshot isolation has been used to criticize the ANSI SQL-92 standard's definition of isolation levels, as it exhibits none of the \"anomalies\" that the SQL standard prohibited, yet is not serializable (the anomaly-free isolation level defined by ANSI).\nIn spite of its distinction from serializability, snapshot isolation is sometimes referred to as serializable by Oracle.",
    "link": "https://en.wikipedia.org/wiki/Snapshot_isolation"
  },
  {
    "title": "Integrated test facility",
    "slug": "integrated-test-facility",
    "content": "An integrated test facility (ITF) creates a fictitious entity in a database to process test transactions simultaneously with live input. \nITF can be used to incorporate test transactions into a normal production run of a system. Its advantage is that periodic testing does not require separate test processes. However, careful planning is necessary, and test data must be isolated from production data. \nMoreover, ITF validates the correct operation of a transaction in an application, but it does not ensure that a system is being operated correctly. Integrated test facility is considered a useful audit tool during an IT audit because it uses the same programs to compare processing using independently calculated data. This involves setting up dummy entities on an application system and processing test or production data against the entity as a means of verifying processing accuracy.",
    "link": "https://en.wikipedia.org/wiki/Integrated_test_facility"
  },
  {
    "title": "PISCES",
    "slug": "pisces",
    "content": "PISCES (Personal Identification Secure Comparison and Evaluation System) is a border control database system largely based on biometrics developed by Booz Allen Hamilton Inc.",
    "link": "https://en.wikipedia.org/wiki/PISCES"
  },
  {
    "title": "International Medical Education Directory",
    "slug": "international-medical-education-directory",
    "content": "The International Medical Education Directory (IMED) was a public database of worldwide medical schools. The IMED was published as a joint collaboration of the Educational Commission for Foreign Medical Graduates (ECFMG) and the Foundation for Advancement of International Medical Education and Research (FAIMER).\nThe information available in IMED was derived from data collected by the Educational Commission for Foreign Medical Graduates (ECFMG) throughout its history of evaluating the medical education credentials of international medical graduates. Using these data as a starting point, Foundation for Advancement of International Medical Education and Research (FAIMER) began developing IMED in 2001 and made it publicly available in April 2002.\nIn April 2014, IMED was merged with the Avicenna Directory to create the World Directory of Medical Schools. The World Directory is now the definitive list of medical schools in the world, as IMED and Avicenna were discontinued in 2015.",
    "link": "https://en.wikipedia.org/wiki/International_Medical_Education_Directory"
  },
  {
    "title": "Online complex processing",
    "slug": "online-complex-processing",
    "content": "Online complex processing (OLCP) is a class of realtime data processing involving complex queries, lengthy queries and/or simultaneous reads and writes to the same records.",
    "link": "https://en.wikipedia.org/wiki/Online_complex_processing"
  },
  {
    "title": "Intelligent database",
    "slug": "intelligent-database",
    "content": "Until the 1980s, databases were viewed as computer systems that stored record-oriented and business data such as manufacturing inventories, bank records, and sales transactions. A database system was not expected to merge numeric data with text, images, or multimedia information, nor was it expected to automatically notice patterns in the data it stored. In the late 1980s the concept of an intelligent database was put forward as a system that manages information (rather than data) in a way that appears natural to users and which goes beyond simple record keeping.\nThe term was introduced in 1989 by the book Intelligent Databases by Kamran Parsaye, Mark Chignell, Setrag Khoshafian and Harry Wong. The concept postulated three levels of intelligence for such systems: high level tools, the user interface and the database engine. The high level tools manage data quality and automatically discover relevant patterns in the data with a process called data mining. This layer often relies on the use of artificial intelligence techniques. The user interface uses hypermedia in a form that uniformly manages text, images and numeric data. The intelligent database engine supports the other two layers, often merging relational database techniques with object orientation.\nIn the twenty-first century, intelligent databases have now become widespread, e.g. hospital databases can now call up patient histories consisting of charts, text and x-ray images just with a few mouse clicks, and many corporate databases include decision support tools based on sales pattern analysis.",
    "link": "https://en.wikipedia.org/wiki/Intelligent_database"
  },
  {
    "title": "Single-instance storage",
    "slug": "singleinstance-storage",
    "content": "Single-instance storage (SIS) is a system's ability to take multiple copies of content and replace them by a single shared copy. It is a means to eliminate data duplication and to increase efficiency.  SIS is frequently implemented in file systems, e-mail server software, data backup, and other storage-related computer software. Single-instance storage is a simple variant of data deduplication. While data deduplication may work at a segment or sub-block level, single-instance storage works at the whole-file level and eliminates redundant copies of entire files or e-mail messages.",
    "link": "https://en.wikipedia.org/wiki/Single-instance_storage"
  },
  {
    "title": "Information schema",
    "slug": "information-schema",
    "content": "In relational databases, the information schema (information_schema) is an ANSI-standard set of read-only views that provide information about all of the tables, views, columns, and procedures in a database. It can be used as a source of the information that some databases make available through non-standard commands, such as:\n\nthe SHOW command of MySQL\nthe DESCRIBE command of Oracle's SQL*Plus\nthe \\d command in psql (PostgreSQL's default command-line program).\n => SELECT count(table_name) FROM information_schema.tables;\n  count \n -------\n     99\n (1 row)\n => SELECT column_name, data_type, column_default, is_nullable\n       FROM information_schema.columns WHERE table_name='alpha';\n  column_name | data_type | column_default | is_nullable \n -------------+-----------+----------------+-------------\n  foo         | integer   |                | YES\n  bar         | character |                | YES\n (2 rows)\n => SELECT * FROM information_schema.information_schema_catalog_name;\n  catalog_name \n --------------\n  johnd\n (1 row)",
    "link": "https://en.wikipedia.org/wiki/Information_schema"
  },
  {
    "title": "MultiValue database",
    "slug": "multivalue-database",
    "content": "A MultiValue database is a type of NoSQL and multidimensional database. It is typically considered synonymous with PICK, a database originally developed as the Pick operating system.\nMultiValue databases include commercial products from Rocket Software, Revelation, InterSystems, Northgate Information Solutions, ONgroup, and other companies. These databases differ from a relational database in that they have features that support and encourage the use of attributes which can take a list of values, rather than all attributes being single-valued. They are often categorized with MUMPS within the category of post-relational databases, although the data model actually pre-dates the relational model. Unlike SQL-DBMS tools, most MultiValue databases can be accessed both with or without SQL.",
    "link": "https://en.wikipedia.org/wiki/MultiValue_database"
  },
  {
    "title": "Computer security",
    "slug": "computer-security",
    "content": "Computer security (also cyber security, digital security, or information technology (IT) security) is a subdiscipline within the field of information security. It focuses on protecting computer software, systems, and networks from threats that can lead to unauthorized information disclosure, theft or damage to hardware, software, or data, as well as to the disruption or misdirection of the services they provide.\nThe growing significance of computer insecurity also reflects the increasing dependence on computer systems, the Internet, and evolving wireless network standards. This reliance has expanded with the proliferation of smart devices, including smartphones, televisions, and other components of the Internet of things (IoT).\nAs digital infrastructure becomes more embedded in everyday life, cyber security has emerged as a critical concern. The complexity of modern information systems—and the societal functions they underpin—has introduced new vulnerabilities. Systems that manage essential services, such as power grids, electoral processes, and finance, are particularly sensitive to security breaches.\nAlthough many aspects of computer security involve digital security, such as electronic passwords and encryption, physical security measures, such as metal locks are still used to prevent unauthorized tampering. IT security is not a perfect subset of information security, therefore does not  completely align with the security convergence schema.",
    "link": "https://en.wikipedia.org/wiki/Computer_security"
  },
  {
    "title": "Whitelist",
    "slug": "whitelist",
    "content": "A whitelist or allowlist is a list or register of entities that are being provided a particular privilege, service, mobility, access or recognition. Entities on the list will be accepted, approved and/or recognized. Whitelisting is the reverse of blacklisting, the practice of identifying entities that are denied, unrecognized, or ostracized.",
    "link": "https://en.wikipedia.org/wiki/Whitelist"
  },
  {
    "title": "Confused deputy problem",
    "slug": "confused-deputy-problem",
    "content": "In information security, a confused deputy is a computer program that is tricked by another program (with fewer privileges or less rights) into misusing its authority on the system. It is a specific type of privilege escalation. The confused deputy problem is often cited as an example of why capability-based security is important.\nCapability systems protect against the confused deputy problem, whereas access-control list–based systems do not.",
    "link": "https://en.wikipedia.org/wiki/Confused_deputy_problem"
  },
  {
    "title": "CAPTCHA",
    "slug": "captcha",
    "content": "A CAPTCHA ( KAP-chə) is a type of challenge–response Turing test used in computing to determine whether the user is human in order to deter bot attacks and spam.\nThe term was coined in 2003 by Luis von Ahn, Manuel Blum, Nicholas J. Hopper, and John Langford. It is an acronym for \"Completely Automated Public Turing test to tell Computers and Humans Apart\". A historically common type of CAPTCHA (displayed as reCAPTCHA v1) was first invented in 1997 by two groups working in parallel. This form of CAPTCHA requires entering a sequence of letters or numbers from a distorted image. Because the test is administered by a computer, in contrast to the standard Turing test that is administered by a human, CAPTCHAs are sometimes described as reverse Turing tests.\nTwo widely used CAPTCHA services are Google's reCAPTCHA and the independent hCaptcha. It takes the average person approximately 10 seconds to solve a typical CAPTCHA. With the rising application of AI making it feasible to defeat the tests and the appearance of scams disguised as CAPTCHAs, their use risks being outmoded.",
    "link": "https://en.wikipedia.org/wiki/CAPTCHA"
  },
  {
    "title": "Two-phase locking",
    "slug": "twophase-locking",
    "content": "In databases and transaction processing, two-phase locking (2PL) is a pessimistic concurrency control method that guarantees conflict-serializability. It is also the name of the resulting set of database transaction schedules (histories). The protocol uses locks, applied by a transaction to data, which may block (interpreted as signals to stop) other transactions from accessing the same data during the transaction's life.\nBy the 2PL protocol, locks are applied and removed in two phases:\n\nExpanding phase: locks are acquired and no locks are released.\nShrinking phase: locks are released and no locks are acquired.\nTwo types of locks are used by the basic protocol: Shared and Exclusive locks. Refinements of the basic protocol may use more lock types. Using locks that block processes, 2PL, S2PL, and SS2PL may be subject to deadlocks that result from the mutual blocking of two or more transactions.",
    "link": "https://en.wikipedia.org/wiki/Two-phase_locking"
  },
  {
    "title": "User-defined function",
    "slug": "userdefined-function",
    "content": "A user-defined function (UDF) is a function provided by the user of a program or environment, in a context where the usual assumption is that functions are built into the program or environment. UDFs are usually written for the requirement of its creator.",
    "link": "https://en.wikipedia.org/wiki/User-defined_function"
  },
  {
    "title": "Computer Law & Security Review",
    "slug": "computer-law--security-review",
    "content": "The Computer Law & Security Review is a journal accessible to a wide range of professional legal and IT practitioners, businesses, academics, researchers, libraries and organisations in both the public and private sectors, the Computer Law and Security Review regularly covers:\n\nCLSR Briefing with special emphasis on UK/US developments\nEuropean Union update\nNational news from 10 European jurisdictions\nPacific rim news column\nRefereed practitioner and academic papers on topics such as Web 2.0, IT security, Identity management, ID cards, RFID, interference with privacy, Internet law, telecoms regulation, online broadcasting, intellectual property, software law, e-commerce, outsourcing, data protection and freedom of information and many other topics.\nThe Journal's Correspondent Panel includes more than 40 specialists in IT law and security.\nEach issue contains articles, case law analysis and current news on information and communications technology.\nSpecial Features\n\nHigh quality peer reviewed papers from internationally renowned practitioner and academic experts\nLatest developments reported in situ by more than 20 leading law firms from around the world\nHighly experienced and respected editor and correspondents panel\nOnline access to all 23 volumes of CLSR with embedded web links to primary sources\nContact details of all authors\nA pool of expertise that can collectively identify the key topics that need to be examined.",
    "link": "https://en.wikipedia.org/wiki/Computer_Law_%26_Security_Review"
  },
  {
    "title": "Client honeypot",
    "slug": "client-honeypot",
    "content": "Honeypots are security devices whose value lie in being probed and compromised. Traditional honeypots are servers (or devices that expose server services) that wait passively to be attacked. Client Honeypots are active security devices in search of malicious servers that attack clients. The client honeypot poses as a client and interacts with the server to examine whether an attack has occurred. Often the focus of client honeypots is on web browsers, but any client that interacts with servers can be part of a client honeypot (for example ftp, email, ssh, etc.).\nThere are several terms that are used to describe client honeypots. Besides client honeypot, which is the generic classification, honeyclient is the other term that is generally used and accepted. However, there is a subtlety here, as \"honeyclient\" is actually a homograph that could also refer to the first known open source client honeypot implementation (see below), although this should be clear from the context.",
    "link": "https://en.wikipedia.org/wiki/Client_honeypot"
  },
  {
    "title": "Trigger list",
    "slug": "trigger-list",
    "content": "Trigger list in its most general meaning refers to a list whose items are used to initiate (\"trigger\") certain actions.",
    "link": "https://en.wikipedia.org/wiki/Trigger_list"
  },
  {
    "title": "Termcap",
    "slug": "termcap",
    "content": "Termcap (terminal capability) is a legacy software library and database used on Unix-like computers that enables programs to use display computer terminals in a terminal-independent manner, which greatly simplifies the process of writing portable text mode applications. It was superseded by the terminfo database used by ncurses, tput, and other programs. \nA termcap database can describe the capabilities of hundreds of different display terminals. This allows programs to have character-based display output, independent of the type of terminal. On-screen text editors such as vi and Emacs are examples of programs that may use termcap. Other programs are listed in the  Termcap category. Access to the termcap database was usually provided by separate libraries, e.g. GNU Termcap.\nExamples of what the database describes:\n\nhow many columns wide the display is\nwhat string to send to move the cursor to an arbitrary position (including how to encode the row and column numbers)\nhow to scroll the screen up one or several lines\nhow much padding is needed for such a scrolling operation.",
    "link": "https://en.wikipedia.org/wiki/Termcap"
  },
  {
    "title": "Collaboration-oriented architecture",
    "slug": "collaborationoriented-architecture",
    "content": "Collaboration Oriented Architecture (COA) is a computer system that is designed to collaborate, or use services, from systems that are outside of the operators control. Collaboration Oriented Architecture will often use Service Oriented Architecture to deliver the technical framework.\nCollaboration Oriented Architecture is the ability to collaborate between systems that are based on the Jericho Forum principles or \"Commandments\".\nBill Gates and Craig Mundie (Microsoft)  clearly articulated the need for people to work outside of their organizations in a secure and collaborative manner in their opening keynote to the RSA Security Conference in February 2007.\nSuccessful implementation of a Collaboration Oriented Architecture implies the ability to successfully inter-work securely over the Internet and will typically mean the resolution of the problems that come with de-perimeterisation.",
    "link": "https://en.wikipedia.org/wiki/Collaboration-oriented_architecture"
  },
  {
    "title": "Spindling",
    "slug": "spindling",
    "content": "In computers spindling is the allocation of different files (e.g., the data files and index files of a database) on different hard disks.  This practice usually reduces contention for read or write resources, thus increasing the system's performance.\nThe word comes from spindle, the axis on which the hard disks spin.",
    "link": "https://en.wikipedia.org/wiki/Spindling"
  },
  {
    "title": "Centurion Guard",
    "slug": "centurion-guard",
    "content": "Centurion Guard is a PC hardware and software-based security product, developed by Centurion Technologies. It was first released in 1996. There were several different releases and versions of this product, and many were distributed in computers donated to libraries by the Bill & Melinda Gates Foundation.",
    "link": "https://en.wikipedia.org/wiki/Centurion_Guard"
  },
  {
    "title": "Variable data publishing",
    "slug": "variable-data-publishing",
    "content": "Variable-data publishing (VDP) (also known as database publishing) is a term referring to the output of a variable composition system. While these systems can produce both electronically viewable and hard-copy (print) output, the \"variable-data publishing\" term today often distinguishes output destined for electronic viewing, rather than that which is destined for hard-copy print (e.g. variable data printing).\n\nEssentially the same techniques are employed to perform variable-data publishing, as those utilized with variable data printing.  The difference is in the interpretation for output.  While variable-data printing may be interpreted to produce various print streams or page-description files (e.g. AFP/IPDS, PostScript, PCL), variable-data publishing produces electronically viewable files, most commonly seen in the forms of PDF, HTML, or XML.\nVariable-data composition involves the use of data to conditionally:\n\nexhibit text (static blocks and/or variable content)\nexhibit images\nselect fonts\nselect colors\nformat page layouts & flows\nVariable-data may be as simple as an address block or salutation. However, it can be any or all of the document's textual content—including words, sentences, paragraphs, pages, or the entire document.  In other words, it can make up as little or as much of the document as the composer desires.  Variable data may also be used to exhibit various images, such as logos, products, or membership photos.  Further, variable-data can be used to build rule-based design schemes, including fonts, colors, and page formats.  The possibilities are vast.\nThe variable-data tools available today, make it possible to perform variable-data composition at nearly every stage of document production.  However, the level of control that can be achieved varies, based upon how far into the document production process a variable-data tool is deployed.  For example, if variable-data insertion occurs just prior to output...it's not likely that the text flow or layout can be altered with nearly as much control as would be available at the time of initial document composition.\nMany organizations will produce multiple forms of output (aka: multi-channel output), for the same document.  This ensures that the published content is available to recipients via any form of access method they might require.  When multi-channel output is utilized, integrity between those output channels often becomes important.\nVariable-data publishing may be performed on everything from a personal computer to a mainframe system.  However, the speed and practical output volumes which can be achieved are directly affected by the computer power utilized.",
    "link": "https://en.wikipedia.org/wiki/Variable_data_publishing"
  },
  {
    "title": "Cloud computing security",
    "slug": "cloud-computing-security",
    "content": "Cloud computing security or cloud security refers to a broad set of policies, technologies, applications, and controls used to protect virtualized IP, data, applications, services, and the associated infrastructure of cloud computing. It is a sub-domain of computer security, network security and, more broadly, information security.",
    "link": "https://en.wikipedia.org/wiki/Cloud_computing_security"
  },
  {
    "title": "Synonym (database)",
    "slug": "synonym-database",
    "content": "In databases, a synonym is an alias or alternate name for a table, view, sequence, or other schema object. They are used mainly to make it intuitive for users to access database objects owned by other users. They also hide the underlying object's identity and make it harder for a malicious program or user to target the underlying object (security through obscurity). Because a synonym is just an alternate name for an object, it requires no storage other than its definition. When an application uses a synonym, the DBMS forwards the request to the synonym's underlying base object. By coding your programs to use synonyms instead of database object names, you insulate yourself from any changes in the name, ownership, or object locations, at the cost of adding another layer that also needs to be maintained. Users can also have different needs, for example some may wish to use a shorter name to refer to database objects they often query, which can be done with aliases without having to rename the underlying object and alter the code referring to it.\nSynonyms are very powerful from the point of view of allowing users access to objects that do not lie within their schema. All synonyms have to be created explicitly with the CREATE SYNONYM command and the underlying objects can be located in the same database or in other databases that are connected by database links\nThere are two major uses of synonyms:\n\nObject invisibility: Synonyms can be created to keep the original object hidden from the user.\nLocation invisibility: Synonyms can be created as aliases for tables and other objects that are not part of the local database.\nWhen a table or a procedure is created, it is created in a particular schema, and other users can access it only by using that schema's name as a prefix to the object's name.  The way around for this is for the schema owner creates a synonym with the same name as the table name.",
    "link": "https://en.wikipedia.org/wiki/Synonym_(database)"
  },
  {
    "title": "Universal IR Evaluation",
    "slug": "universal-ir-evaluation",
    "content": "In computer science, Universal IR Evaluation  (information retrieval evaluation) aims to develop measures of database retrieval performance that shall be comparable across all information retrieval tasks.",
    "link": "https://en.wikipedia.org/wiki/Universal_IR_Evaluation"
  },
  {
    "title": "Terminology model",
    "slug": "terminology-model",
    "content": "A terminology model is a refinement of a concept system. Within a terminology model the concepts (object types) of a specific problem or subject area are defined by subject-matter experts in terms of concept (object type) definitions and definitions of subordinated concepts or characteristics (properties). Besides object types, the terminology model allows defining hierarchical classifications, definitions for object type and property behavior and definition of casual relations.\nThe terminology model is a means for subject-matter experts to express their knowledge about the subject in subject-specific terms. Since the terminology model is structured rather similar to an object-oriented database schema, is can be transformed without loss of information into an object-oriented database schema. Thus, the terminology model is a method for problem analysis on the one side and a mean of defining database schema on the other side.\nSeveral terminology models have been developed and published in the field of statistics:\n\nTerminology model for classifications\nTerminology model for statistical variables\nReference model for statistical metadata",
    "link": "https://en.wikipedia.org/wiki/Terminology_model"
  },
  {
    "title": "Computer security compromised by hardware failure",
    "slug": "computer-security-compromised-by-hardware-failure",
    "content": "Computer security compromised by hardware failure is a branch of computer security applied to hardware.\nThe objective of computer security includes protection of information and property from theft, corruption, or natural disaster, while allowing the information and property to remain accessible and productive to its intended users. Such secret information could be retrieved by different ways. This article focus on the retrieval of data thanks to misused hardware or hardware failure. Hardware could be misused or exploited to get secret data. This article collects main types of attack that can lead to data theft.\nComputer security can be compromised by devices, such as keyboards, monitors or printers (thanks to electromagnetic or acoustic emanation for example) or by components of the computer, such as the memory, the network card or the processor (thanks to time or temperature analysis for example).",
    "link": "https://en.wikipedia.org/wiki/Computer_security_compromised_by_hardware_failure"
  },
  {
    "title": "Cybercrime",
    "slug": "cybercrime",
    "content": "Cybercrime encompasses a wide range of criminal activities that are carried out using digital devices and/or networks. It has been variously defined as \"a crime committed on a computer network, especially the Internet;  Cybercriminals may exploit vulnerabilities in computer systems and networks to gain unauthorized access, steal sensitive information, disrupt services, and cause financial or reputational harm to individuals, organizations, and governments.\nCybercrimes refer to socially dangerous acts committed using computer equipment against information processed and used in cyberspace.\nIn 2000, the tenth United Nations Congress on the Prevention of Crime and the Treatment of Offenders classified cyber crimes into five categories: unauthorized access, damage to computer data or programs, sabotage to hinder the functioning of a computer system or network, unauthorized interception of data within a system or network, and computer espionage.\nInternationally, both state and non-state actors engage in cybercrimes, including espionage, financial theft, and other cross-border crimes. Cybercrimes crossing international borders and involving the actions of at least one nation-state are sometimes referred to as cyberwarfare. Warren Buffett has stated that cybercrime is the \"number one problem with mankind\", and that it \"poses real risks to humanity\".\nThe World Economic Forum's (WEF) 2020 Global Risks Report highlighted that organized cybercrime groups are joining forces to commit criminal activities online, while estimating the likelihood of their detection and prosecution to be less than 1 percent in the US. There are also many privacy concerns surrounding cybercrime when confidential information is intercepted or disclosed, legally or otherwise.\nThe World Economic Forum's 2023 Global Risks Report ranked cybercrime as one of the top 10 risks facing the world today and for the next 10 years.",
    "link": "https://en.wikipedia.org/wiki/Cybercrime"
  },
  {
    "title": "Data remanence",
    "slug": "data-remanence",
    "content": "Data remanence is the residual representation of digital data that remains even after attempts have been made to remove or erase the data. This residue may result from data being left intact by a nominal file deletion operation, by reformatting of storage media that does not remove data previously written to the media, or through physical properties of the storage media that allow previously written data to be recovered. Data remanence may make inadvertent disclosure of sensitive information possible should the storage media be released into an uncontrolled environment (e.g., thrown in refuse containers or lost). \nVarious techniques have been developed to counter data remanence. These techniques are classified as clearing, purging/sanitizing, or destruction. Specific methods include overwriting, degaussing, encryption, and media destruction.\nEffective application of countermeasures can be complicated by several factors, including media that are inaccessible, media that cannot effectively be erased, advanced storage systems that maintain histories of data throughout the data's life cycle, and persistence of data in memory that is typically considered volatile.\nSeveral standards exist for the secure removal of data and the elimination of data remanence.",
    "link": "https://en.wikipedia.org/wiki/Data_remanence"
  },
  {
    "title": "Dancing pigs",
    "slug": "dancing-pigs",
    "content": "In computer security, \"dancing pigs\" is a term or problem that explains computer users' attitudes towards computer security. It states that users will continue to pick an amusing graphic even if they receive a warning from security software that it is potentially dangerous. In other words, users choose their primary desire features without considering the security. \"Dancing pigs\" is generally used by tech experts and can be found in IT articles.",
    "link": "https://en.wikipedia.org/wiki/Dancing_pigs"
  },
  {
    "title": "Crackme",
    "slug": "crackme",
    "content": "A crackme is a small computer program designed to test a programmer's reverse engineering skills. Crackmes are made as a legal way to crack software, since no intellectual property is being infringed.",
    "link": "https://en.wikipedia.org/wiki/Crackme"
  },
  {
    "title": "Data classification (data management)",
    "slug": "data-classification-data-management",
    "content": "Data classification is the process of organizing data into categories based on attributes like file type, content, or metadata. The data is then assigned class labels that describe a set of attributes for the corresponding data sets. The goal is to provide meaningful class attributes to former less structured information, enabling organizations to manage, protect, and govern their data more effectively.\nData classification can be viewed as a multitude of labels that are used to define the type of data, especially on confidentiality and integrity issues.",
    "link": "https://en.wikipedia.org/wiki/Data_classification_(data_management)"
  },
  {
    "title": "CPU modes",
    "slug": "cpu-modes",
    "content": "CPU modes (also called processor modes, CPU states, CPU privilege levels and other names) are operating modes for the central processing unit of most computer architectures that place restrictions on the type and scope of operations that can be performed by instructions being executed by the CPU. For example, this design allows an operating system to run with more privileges than application software by running the operating systems and applications in different modes.\nIdeally, only highly trusted kernel code is allowed to execute in the unrestricted mode; everything else (including non-supervisory portions of the operating system) runs in a restricted mode and must use a system call (via interrupt) to request the kernel perform on its behalf any operation that could damage or compromise the system, making it impossible for untrusted programs to alter or damage other programs (or the computing system itself). Device drivers are designed to be part of the kernel due to the need for frequent I/O access.\nMultiple modes can be implemented, e.g. allowing a hypervisor to run multiple operating system supervisors beneath it, which is the basic design of many virtual machine systems available today.",
    "link": "https://en.wikipedia.org/wiki/CPU_modes"
  },
  {
    "title": "Cryptographic module",
    "slug": "cryptographic-module",
    "content": "A cryptographic module is a component of a computer system that securely implements cryptographic algorithms, typically with some element of tamper resistance.\nNIST defines a cryptographic module as \"The set of hardware, software, and/or firmware that implements security functions (including cryptographic algorithms), holds plaintext keys and uses them for performing cryptographic operations, and is contained within a cryptographic module boundary.\"\nHardware security modules, including secure cryptoprocessors, are one way of implementing cryptographic modules.\nStandards for cryptographic modules include FIPS 140-3 and ISO/IEC 19790.",
    "link": "https://en.wikipedia.org/wiki/Cryptographic_module"
  },
  {
    "title": "Economics of security",
    "slug": "economics-of-security",
    "content": "The economics of information security addresses the economic aspects of privacy and computer security. Economics of information security includes models of the strictly rational “homo economicus” as well as behavioral economics. Economics of securities addresses individual and organizational decisions and behaviors with respect to security and privacy as market decisions.\nEconomics of security addresses a core question: why do agents choose technical risks when there exists technical solutions to mitigate security and privacy risks?  Economics addresses not only this question, but also inform design decisions in security engineering.",
    "link": "https://en.wikipedia.org/wiki/Economics_of_security"
  },
  {
    "title": "Defensive computing",
    "slug": "defensive-computing",
    "content": "Defensive computing is a form of practice for computer users to help reduce the risk of computing problems, by avoiding dangerous computing practices. The primary goal of this method of computing is to be able to anticipate and prepare for potentially problematic situations prior to their occurrence, despite any adverse conditions of a computer system or any mistakes made by other users. This can be achieved through adherence to a variety of general guidelines, as well as the practice of specific computing techniques.\nStrategies for defensive computing could be divided into two categories, network security and the backup and restoration of data.",
    "link": "https://en.wikipedia.org/wiki/Defensive_computing"
  },
  {
    "title": "Enterprise information security architecture",
    "slug": "enterprise-information-security-architecture",
    "content": "Enterprise information security architecture(EISA) is the practice of designing, constructing and maintaining information security strategies and policies in enterprise organisations. A subset of enterprise architecture, information security frameworks are often given their own dedicated resources in larger organisations and are therefore significantly more complex and robust than in small and medium-sized enterprises.",
    "link": "https://en.wikipedia.org/wiki/Enterprise_information_security_architecture"
  },
  {
    "title": "Data breach notification laws",
    "slug": "data-breach-notification-laws",
    "content": "Security breach notification laws or data breach notification laws are laws that require individuals or entities affected by a data breach, unauthorized access to data, to notify their customers and other parties about the breach, as well as take specific steps to remedy the situation based on state legislature.\nSuch laws have been irregularly enacted in all 50 U.S. states since 2002. Currently, all 50 states have enacted forms of data breach notification laws. There is no federal data breach notification law, despite previous legislative attempts. These laws were enacted in response to an escalating number of breaches of consumer databases containing personally identifiable information. Similarly, multiple other countries, like the European Union General Data Protection Regulation (GDPR) and Australia's Privacy Amendment (Notifiable Data Breaches) Act 2017 (Cth), have added breach disclosure or data breach notification laws to combat the increasing occurrences of data breaches.\nThe rise in data breaches conducted by both countries and individuals is evident and alarming, as the number of reported data breaches has increased from 421 in 2011, to 1,091 in 2016, and 1,579 in 2017 according to the Identity Theft Resource Center (ITRC). It has also impacted millions of people and gained increasing public awareness due to large data breaches such as the October 2017 Equifax breach that exposed almost 146 million individual's personal information.",
    "link": "https://en.wikipedia.org/wiki/Data_breach_notification_laws"
  },
  {
    "title": "Data breach",
    "slug": "data-breach",
    "content": "A data breach, also known as data leakage, is \"the unauthorized exposure, disclosure, or loss of personal information\".\nAttackers have a variety of motives, from financial gain to political activism, political repression, and espionage. There are several technical root causes of data breaches, including accidental or intentional disclosure of information by insiders, loss or theft of unencrypted devices, hacking into a system by exploiting software vulnerabilities, and social engineering attacks such as phishing where insiders are tricked into disclosing information. Although prevention efforts by the company holding the data can reduce the risk of data breach, it cannot bring it to zero.\nA large number of data breaches are never detected. If a breach is made known to the company holding the data, post-breach efforts commonly include containing the breach, investigating its scope and cause, and notifications to people whose records were compromised, as required by law in many jurisdictions. Law enforcement agencies may investigate breaches, although the hackers responsible are rarely caught.\nMany criminals sell data obtained in breaches on the dark web. Thus, people whose personal data was compromised are at elevated risk of identity theft for years afterwards and a significant number will become victims of this crime. Data breach notification laws in many jurisdictions, including all states of the United States and European Union member states, require the notification of people whose data has been breached. Lawsuits against the company that was breached are common, although few victims receive money from them. There is little empirical evidence of economic harm to firms from breaches except the direct cost, although there is some evidence suggesting a temporary, short-term decline in stock price.",
    "link": "https://en.wikipedia.org/wiki/Data_breach"
  },
  {
    "title": "Cyber Storm Exercise",
    "slug": "cyber-storm-exercise",
    "content": "The Cyber Storm exercise is a biennial simulated exercise overseen by the United States Department of Homeland Security that took place February 6 through February 10, 2006 with the purpose of testing the nation's defenses against digital espionage. The simulation was targeted primarily at American security organizations but officials from the United Kingdom, Canada, Australia and New Zealand participated as well.",
    "link": "https://en.wikipedia.org/wiki/Cyber_Storm_Exercise"
  },
  {
    "title": "Four Horsemen of the Infocalypse",
    "slug": "four-horsemen-of-the-infocalypse",
    "content": "The Four Horsemen of the Infocalypse refers to those who use the Internet to facilitate crime or (pejoratively) to rhetorical approaches evoking such criminals.\nThe phrase is a play on Four Horsemen of the Apocalypse. There is not a universally agreed definition of who the Horsemen are. Terrorists, pedophiles/child molesters, organized crime like drug dealers, intellectual property pirates, and money launderers are cited commonly.\nOne of the most famous definitions is in The Cyphernomicon by the cypherpunk writer and engineer Tim May, which states:\n\n8.3.4. \"How will privacy and anonymity be attacked?\" [...]\nlike so many other \"computer hacker\" items, as a tool for the \"Four Horsemen\": drug-dealers, money-launderers,  terrorists, and pedophiles.\n17.5.7. \"What limits on the Net are being proposed?\" [...]\n\nNewspapers are complaining about the Four Horsemen of the Infocalypse: terrorists, pedophiles, drug dealers, and money launderers\nDigital rights activist Cory Doctorow frequently cites \"software pirates, organized crime, child pornographers, and terrorists\". Other sources use slightly different descriptions, but generally refer to similar activities.",
    "link": "https://en.wikipedia.org/wiki/Four_Horsemen_of_the_Infocalypse"
  },
  {
    "title": "Federal Desktop Core Configuration",
    "slug": "federal-desktop-core-configuration",
    "content": "The Federal Desktop Core Configuration is a list of security settings recommended by the National Institute of Standards and Technology for general-purpose microcomputers that are connected directly to the network of a United States government agency.\nThe FDCC is a list of agreed upon Microsoft Windows operating system common core system functions, applications, files, and services that are changed in their configuration around which a framework for a more secure, and security-reliable MS Windows operating system was created. The standards were then made mandatory for every federal government computer effective 1 Feb 2008. If you wanted to connect to a federal office computer network your system had to meet or exceed the FDCC standard or you were denied access.\nFDCC applied only to Windows XP and Vista desktop and laptop computers and was replaced by the United States Government Configuration Baseline (USGCB), which included settings for Windows 7 and Red Hat Enterprise Linux 5.\nFor Windows 7, the NIST changed the naming convention to the US Government Computer Baseline (USGCB ver 2.0). In addition to un-classifying a general Windows settings guide, the NIST also publishes guides specifically for Windows Firewall, Internet Explorer, and a guide (Vista-Energy, for example) created to capture settings that adhere to energy conservation policies.",
    "link": "https://en.wikipedia.org/wiki/Federal_Desktop_Core_Configuration"
  },
  {
    "title": "DREAD (risk assessment model)",
    "slug": "dread-risk-assessment-model",
    "content": "DREAD (Damage, Reproducibility, Exploitability, Affected users, Discoverability) is a risk assessment and threat modeling system for computer security threats. When a given threat is assessed using DREAD, each category is given a rating from 1 to 10, and the sum of all ratings is taken to assess the overall risk. It was formerly used at Microsoft before being discontinued for its inconsistency and subjectivity. It has also been criticised for promoting security through obscurity through the discoverability element. Some organizations have moved to a DREAD-D \"DREAD minus D\" scale, which omits Discoverability.",
    "link": "https://en.wikipedia.org/wiki/DREAD_(risk_assessment_model)"
  },
  {
    "title": "Fail-stop",
    "slug": "failstop",
    "content": "A fail-stop subset of a computer language is one that has the same semantics as the original, except in the case where an exceptional condition arises.  The fail-stop subset must report an exceptional condition whenever the superset language reports one, but may additionally report an exceptional condition in other cases.\nFail-stop languages are often used in computer systems where correctness is very important, since it is easier to make such systems fail-fast.  For example, the \"+\" operator in many programming languages is not associative because of the possibility of floating-point overflow.  Repairing these languages to fail fast when commonly assumed properties do not hold makes it much easier to write and verify correct code.",
    "link": "https://en.wikipedia.org/wiki/Fail-stop"
  },
  {
    "title": "CyberPatriot",
    "slug": "cyberpatriot",
    "content": "CyberPatriot is a national youth cyber education program for K-12 created in the United States to help direct students toward careers in cybersecurity or other computer science, technology, engineering, and mathematics disciplines. The program was created by the Air Force Association. It is a National Youth Cyber Defense Competition for high and middle school students, and features the annual in-person National Final Competition. It is similar to its collegiate counterpart, the Collegiate Cyber Defense Competition (CCDC). The AFA is also affiliated with distinctly branded sister competitions in US-allied countries, including Canada, formerly the UK, and Australia, but such teams may also be eligible to compete separately in the main CyberPatriot program.\nCyberPatriot requires teams to assume the role of cybersecurity professionals, responsible for protecting various systems in a set amount of time. The competition consists of multiple online rounds in which teams analyze virtual machines, identify vulnerabilities, and implement security measures, answer forensics questions, and secure critical services. The Center for Infrastructure Assurance and Security (CIAS) is responsible for designing, developing, and supplying the technology and virtual machines used in CyberPatriot. The competition assesses participants' cybersecurity knowledge, problem-solving abilities, teamwork, and analytical thinking.\nThe National Youth Cyber Defense Competition is now in its eighteenth season and is called \"CyberPatriot 18\" indicating the season's competition. CyberPatriot 18 is accessible to high schools, middle schools, and accredited homeschooling programs across the United States. JROTC units of all Services, Civil Air Patrol squadrons, and Naval Sea Cadet Corps divisions may also participate in the competition. CyberPatriot also sponsors two additional initiative programs: Summer CyberCamps and an Elementary School Cyber Education Initiative. The Northrop Grumman Foundation is the \"presenting sponsor\". A British spin off program was called Cyber Centurion.",
    "link": "https://en.wikipedia.org/wiki/CyberPatriot"
  },
  {
    "title": "Hacker Bible",
    "slug": "hacker-bible",
    "content": "The Hacker Bible is a publication of the German hacker organization Chaos Computer Club (CCC). It has been published in three editions to date, 1985, 1988, and 2024. The first two were edited by Wau Holland and published on the Grüne Kraft press. The third edition was published by the Chaos Computer Club and released by Katapult Verlag.",
    "link": "https://en.wikipedia.org/wiki/Hacker_Bible"
  },
  {
    "title": "Cyber Threat Intelligence Integration Center",
    "slug": "cyber-threat-intelligence-integration-center",
    "content": "The Cyber Threat Intelligence Integration Center (CTIIC) is a United States federal government agency that operates as a fusion center between intelligence agencies and the private sector for real-time use against cyber attacks. The agency's seal incorporates binary code that, when decoded, reads \"AWARENESS ANALYSIS OPPORTUNITY\" (originally encoded without spaces). CTIIC was created in the wake of the 2014 cyber attack on Sony in combination with the need to establish a cyber integration center following blocked efforts in Congress that were stymied over liability and privacy concerns of citizens.",
    "link": "https://en.wikipedia.org/wiki/Cyber_Threat_Intelligence_Integration_Center"
  },
  {
    "title": "RFPolicy",
    "slug": "rfpolicy",
    "content": "The RFPolicy outlines a method for contacting vendors about security vulnerabilities found in their products.  It was initially written in 2000 by hacker and security consultant Rain Forest Puppy. It was perhaps the second disclosure policy, following Simple Nomad's. \nThe policy gives the vendor five working days to respond to the reporter of the bug. If the vendor fails to contact the reporter within those five days, the issue is recommended to be disclosed to the general community. The reporter should help the vendor reproduce the bug and work out a fix. The reporter should delay notifying the general community about the bug if the vendor provides feasible reasons for requiring so.\nIf the vendor fails to respond or shuts down communication with the reporter of the problem within five working days, the reporter should disclose the issue to the general community. When issuing an alert or fix, the vendor should give the reporter proper credit for reporting the bug.\nContext for the history of vulnerability disclosure is available in a history article.",
    "link": "https://en.wikipedia.org/wiki/RFPolicy"
  },
  {
    "title": "List of security hacking incidents",
    "slug": "list-of-security-hacking-incidents",
    "content": "The list of security hacking incidents covers important or noteworthy events in the history of security hacking and cracking.",
    "link": "https://en.wikipedia.org/wiki/List_of_security_hacking_incidents"
  },
  {
    "title": "Hardening (computing)",
    "slug": "hardening-computing",
    "content": "In computer security, hardening or system hardening is usually the process of securing a system by making it a 'hard target' by reducing its attack surface vulnerabilities. The attack surface is larger when a system performs more functions; in principle a single-function system is more secure than a multipurpose one. Hardening is considered an important component of cybersecurity.\nReducing available ways of attack typically includes changing default passwords, the removal of unnecessary software, unnecessary usernames or logins, and the disabling or removal of unnecessary services. It may also involve patching vulnerabilities and switching off ancillary services that are not essential. Hardening measures can also include setting up intrusion prevention systems, disabling or restricting accounts, reducing file system permissions, using encrypted network connections and enabling host-based network security.",
    "link": "https://en.wikipedia.org/wiki/Hardening_(computing)"
  },
  {
    "title": "List of security-focused operating systems",
    "slug": "list-of-securityfocused-operating-systems",
    "content": "This is a list of operating systems specifically focused on security. Similar concepts include security-evaluated operating systems that have achieved certification from an auditing organization, and trusted operating systems that provide sufficient support for multilevel security and evidence of correctness to meet a particular set of requirements.",
    "link": "https://en.wikipedia.org/wiki/List_of_security-focused_operating_systems"
  },
  {
    "title": "Seccomp",
    "slug": "seccomp",
    "content": "seccomp (short for secure computing) is a computer security facility in the Linux kernel. seccomp allows a process to make a one-way transition into a \"secure\" state where it cannot make any system calls except exit(), sigreturn(), read() and write() to already-open file descriptors. Should it attempt any other system calls, the kernel will either just log the event or terminate the process with SIGKILL or SIGSYS. In this sense, it does not virtualize the system's resources but isolates the process from them entirely.\nseccomp mode is enabled via the prctl(2) system call using the PR_SET_SECCOMP argument, or (since Linux kernel 3.17) via the seccomp(2) system call. seccomp mode used to be enabled by writing to a file, /proc/self/seccomp, but this method was removed in favor of prctl(). In some kernel versions, seccomp disables the RDTSC x86 instruction, which returns the number of elapsed processor cycles since power-on, used for high-precision timing.\nseccomp-bpf is an extension to seccomp that allows filtering of system calls using a configurable policy implemented using Berkeley Packet Filter rules. It is used by OpenSSH and vsftpd as well as the Google Chrome/Chromium web browsers on ChromeOS and Linux. (In this regard seccomp-bpf achieves similar functionality, but with more flexibility and higher performance, to the older systrace—which seems to be no longer supported for Linux.)\nSome consider seccomp comparable to OpenBSD pledge(2) and FreeBSD capsicum(4).",
    "link": "https://en.wikipedia.org/wiki/Seccomp"
  },
  {
    "title": "Secure environment",
    "slug": "secure-environment",
    "content": "In computing, a secure environment is any system which implements the controlled storage and use of information.  In the event of computing data loss, a secure environment is used to protect personal or confidential data. It may also be known as a trusted execution environment (TEE).\nOften, secure environments employ cryptography as a means to protect information. This is typically used for processing confidential or restricted information.\nSome secure environments employ cryptographic hashing, simply to verify that the information has not been altered since it was last modified.",
    "link": "https://en.wikipedia.org/wiki/Secure_environment"
  },
  {
    "title": "Parkerian Hexad",
    "slug": "parkerian-hexad",
    "content": "The Parkerian Hexad is a set of six elements of information security proposed by Donn B. Parker in 1998. The Parkerian Hexad adds three additional attributes to the three classic security attributes of the CIA triad (confidentiality, integrity, availability).\nThe Parkerian Hexad attributes are the following:\n\nConfidentiality\nPossession or Control\nIntegrity\nAuthenticity\nAvailability\nUtility\nThese attributes of information are atomic in that they are not broken down into further constituents; they are non-overlapping in that they refer to unique aspects of information. Any information security breach can be described as affecting one or more of these fundamental attributes of information.",
    "link": "https://en.wikipedia.org/wiki/Parkerian_Hexad"
  },
  {
    "title": "Nobody (username)",
    "slug": "nobody-username",
    "content": "In many Unix variants, \"nobody\" is the conventional name of a user identifier which owns no files, is in no privileged groups, and has no abilities except those which every other user has. It is normally not enabled as a user account, i.e. has no home directory or login credentials assigned. Some systems also define an equivalent group \"nogroup\".",
    "link": "https://en.wikipedia.org/wiki/Nobody_(username)"
  },
  {
    "title": "Physical information security",
    "slug": "physical-information-security",
    "content": "Physical information security is the intersection or common ground between physical security and information security.  It primarily concerns the protection of tangible information-related assets such as computer systems and storage media against physical, real-world threats such as unauthorized physical access, theft, fire and flood.  It typically involves physical controls such as protective barriers and locks, uninterruptible power supplies, and shredders.  Information security controls in the physical domain complement those in the logical domain (such as encryption), and procedural or administrative controls (such as information security awareness and compliance with policies and laws).",
    "link": "https://en.wikipedia.org/wiki/Physical_information_security"
  },
  {
    "title": "Public computer",
    "slug": "public-computer",
    "content": "A public computer (or public access computer) is any of various computers available in public areas. Some places where public computers may be available are libraries, schools, or dedicated facilities run by government.\nPublic computers share similar hardware and software components to personal computers, however, the role and function of a public access computer is entirely different. A public access computer is used by many different untrusted individuals throughout the course of the day. The computer must be locked down and secure against both intentional and unintentional abuse. Users typically do not have authority to install software or change settings. A personal computer, in contrast, is typically used by a single responsible user, who can customize the machine's behavior to their preferences.\nPublic access computers are often provided with tools such as a PC reservation system to regulate access.\nThe world's first public access computer center was the Marin Computer Center in California, co-founded by David and Annie Fox in 1977.",
    "link": "https://en.wikipedia.org/wiki/Public_computer"
  },
  {
    "title": "HTTP tunnel",
    "slug": "http-tunnel",
    "content": "HTTP tunneling is used to create a network link between two computers in conditions of restricted network connectivity including firewalls, NATs and ACLs, among other restrictions. The tunnel is created by an intermediary called a proxy server which is usually located in a DMZ.\nTunneling can also allow communication using a protocol that normally wouldn’t be supported on the restricted network.",
    "link": "https://en.wikipedia.org/wiki/HTTP_tunnel"
  },
  {
    "title": "Record sealing",
    "slug": "record-sealing",
    "content": "Record sealing is the process of making public records inaccessible to the public.\nIn many cases, a person with a sealed record gains the legal right to deny or not acknowledge anything to do with the arrest and the legal proceedings from the case itself.\nRecords are commonly sealed in a number of situations:\n\nSealed birth records (typically after adoption or determination of paternity)\nJuvenile criminal records may be sealed\nOther types of cases involving juveniles may be sealed, anonymized, or pseudonymized (\"impounded\"); e.g., child sex offense or custody cases\nCases using witness protection information may be partly sealed\nCases involving trade secrets\nCases involving state secrets",
    "link": "https://en.wikipedia.org/wiki/Record_sealing"
  },
  {
    "title": "Physical access",
    "slug": "physical-access",
    "content": "Physical access is a term in computer security that refers to the ability of people to physically gain access to a computer system. According to Gregory White, \"Given physical access to an office, the knowledgeable attacker will quickly be able to find the information needed to gain access to the organization's computer systems and network.\"",
    "link": "https://en.wikipedia.org/wiki/Physical_access"
  },
  {
    "title": "IEEE 1667",
    "slug": "ieee-1667",
    "content": "IEEE 1667 (\"Standard Protocol for Authentication in Host Attachments of Transient Storage Devices\") is a standard published and maintained by the IEEE that describes various methods for authenticating removable storage devices such as USB flash drives when they are inserted into a computer. The protocol is universal, and thus operating-system independent. It is currently part of Windows Vista (SP2) and Windows 7, Server 2008, Server 2012, Windows 8, Windows 8.1, Windows 10 and Windows 11.",
    "link": "https://en.wikipedia.org/wiki/IEEE_1667"
  },
  {
    "title": "Secure coding",
    "slug": "secure-coding",
    "content": "Secure coding is the practice of developing computer software in such a way that guards against the accidental introduction of security vulnerabilities. Defects, bugs and logic flaws are consistently the primary cause of commonly exploited software vulnerabilities. Through the analysis of thousands of reported vulnerabilities, security professionals have discovered that most vulnerabilities stem from a relatively small number of common software programming errors. By identifying the insecure coding practices that lead to these errors and educating developers on secure alternatives, organizations can take proactive steps to help significantly reduce or eliminate vulnerabilities in software before deployment.\nSome scholars have suggested that in order to effectively confront threats related to cybersecurity, proper security should be coded or “baked in” to the systems. With security being designed into the software, this ensures that there will be protection against insider attacks and reduces the threat to application security.",
    "link": "https://en.wikipedia.org/wiki/Secure_coding"
  },
  {
    "title": "Open-source software security",
    "slug": "opensource-software-security",
    "content": "Open-source software security is the measure of assurance or guarantee in the freedom from danger and risk inherent to an open-source software system.",
    "link": "https://en.wikipedia.org/wiki/Open-source_software_security"
  },
  {
    "title": "Pwnie Awards",
    "slug": "pwnie-awards",
    "content": "The Pwnie Awards recognize both excellence and incompetence in the field of information security. Winners are selected by a committee of security industry professionals from nominations collected from the information security community. Nominees are announced yearly at Summercon, and the awards themselves are presented at the Black Hat Security Conference.",
    "link": "https://en.wikipedia.org/wiki/Pwnie_Awards"
  },
  {
    "title": "IT baseline protection",
    "slug": "it-baseline-protection",
    "content": "The IT baseline protection (German: IT-Grundschutz) approach from the German Federal Office for Information Security (BSI) is a methodology to identify and implement computer security measures in an organization. The aim is the achievement of an adequate and appropriate level of security for IT systems. To reach this goal the BSI recommends \"well-proven technical, organizational, personnel, and infrastructural safeguards\". Organizations and federal agencies show their systematic approach to secure their IT systems (e.g. Information Security Management System) by obtaining an ISO/IEC 27001 Certificate on the basis of IT-Grundschutz.",
    "link": "https://en.wikipedia.org/wiki/IT_baseline_protection"
  },
  {
    "title": "HEAT LANrev",
    "slug": "heat-lanrev",
    "content": "HEAT LANrev (formerly Absolute Manage) is systems lifecycle management software used by system administrators to automate IT administration tasks. The product includes server and client (\"agent\") software that runs on Windows and macOS.",
    "link": "https://en.wikipedia.org/wiki/HEAT_LANrev"
  },
  {
    "title": "System integrity",
    "slug": "system-integrity",
    "content": "In telecommunications, the term system integrity has the following meanings: \n\nThat condition of a system wherein its mandated operational and technical parameters are within the prescribed limits.\nThe quality of an AIS when it performs its intended function in an unimpaired manner, free from deliberate or inadvertent unauthorized manipulation of the system.\nThe state that exists when there is complete assurance that under all conditions an IT system is based on the logical correctness and reliability of the operating system, the logical completeness of the hardware and software that implement the protection mechanisms, and data integrity.",
    "link": "https://en.wikipedia.org/wiki/System_integrity"
  },
  {
    "title": "Trustworthy computing",
    "slug": "trustworthy-computing",
    "content": "The term trustworthy computing (TwC) has been applied to computing systems that are inherently secure, available, and reliable. It is particularly associated with the Microsoft initiative of the same name, launched in 2002.",
    "link": "https://en.wikipedia.org/wiki/Trustworthy_computing"
  },
  {
    "title": "Site Security Handbook",
    "slug": "site-security-handbook",
    "content": "The Site Security Handbook, RFC 2196, is a guide on setting computer security policies and procedures for sites that have systems on the Internet (however, the information provided should also be useful to sites not yet connected to the Internet).  The guide lists issues and factors that a site must consider when setting their own policies.  It makes a number of recommendations and provides discussions of relevant areas.\nThis guide is only a framework for setting security policies and procedures.  In order to have an effective set of policies and procedures, a site will have to make many decisions, gain agreement, and then communicate and implement these policies.\nThe guide is a product of the IETF SSH working group, and was published in 1997, obsoleting the earlier RFC 1244 from 1991.",
    "link": "https://en.wikipedia.org/wiki/Site_Security_Handbook"
  },
  {
    "title": "Security awareness",
    "slug": "security-awareness",
    "content": "Security awareness is the knowledge and attitude members of an organization possess regarding the protection of the physical, and especially informational, assets of that organization. However, it is very tricky to implement because organizations are not able to impose such awareness directly on employees as there are no ways to explicitly monitor people's behavior. That being said, the literature does suggest several ways that such security awareness could be improved. Many organizations require formal security awareness training for all workers when they join the organization and periodically thereafter, usually annually. Another main force that is found to have a strong correlation with employees' security awareness is managerial security participation. It also bridges security awareness with other organizational aspects.",
    "link": "https://en.wikipedia.org/wiki/Security_awareness"
  },
  {
    "title": "Secure state",
    "slug": "secure-state",
    "content": "A secure state is an information systems security term to describe where entities in a computer system are divided into subjects and objects, and it can be formally proven that each state transition preserves security by moving from one secure state to another secure state. Thereby it can be inductively proven that the system is secure. As defined in the Bell–LaPadula model, the secure state is built on the concept of a state machine with a set of allowable states in a system. The transition from one state to another state is defined by transition functions.\nA system state is defined to be \"secure\" if the only permitted access modes of subjects to objects are in accordance with a security policy.",
    "link": "https://en.wikipedia.org/wiki/Secure_state"
  },
  {
    "title": "Security information management",
    "slug": "security-information-management",
    "content": "Security information management (SIM) is an information security industry term for the collection of data such as log files into a central repository for trend analysis.",
    "link": "https://en.wikipedia.org/wiki/Security_information_management"
  },
  {
    "title": "Amazon Elastic Compute Cloud",
    "slug": "amazon-elastic-compute-cloud",
    "content": "Amazon Elastic Compute Cloud (EC2) is a part of Amazon's cloud-computing platform, Amazon Web Services (AWS), that allows users to rent virtual computers on which to run their own computer applications. EC2 encourages scalable deployment of applications by providing a web service through which a user can boot an Amazon Machine Image (AMI) to configure a virtual machine, which Amazon calls an \"instance\", containing any software desired. A user can create, launch, and terminate server-instances as needed, paying by the second for active servers – hence the term \"elastic\". EC2 provides users with control over the geographical location of instances that allows for latency optimization and high levels of redundancy. In November 2010, Amazon switched its own retail website platform to EC2 and AWS.",
    "link": "https://en.wikipedia.org/wiki/Amazon_Elastic_Compute_Cloud"
  },
  {
    "title": "WS-SecurityPolicy",
    "slug": "wssecuritypolicy",
    "content": "WS-Security Policy is a web services specification, created by IBM and 12 co-authors, that has become an OASIS standard as of version 1.2. It extends the fundamental security protocols specified by the WS-Security, WS-Trust and WS-Secure Conversation by offering mechanisms to represent the capabilities and requirements of web services as policies. Security policy assertions are based on the WS-Policy framework. \nPolicy assertions can be used to require more generic security attributes like transport layer security <TransportBinding>, message level security <AsymmetricBinding> or timestamps, and specific attributes like token types. \nMost policy assertion can be found in following categories:\n\nProtection assertions identify the elements of a message that are required to be signed, encrypted or existent.\nToken assertions specify allowed token formats (SAML, X509, Username etc.).\nSecurity binding assertions control basic security safeguards like transport and message level security, cryptographic algorithm suite and required timestamps.\nSupporting token assertions add functions like user sign-on using a username token.\nPolicies can be used to drive development tools to generate code with certain capabilities, or may be used at runtime to negotiate the security aspects of web service communication. Policies may be attached to WSDL elements such as service, port, operation and message, as defined in WS Policy Attachment.",
    "link": "https://en.wikipedia.org/wiki/WS-SecurityPolicy"
  },
  {
    "title": "Sherwood Applied Business Security Architecture",
    "slug": "sherwood-applied-business-security-architecture",
    "content": "SABSA (Sherwood Applied Business Security Architecture) is a model and methodology for developing a risk-driven enterprise information security architecture and service management, to support critical business processes. It was developed independently from the Zachman Framework, but has a similar structure. The primary characteristic of the SABSA model is that everything must be derived from an analysis of the business requirements for security, especially those in which security has an enabling function through which new business opportunities can be developed and exploited.\nThe process analyzes the business requirements at the outset, and creates a chain of traceability through the strategy and concept, design, implementation, and ongoing ‘manage and measure’ phases of the lifecycle to ensure that the business mandate is preserved.  Framework tools created from practical experience further support the whole methodology.  \nThe model is layered, with the top layer being the business requirements definition stage.  At each lower layer a new level of abstraction and detail is developed, going through the definition of the conceptual architecture, logical services architecture, physical infrastructure architecture and finally at the lowest layer, the selection of technologies and products (component architecture). \nThe SABSA model itself is generic and can be the starting point for any organization, but by going through the process of analysis and decision-making implied by its structure, it becomes specific to the enterprise, and is finally highly customized to a unique business model.  It becomes in reality the enterprise security architecture, and it is central to the success of a strategic program of information security management within the organization. \nSABSA is a particular example of a methodology that can be used both for IT (information technology) and OT (operational technology) environments.",
    "link": "https://en.wikipedia.org/wiki/Sherwood_Applied_Business_Security_Architecture"
  },
  {
    "title": "Zardoz (computer security)",
    "slug": "zardoz-computer-security",
    "content": "In computer security, the Security-Digest list, better known as the Zardoz list, was a semi-private full disclosure mailing list run by Neil Gorsuch from 1989 through 1991. It identified weaknesses in systems and gave directions on where to find them. It was a perennial target for computer hackers, who sought archives of the list for information on undisclosed software vulnerabilities.",
    "link": "https://en.wikipedia.org/wiki/Zardoz_(computer_security)"
  },
  {
    "title": "Zero-day vulnerability",
    "slug": "zeroday-vulnerability",
    "content": "A zero-day (also known as a 0-day) is a vulnerability or security hole in a computer system unknown to its developers or anyone capable of mitigating it. Until the vulnerability is remedied, threat actors can exploit it in a zero-day exploit, or zero-day attack.\nThe term \"zero-day\" originally referred to the number of days since a new piece of software was released to the public, so \"zero-day software\" was obtained by hacking into a developer's computer before release. Eventually the term was applied to the vulnerabilities that allowed this hacking, and to the number of days that the vendor has had to fix them. Vendors who discover the vulnerability may create patches or advise workarounds to mitigate it, though users need to deploy that mitigation to eliminate the vulnerability in their systems. Zero-day attacks are severe threats.",
    "link": "https://en.wikipedia.org/wiki/Zero-day_vulnerability"
  },
  {
    "title": "Cloud computing",
    "slug": "cloud-computing",
    "content": "Cloud computing is defined by the ISO as \"a paradigm for enabling network access to a scalable and elastic pool of shareable physical or virtual resources with self-service provisioning and administration on demand\". It is commonly referred to as \"the cloud\".",
    "link": "https://en.wikipedia.org/wiki/Cloud_computing"
  },
  {
    "title": "Vulnerability Discovery Model",
    "slug": "vulnerability-discovery-model",
    "content": "A Vulnerability Discovery Model (VDM) uses discovery event data with software reliability models for predicting the same.    A thorough presentation of VDM techniques is available in.  Numerous model implementations are available in the MCMCBayes open source repository.  Several VDM examples include:\n\nAlhazmi-Malaiya: Time based model (Alhazmi-Malaiya Logistic (AML) model)\nAlhazmi-Malaiya: Effort based model\nRescorla: Quadratic Model and Exponential Model \nAnderson: Thermodynamic Model\nKim: Weibull Model\nLinear Model\nHump-Shaped Model\nIndependent and Dependent Model\nVulnerability Discovery Modeling using Bayesian model averaging\nMultivariate Vulnerability Discovery Models",
    "link": "https://en.wikipedia.org/wiki/Vulnerability_Discovery_Model"
  },
  {
    "title": "Vanish (computer science)",
    "slug": "vanish-computer-science",
    "content": "Vanish was a project to \"give users control over the lifetime of personal data stored on the web.\" It was led by Roxana Geambasu at the University of Washington.  The project proposed to allow a user to enter information to send across the internet, thereby relinquishing control of it. However, the user can include an \"expiration date,\" after which the information is no longer usable by anyone who may have a copy of it, even the creator.  The Vanish approach was found to be vulnerable to a Sybil attack and thus insecure by a team called Unvanish from the University of Texas, University of Michigan, and Princeton.",
    "link": "https://en.wikipedia.org/wiki/Vanish_(computer_science)"
  },
  {
    "title": "Shell Control Box",
    "slug": "shell-control-box",
    "content": "Shell Control Box (SCB) is a network security appliance that controls privileged access to remote IT systems, records activities in replayable audit trails, and prevents malicious actions. For example, it records as a system administrator updates a file server or a third-party network operator configures a router. The recorded audit trails can be replayed like a movie to review the events as they occurred. The content of the audit trails is indexed to make searching for events and automatic reporting possible.\nSCB is a Linux-based device developed by Balabit. It is an application level proxy gateway. In 2017, Balabit changed the name of the product to Privileged Session Management (PSM) and repositioned it as the core module of its Privileged Access Management solution.",
    "link": "https://en.wikipedia.org/wiki/Shell_Control_Box"
  },
  {
    "title": "System Service Descriptor Table",
    "slug": "system-service-descriptor-table",
    "content": "The System Service Descriptor Table (SSDT) is an internal dispatch table within Microsoft Windows.",
    "link": "https://en.wikipedia.org/wiki/System_Service_Descriptor_Table"
  },
  {
    "title": "Apache Hama",
    "slug": "apache-hama",
    "content": "Apache Hama  is a distributed computing framework based on bulk synchronous parallel computing techniques for massive scientific computations e.g., matrix, graph and network algorithms. Originally a sub-project of Hadoop, it became an Apache Software Foundation top level project in 2012. It was created by Edward J. Yoon, who named it (short for \"Hadoop Matrix Algebra\"), and Hama also means hippopotamus in Yoon's native Korean language (하마), following the trend of naming Apache projects after animals and zoology (such as Apache Pig). Hama was inspired by Google's Pregel large-scale graph computing framework described in 2010. When executing graph algorithms, Hama showed a fifty-fold performance increase relative to Hadoop.\nRetired in April 2020, project resources are made available as part of the Apache Attic. Yoon cited issues of installation, scalability, and a difficult programming model for its lack of adoption.",
    "link": "https://en.wikipedia.org/wiki/Apache_Hama"
  },
  {
    "title": "Digital supply chain security",
    "slug": "digital-supply-chain-security",
    "content": "Digital supply chain security refers to efforts to enhance cyber security within the supply chain. It is a subset of supply chain security and is  focused on the management of cyber security requirements for information technology systems, software and networks, which are driven by threats such as cyber-terrorism, malware, data theft and the advanced persistent threat (APT). Typical supply chain cyber security activities for minimizing risks include buying only from trusted vendors, disconnecting critical machines from outside networks, and educating users on the threats and protective measures they can take.\nThe acting deputy undersecretary for the National Protection and Programs Directorate for the United States Department of Homeland Security, Greg Schaffer, stated at a hearing that he is aware that there are instances where malware has been found on imported electronic and computer devices sold within the United States.",
    "link": "https://en.wikipedia.org/wiki/Digital_supply_chain_security"
  },
  {
    "title": "Abiquo Enterprise Edition",
    "slug": "abiquo-enterprise-edition",
    "content": "Abiquo Hybrid Cloud Management Platform is a web-based cloud computing software platform developed by\nAbiquo. Written entirely in Java, it is used to build, integrate and manage public and private clouds in homogeneous environments. Users can deploy and manage servers, storage system and network and virtual devices. It also supports LDAP integration.",
    "link": "https://en.wikipedia.org/wiki/Abiquo_Enterprise_Edition"
  },
  {
    "title": "The Business Cloud",
    "slug": "the-business-cloud",
    "content": "The Business Cloud is an API enabled self-service platform, developed by Domo, that provides an array of services like data connection and data visualization.",
    "link": "https://en.wikipedia.org/wiki/The_Business_Cloud"
  },
  {
    "title": "Centralized computing",
    "slug": "centralized-computing",
    "content": "Centralized computing is computing done at a central location, using terminals that are attached to a central computer. The computer itself may control all the peripherals directly (if they are physically connected to the central computer), or they may be attached via a terminal server. Alternatively, if the terminals have the capability, they may be able to connect to the central computer over the network. The terminals may be text terminals or thin clients, for example.\nIt offers greater security over decentralized systems because all of the processing is controlled in a central location. In addition, if one terminal breaks down, the user can simply go to another terminal and log in again, and all of their files will still be accessible. Depending on the system, they may even be able to resume their session from the point they were at before, as if nothing had happened.\nThis type of arrangement does have some disadvantages. The central computer performs the computing functions and controls the remote terminals. This type of system relies totally on the central computer. Should the central computer crash, the entire system will \"go down\" (i.e. will be unavailable).\nAnother disadvantage is that central computing relies heavily on the quality of administration and resources provided to its users.  Should the central computer be inadequately supported by any means (e.g. size of home directories, problems regarding administration), then your usage will suffer greatly.  The reverse situation, however, (i.e., a system supported better than your needs) is one of the key advantages to centralized computing.",
    "link": "https://en.wikipedia.org/wiki/Centralized_computing"
  },
  {
    "title": "Cloud testing",
    "slug": "cloud-testing",
    "content": "Cloud testing is a form of software testing in which web applications use cloud computing environments (a \"cloud\") to simulate real-world user traffic.",
    "link": "https://en.wikipedia.org/wiki/Cloud_testing"
  },
  {
    "title": "Cloud Computing Manifesto",
    "slug": "cloud-computing-manifesto",
    "content": "The Cloud Computing Manifesto is a manifesto containing a \"public declaration of principles and intentions\" for cloud computing providers and vendors, annotated as \"a call to action for the worldwide cloud community\" and \"dedicated belief that the cloud should be open\". It follows the earlier development of the Cloud Computing Bill of Rights which addresses similar issues from the users' point of view.\nThe document was developed \"by way of an open community consensus process\" in response to a request by Microsoft that \"any 'manifesto' should be created, from its inception, through an open mechanism like a Wiki, for public debate and comment, all available through a Creative Commons license\". Accordingly, it is hosted on a MediaWiki wiki and licensed under the CC-BY-SA 3.0 license.\nThe original, controversial version of the document called the Open Cloud Manifesto was sharply criticised by Microsoft who \"spoke out vehemently against it\" for being developed in secret by a \"shadowy group of IT industry companies\", raising questions about conflicts of interest and resulting in extensive media coverage over the following days. A pre-announcement commits to the official publication of this document on 30 March 2009 (in spite of calls to publish it earlier), at which time the identities of the signatories (\"several of the largest technology companies and organizations\" led by IBM along with OMG and believed also to include Cisco, HP, and Sun Microsystems) is said to be revealed. Amazon, Google, Microsoft and Salesforce.com are among those known to have rejected the document by declining to be signatories. The document was leaked by Geva Perry in a blog post on 27 March 2009 and confirmed to be authentic shortly afterwards.\nThe authors of both public and private documents have agreed to \"work to bring together the best points of each effort\".",
    "link": "https://en.wikipedia.org/wiki/Cloud_Computing_Manifesto"
  },
  {
    "title": "Cloud communications",
    "slug": "cloud-communications",
    "content": "Cloud communications are Internet-based voice and data communications where telecommunications applications, switching and storage are hosted by a third-party outside of the organization using them, and they are accessed over the public Internet. Cloud services is a broad term, referring primarily to data-center-hosted services that are run and accessed over an Internet infrastructure. Until recently, these services have been data-centric, but with the evolution of VoIP (voice over Internet protocol), voice has become part of the cloud phenomenon.  Cloud telephony (also known as hosted telephony) refers specifically to voice services and more specifically the replacement of conventional business telephone equipment, such as a private branch exchange (PBX), with third-party VoIP service.\nCloud communications providers deliver voice and data communications applications and services, hosting them on servers that the providers own and maintain, giving their customers access to the “cloud.” Because they only pay for services or applications they use, customers have a more cost-effective, reliable and secure communications environment, without the headaches associated with more conventional PBX system deployment.\nCompanies can cut costs with cloud communications services without sacrificing features. The success of Google and others as cloud-based providers has demonstrated that a cloud-based platform can be just as effective as a software-based platform, but at a much lower cost. Voice services delivered from the cloud increases the value of hosted telephony, as users can equally well turn to a cloud-based offering instead of relying on a facilities-based service provider for hosted VoIP. This expands their options beyond local or regional carriers.\nIn the past, businesses have been able to do this for IT services, but not telecommunication. Cloud communications is attractive because the cloud can now become a platform for voice, data and video. Most hosted services have been built around voice, and are usually referred to as hosted VoIP. The cloud communications environment serves as a platform upon which all these modes can seamlessly work as well as integrate.\nThere are three trends in enterprise communications pushing users to access the cloud and allowing them to do it from any device they choose, a development traditional IT communications infrastructure was not designed to handle. The first trend is increasingly distributed company operations in branches and home offices, making wide area networks cumbersome, inefficient and costly. Second, more communications devices need access to enterprise networks – iPhones, printers and VoIP handsets, for example. Third, data centers housing enterprise IT assets and applications are consolidating and are often being located and managed remotely.",
    "link": "https://en.wikipedia.org/wiki/Cloud_communications"
  },
  {
    "title": "C-RAN",
    "slug": "cran",
    "content": "C-RAN (Cloud-RAN), also referred to as Centralized-RAN, is an architecture for cellular networks. C-RAN is a centralized, cloud computing-based architecture for radio access networks that supports 2G, 3G, 4G, 5G and future wireless communication standards. Its name comes from the four 'C's in the main characteristics of C-RAN system, \"Clean, Centralized processing, Collaborative radio, and a real-time Cloud Radio Access Network\".",
    "link": "https://en.wikipedia.org/wiki/C-RAN"
  },
  {
    "title": "Cloud Foundry",
    "slug": "cloud-foundry",
    "content": "Cloud Foundry is an open source, multi-cloud application platform as a service (PaaS) governed by the Cloud Foundry Foundation, a 501(c)(6) organization.\nThe software was originally developed by VMware, transferred to Pivotal Software (a joint venture by EMC, VMware and General Electric), who then transferred the software to the Cloud Foundry Foundation upon its inception in 2015.",
    "link": "https://en.wikipedia.org/wiki/Cloud_Foundry"
  },
  {
    "title": "Cloud manufacturing",
    "slug": "cloud-manufacturing",
    "content": "Cloud manufacturing (CMfg) is a new manufacturing paradigm developed from existing advanced manufacturing models (e.g., ASP, AM, NM, MGrid) and enterprise information technologies under the support of cloud computing, Internet of Things (IoT), virtualization and service-oriented technologies, and advanced computing technologies. It transforms manufacturing resources and manufacturing capabilities into manufacturing services, which can be managed and operated in an intelligent and unified way to enable the full sharing and circulating of manufacturing resources and manufacturing capabilities. CMfg can provide safe and reliable, high quality, cheap and on-demand manufacturing services for the whole lifecycle of manufacturing. The concept of manufacturing here refers to big manufacturing that includes the whole lifecycle of a product (e.g. design, simulation, production, test, maintenance). \nThe concept of Cloud manufacturing was initially proposed by the research group led by Prof. Bo Hu Li and Prof. Lin Zhang in China in 2010.\n\n Related discussions and research were conducted hereafter, and some similar definitions (e.g. Cloud-Based Design and Manufacturing (CBDM).\n) to cloud manufacturing were introduced.\nCloud manufacturing is a type of parallel, networked, and distributed system consisting of an integrated and inter-connected virtualized service pool (manufacturing cloud) of manufacturing resources and capabilities as well as capabilities of intelligent management and on-demand use of services to provide solutions for all kinds of users involved in the whole lifecycle of manufacturing.",
    "link": "https://en.wikipedia.org/wiki/Cloud_manufacturing"
  },
  {
    "title": "Cloud-to-cloud integration",
    "slug": "cloudtocloud-integration",
    "content": "Cloud-to-Cloud Integration ( C2I ) allows users to connect disparate cloud computing platforms.  While Paas (Platform as a service) and Saas (Software as a service) continue to gain momentum, different vendors have different implementations for cloud computing, e.g. Database, REST, SOAP API.\nAnother name for Cloud-to-Cloud Integration is Cloud-Surfing.\nSee also Cloud-based integration",
    "link": "https://en.wikipedia.org/wiki/Cloud-to-cloud_integration"
  },
  {
    "title": "Cloudflare",
    "slug": "cloudflare",
    "content": "Cloudflare, Inc. is an American technology company headquartered in San Francisco, California, that provides a range of internet services, including content delivery network (CDN) services, cloud cybersecurity, DDoS mitigation, and ICANN-accredited domain registration. The company's services act primarily as a reverse proxy between website visitors and a customer's hosting provider, improving performance and protecting against malicious traffic.\nCloudflare was founded in 2009 by Matthew Prince, Lee Holloway, and Michelle Zatlyn. The company went public on the New York Stock Exchange in 2019 under the ticker symbol NET. Cloudflare has since expanded its offerings to include edge computing through its Workers platform, a public DNS resolver (1.1.1.1), and a VPN service known as WARP. In recent years, the company has integrated artificial intelligence into its infrastructure, acquiring companies such as Replicate and launching tools to manage AI bots and scrapers. According to W3Techs, Cloudflare is used by approximately 21.3% of all websites on the Internet as of January 2026.\nThe company has been the subject of controversy regarding its policy of content neutrality. While Cloudflare executives have historically advocated for remaining a neutral infrastructure provider, the company has terminated services for specific high-profile websites associated with hate speech and violence, including The Daily Stormer, 8chan, and Kiwi Farms, following significant public pressure. Cloudflare has also faced criticism and litigation regarding copyright infringement by websites using its services, notably losing a lawsuit against Japanese publishers in 2025. The company experienced significant global outages in late 2025 which disrupted services for major platforms internationally.",
    "link": "https://en.wikipedia.org/wiki/Cloudflare"
  },
  {
    "title": "Cloud database",
    "slug": "cloud-database",
    "content": "A cloud database is a database that typically runs on a cloud computing platform and access to the database is provided as-a-service. There are two common deployment models: users can run databases on the cloud independently, using a virtual machine image, or they can purchase access to a database service, maintained by a cloud database provider. Of the databases available on the cloud, some are SQL-based and some use a NoSQL data model.\nDatabase services take care of scalability and high availability of the database. Database services make the underlying software-stack transparent to the user.",
    "link": "https://en.wikipedia.org/wiki/Cloud_database"
  },
  {
    "title": "Cloud-computing comparison",
    "slug": "cloudcomputing-comparison",
    "content": "The following is a comparison of cloud-computing software and providers.",
    "link": "https://en.wikipedia.org/wiki/Cloud-computing_comparison"
  },
  {
    "title": "Carrier cloud",
    "slug": "carrier-cloud",
    "content": "In cloud computing, a carrier cloud is a class of cloud that integrates wide area networks (WAN) and other attributes of communications service providers’ carrier-grade networks to enable the deployment of highly-complex applications in the cloud. In contrast, classic cloud computing focuses on the data center and does not address the network connecting data centers and cloud users. This may result in unpredictable response times and security issues when business-critical data are transferred over the Internet.",
    "link": "https://en.wikipedia.org/wiki/Carrier_cloud"
  },
  {
    "title": "Cloud collaboration",
    "slug": "cloud-collaboration",
    "content": "Cloud collaboration is a method of sharing and co-authoring computer files via cloud computing, whereby documents are uploaded to a central \"cloud\" for storage, where they can then be accessed by other users.\nCloud collaboration technologies allow users to upload, comment and collaborate on documents and even amend the document itself, evolving the document. Businesses in the last few years have increasingly been switching to use of cloud collaboration.",
    "link": "https://en.wikipedia.org/wiki/Cloud_collaboration"
  },
  {
    "title": "Community cloud",
    "slug": "community-cloud",
    "content": "A  community cloud in computing is a collaborative effort in which infrastructure is shared between several organizations from a specific community with common concerns (security, compliance, jurisdiction, etc.), whether managed internally or by a third party and hosted internally or externally.  This is controlled and used by a group of organizations that have shared interests. The costs are spread over fewer users than a public cloud (but more than a private cloud), so only some of the cost savings potential of cloud computing are realized.\nThe community cloud is provisioned for use by a group of consumers from different organizations who share the same concerns (e.g., application, security, policy, and efficiency demands).",
    "link": "https://en.wikipedia.org/wiki/Community_cloud"
  },
  {
    "title": "Carrenza",
    "slug": "carrenza",
    "content": "Carrenza was a cloud-computing company based in London, United Kingdom. The company was acquired by Six Degrees Technology Group in 2016.",
    "link": "https://en.wikipedia.org/wiki/Carrenza"
  },
  {
    "title": "Cloud computing architecture",
    "slug": "cloud-computing-architecture",
    "content": "Cloud computing architecture refers to the components and subcomponents required for cloud computing.  These components typically consist of a front end platform (fat client, thin client, mobile), back end platforms (servers, storage), a cloud based delivery, and a network (Internet, Intranet, Intercloud). Combined, these components make up cloud computing architecture.",
    "link": "https://en.wikipedia.org/wiki/Cloud_computing_architecture"
  },
  {
    "title": "Cloud printing",
    "slug": "cloud-printing",
    "content": "There are, in essence, three kinds of Cloud printing.",
    "link": "https://en.wikipedia.org/wiki/Cloud_printing"
  },
  {
    "title": "Cloud Security Alliance",
    "slug": "cloud-security-alliance",
    "content": "Cloud Security Alliance (CSA) is a not-for-profit organization with the mission to “promote the use of best practices for providing security assurance within cloud computing, Artificial Intelligence and to provide education on the uses of cloud computing to help secure all other forms of computing.”\nThe CSA has over 80,000 individual members worldwide. CSA gained significant reputability in 2011 when the American Presidential Administration selected the CSA Summit as the venue for announcing the federal government’s cloud computing strategy.",
    "link": "https://en.wikipedia.org/wiki/Cloud_Security_Alliance"
  },
  {
    "title": "Cloud-based integration",
    "slug": "cloudbased-integration",
    "content": "Cloud-based integration is a form of systems integration business delivered as a cloud computing service that addresses data, process, service-oriented architecture (SOA) and application integration.",
    "link": "https://en.wikipedia.org/wiki/Cloud-based_integration"
  },
  {
    "title": "Key distribution",
    "slug": "key-distribution",
    "content": "In symmetric key cryptography, both parties must possess a secret key which they must exchange prior to using any encryption.  Distribution of secret keys has been problematic until recently, because it involved face-to-face meeting, use of a trusted courier, or sending the key through an existing encryption channel.  The first two are often impractical and unsafe, while the third depends on the security of a previous key exchange.\nIn public key cryptography, the key distribution of public keys is done through public key servers. When a person creates a key-pair, they keep one key private and the other, known as the public-key, is uploaded to a server where it can be accessed by anyone to send the user a private, encrypted, message.\nSecure Sockets Layer (SSL) uses Diffie–Hellman key exchange if the client does not have a public-private key pair and a published certificate in the public key infrastructure, and Public Key Cryptography if the user does have both the keys and the credential.\nKey distribution is an important issue in wireless sensor network (WSN) design. There are many key distribution schemes in the literature that are designed to maintain an easy and at the same time secure communication among sensor nodes. The most accepted method of key distribution in WSNs is key predistribution, where secret keys are placed in sensor nodes before deployment. When the nodes are deployed over the target area, the secret keys are used to create the network.\nFor more info see: key distribution in wireless sensor networks.",
    "link": "https://en.wikipedia.org/wiki/Key_distribution"
  },
  {
    "title": "Infrastructure as a service",
    "slug": "infrastructure-as-a-service",
    "content": "Infrastructure as a service (IaaS) is a cloud computing service model where a cloud services vendor provides computing resources such as storage, network, servers, and virtualization (which emulates computer hardware). This service frees users from maintaining their own data center, but they must install and maintain the operating system and application software.  Iaas provides users high-level APIs to control details of underlying network infrastructure such as backup, data partitioning, scaling, security and physical computing resources. Services can be scaled on-demand by the user. According to the Internet Engineering Task Force (IETF), such infrastructure is the most basic cloud-service model. IaaS can be hosted in a public cloud (where users share hardware, storage, and network devices), a private cloud (users do not share resources), or a hybrid cloud (combination of both).",
    "link": "https://en.wikipedia.org/wiki/Infrastructure_as_a_service"
  },
  {
    "title": "Geo-replication",
    "slug": "georeplication",
    "content": "Geo-replication systems are designed to provide improved availability and disaster tolerance by using geographically distributed data centers. This is intended to improve the response time for applications such as web portals. Geo-replication can be achieved using software, hardware or a combination of the two.",
    "link": "https://en.wikipedia.org/wiki/Geo-replication"
  },
  {
    "title": "EyeOS",
    "slug": "eyeos",
    "content": "eyeOS  was a web desktop for cloud computing, whose main purpose is to enable collaboration and communication among users. It is mainly written in PHP, XML, and JavaScript. It is a private-cloud application platform with a web-based desktop interface. eyeOS delivers a whole desktop from the cloud with file management, personal management information tools, and collaborative tools, with the integration of the client's applications.",
    "link": "https://en.wikipedia.org/wiki/EyeOS"
  },
  {
    "title": "Message queuing service",
    "slug": "message-queuing-service",
    "content": "A message queueing service is a message-oriented middleware or MOM deployed in a compute cloud using software as a service model. Service subscribers access queues and or topics to exchange data using point-to-point or publish and subscribe patterns.\nIt's important to differentiate between event-driven and message-driven (aka queue driven) services: Event-driven services (e.g. AWS SNS) are decoupled from their consumers. Whereas queue / message driven services (e.g. AWS SQS) are coupled with their consumers.\nMessage queues can be a good buffer to handle spiky workloads but they have a finite capacity. According to Gregor Hohpe, message queues require proper mechanisms (aka flow controls) to avoid filling the queue beyond its manageable capacity and to keep the system stable.",
    "link": "https://en.wikipedia.org/wiki/Message_queuing_service"
  },
  {
    "title": "Fabric computing",
    "slug": "fabric-computing",
    "content": "Fabric computing or unified computing involves constructing a computing fabric consisting of interconnected nodes that look like a weave or a fabric when seen collectively from a distance.\nUsually the phrase refers to a consolidated high-performance computing system consisting of loosely coupled storage, networking and parallel processing functions linked by high bandwidth interconnects (such as 10 Gigabit Ethernet and InfiniBand) but the term has also been used to describe platforms such as the Azure Services Platform and grid computing in general (where the common theme is interconnected nodes that appear as a single logical unit).\nThe fundamental components of fabrics are \"nodes\" (processor(s), memory, and/or peripherals) and \"links\" (functional connections between nodes). While the term \"fabric\" has also been used in association with storage area networks and with switched fabric networking, the introduction of compute resources provides a complete \"unified\" computing system. Other terms used to describe such fabrics include \"unified fabric\", \"data center fabric\"  and \"unified data center fabric\".\nIan Foster, director of the Computation Institute at the Argonne National Laboratory and University of Chicago suggested in 2007 that grid computing \"fabrics\" were \"poised to become the underpinning for next-generation enterprise IT architectures and be used by a much greater part of many organizations\".",
    "link": "https://en.wikipedia.org/wiki/Fabric_computing"
  },
  {
    "title": "Hosted desktop",
    "slug": "hosted-desktop",
    "content": "A hosted desktop is a product set within the larger cloud-computing sphere generally delivered using a combination of technologies including hardware virtualization and some form of remote connection software, Citrix XenApp or Microsoft Remote Desktop Services being two of the most common. Processing takes place within the provider's datacenter environment with traffic between the datacenter and the client being primarily display updates, mouse movements and keyboard activity (additional traffic will be generated by audio & print jobs).\nA hosted desktop commonly involves a browser-based connection to a desktop environment which includes an office productivity suite alongside other desktop applications. The desktop is hosted, run, delivered and supported from a central location, usually a secure data center with high-quality and resilient connections to the Internet/cloud. Cloud Desktop is a term often used to refer to a container of a collection of virtual objects, software, hardware, configurations etc., residing on the cloud, used by a client to interact with remote services and perform computer related tasks.\nConnecting clients run pre-installed or downloaded viewer applications via one of many remote desktop protocols. Clients can include thin clients, PCs, workstations, mobile and handheld devices running a variety of operating systems such as Windows, Mac OS X, Linux and others.\nThe move towards hosted desktops, of which virtual desktop infrastructure (VDI) is a subset, is predicted by Gartner to account for 49 million business desktops by 2013 equal to more than 40 percent of the worldwide professional PC market. The development of applications by service providers such as Google and Microsoft have accelerated this process, as has the evolution of new licensing schemes which allow fee-paying based on a subscription rather than on purchase.",
    "link": "https://en.wikipedia.org/wiki/Hosted_desktop"
  },
  {
    "title": "DocuWare",
    "slug": "docuware",
    "content": "DocuWare is cloud-based Software as a Service (SaaS) provider. DocuWare software provides document management, repository, and workflow automation functions (also referred to as enterprise content management (ECM) or content services).\nThe company is headquartered in Germany and the United States.\nDocuWare is also the name of the flagship product offered by the company.",
    "link": "https://en.wikipedia.org/wiki/DocuWare"
  },
  {
    "title": "Granular configuration automation",
    "slug": "granular-configuration-automation",
    "content": "Granular configuration automation (GCA) is a specialized area in the field of configuration management which focuses on visibility and control of an IT environment's configuration and bill-of-material at the most granular level. This framework focuses on improving the stability of IT environments by analyzing granular information. It responds to the requirement to determine a threat level of an environment risk, and to allow IT organizations to focus on those risks with the highest impact on performance. Granular configuration automation combines two major trends in configuration management: the move to collect detailed and comprehensive environment information and the growing utilization of automation tools.",
    "link": "https://en.wikipedia.org/wiki/Granular_configuration_automation"
  },
  {
    "title": "Cooperative storage cloud",
    "slug": "cooperative-storage-cloud",
    "content": "A cooperative storage cloud is a decentralized model of networked online storage where data is stored on multiple computers (nodes), hosted by the participants cooperating in the cloud. For the cooperative scheme to be viable, the total storage contributed in aggregate must be at least equal to the amount of storage needed by end users.  However, some nodes may contribute less storage and some may contribute more.  There may be reward models to compensate the nodes contributing more.\nUnlike a traditional storage cloud, a cooperative does not directly employ dedicated servers for the actual storage of the data, thereby eliminating the need for a significant dedicated hardware investment. Each node in the cooperative runs specialized software which communicates with a centralized control and orchestration server, thereby allowing the node to both consume and contribute storage space to the cloud. The centralized control and orchestration server requires several orders of magnitude less resources (storage, computing power, and bandwidth) to operate, relative to the overall capacity of the cooperative.",
    "link": "https://en.wikipedia.org/wiki/Cooperative_storage_cloud"
  },
  {
    "title": "Apache Hive",
    "slug": "apache-hive",
    "content": "Apache Hive is a data warehouse software project. It is built on top of Apache Hadoop for providing data query and analysis. Hive gives an SQL-like interface to query data stored in various databases and file systems that integrate with Hadoop. Traditional SQL queries must be implemented in the MapReduce Java API to execute SQL applications and queries over distributed data.\nHive provides the necessary SQL abstraction to integrate SQL-like queries (HiveQL) into the underlying Java without the need to implement queries in the low-level Java API. Hive facilitates the integration of SQL-based querying languages with Hadoop, which is commonly used in data warehousing applications. While initially developed by Facebook, Apache Hive is used and developed by other companies such as Netflix and the Financial Industry Regulatory Authority (FINRA). Amazon maintains a software fork of Apache Hive included in Amazon Elastic MapReduce on Amazon Web Services.",
    "link": "https://en.wikipedia.org/wiki/Apache_Hive"
  },
  {
    "title": "Distributed Common Ground System",
    "slug": "distributed-common-ground-system",
    "content": "The Distributed Common Ground System (DCGS) is a system which produces military intelligence for multiple branches of the American military.",
    "link": "https://en.wikipedia.org/wiki/Distributed_Common_Ground_System"
  },
  {
    "title": "Digital omnivore",
    "slug": "digital-omnivore",
    "content": "A digital omnivore is a person who uses multiple modalities (devices) to access the Internet and other media content in their daily life. As people increasingly own mobile devices, cross-platform multimedia consumption has continued to shape the digital landscape, both in terms of the type of media content they consume and how they consume it. As of 2021, at least half of all global digital traffic is generated by mobile devices.",
    "link": "https://en.wikipedia.org/wiki/Digital_omnivore"
  },
  {
    "title": "Managed private cloud",
    "slug": "managed-private-cloud",
    "content": "Managed private cloud (also known as \"hosted private cloud\" or \"single-tenant SaaS\") refers to a principle in software architecture where a single instance of the software runs on a server, serves a single client organization (tenant), and is managed by a third party. The third-party provider is responsible for providing the hardware for the server and also for preliminary maintenance. This is in contrast to multitenancy, where multiple client organizations share a single server, or an on-premises deployment, where the client organization hosts its software instance.\nManaged private clouds also fall under the larger umbrella of cloud computing.",
    "link": "https://en.wikipedia.org/wiki/Managed_private_cloud"
  },
  {
    "title": "Fabric Connect",
    "slug": "fabric-connect",
    "content": "Fabric Connect, in computer networking usage, is the name used by Extreme Networks to market an extended implementation of the IEEE 802.1aq and IEEE 802.1ah-2008 standards.\nThe Fabric Connect technology was originally developed by the Enterprise Solutions R&D department within Nortel Networks. In 2009, Avaya, Inc acquired Nortel Networks Enterprise Business Solutions; this transaction included the Fabric Connect intellectual property together with all of the Ethernet Switching platforms that supported it. Subsequently, the Fabric Connect technology became part of the Extreme Networks portfolio by virtue of their 2017 purchase of the Avaya Networking business and assets. It was during the Avaya era that this technology was promoted as the lead element of the Virtual Enterprise Network Architecture (VENA).",
    "link": "https://en.wikipedia.org/wiki/Fabric_Connect"
  },
  {
    "title": "Google Compute Engine",
    "slug": "google-compute-engine",
    "content": "Google Compute Engine  (GCE) is the infrastructure as a service (IaaS) component of Google Cloud Platform which is built on the global infrastructure that runs Google's search engine, Gmail, YouTube and other services. Google Compute Engine enables users (utilising authentication based on OAuth 2.0) to launch virtual machines (VMs) on demand. VMs can be launched from the standard images or custom images created by users. Google Compute Engine can be accessed via the Developer Console, RESTful API or command-line interface (CLI).",
    "link": "https://en.wikipedia.org/wiki/Google_Compute_Engine"
  },
  {
    "title": "Kevin L. Jackson",
    "slug": "kevin-l-jackson",
    "content": "Kevin L. Jackson is an American business executive and writer. He served in the US Navy for fifteen years, before becoming a senior business executive in the computer industry. Jackson is currently the CEO & Founder, GovCloud Network, a consultancy formed to assist agencies and businesses leverage the parallel and global nature of cloud computing.",
    "link": "https://en.wikipedia.org/wiki/Kevin_L._Jackson"
  },
  {
    "title": "Distributed manufacturing",
    "slug": "distributed-manufacturing",
    "content": "Distributed manufacturing, also known as distributed production, cloud producing, distributed digital manufacturing, and local manufacturing, is a form of decentralized manufacturing practiced by enterprises using a network of geographically dispersed manufacturing facilities that are coordinated using information technology. It can also refer to local manufacture via the historic cottage industry model, or manufacturing that takes place in the homes of consumers.",
    "link": "https://en.wikipedia.org/wiki/Distributed_manufacturing"
  },
  {
    "title": "Elasticity (computing)",
    "slug": "elasticity-computing",
    "content": "In computing, elasticity is defined as \"the degree to which a system is able to adapt to workload changes by provisioning and de-provisioning resources in an autonomic manner, such that at each point in time the available resources match the current demand as closely as possible\". Elasticity is a defining characteristic that differentiates cloud computing from previously proposed distributed computing paradigms, such as grid computing. The dynamic adaptation of capacity, e.g., by altering the use of computing resources, to meet a varying workload is called \"elastic computing\".\nIn the world of distributed systems, there are several definitions according to the authors, some considering the concepts of scalability a sub-part of elasticity, others as being distinct.",
    "link": "https://en.wikipedia.org/wiki/Elasticity_(computing)"
  },
  {
    "title": "Distributed file system for cloud",
    "slug": "distributed-file-system-for-cloud",
    "content": "A distributed file system for cloud is a file system that allows many clients to have access to data and supports operations (create, delete, modify, read, write) on that data. Each data file may be partitioned into several parts called chunks. Each chunk may be stored on different remote machines, facilitating the parallel execution of applications. Typically, data is stored in files in a hierarchical tree, where the nodes represent directories. There are several ways to share files in a distributed architecture: each solution must be suitable for a certain type of application, depending on how complex the application is. Meanwhile, the security of the system must be ensured. Confidentiality, availability and integrity are the main keys for a secure system.\nUsers can share computing resources through the Internet thanks to cloud computing which is typically characterized by scalable and elastic resources – such as physical servers, applications and any services that are virtualized and allocated dynamically. Synchronization is required to make sure that all devices are up-to-date.\nDistributed file systems enable many big, medium, and small enterprises to store and access their remote data as they do local data, facilitating the use of variable resources.",
    "link": "https://en.wikipedia.org/wiki/Distributed_file_system_for_cloud"
  },
  {
    "title": "Virtual private server",
    "slug": "virtual-private-server",
    "content": "A virtual private server (VPS) or virtual dedicated server (VDS)  is a virtual machine sold as a service by an Internet hosting company.\nA virtual private server runs its own copy of an operating system (OS), and customers may have superuser-level access to that operating system instance, so they can install almost any software that runs on that OS. For many purposes, it is functionally equivalent to a dedicated physical server and, being software-defined, can be created and configured more easily. A virtual server costs less than an equivalent physical server. However, as virtual servers share the underlying physical hardware with other VPS, performance may be lower depending on the workload of any other executing virtual machines.",
    "link": "https://en.wikipedia.org/wiki/Virtual_private_server"
  },
  {
    "title": "Thinkfree Office",
    "slug": "thinkfree-office",
    "content": "Thinkfree Office is a web-based commercial office productivity suite developed by South Korea-based Thinkfree Inc. It includes Word (a word processor), Spreadsheet (a spreadsheet) and Presentation (a presentation program).\nThey are compatible with Microsoft Office's Word, PowerPoint, and Excel. It also features collaborative editing. The product is hosted on the client's server.",
    "link": "https://en.wikipedia.org/wiki/Thinkfree_Office"
  },
  {
    "title": "Physicalization",
    "slug": "physicalization",
    "content": "Physicalization of computer hardware (the opposite of virtualization), is a way to place multiple physical machines in a rack unit.\nIt can be a way to reduce hardware costs, since in some cases, server processors cost more per core than energy efficient laptop processors, which may make up for added cost of board level integration.  While Moore's law makes increasing integration less expensive, some jobs require much I/O bandwidth, which may be less expensive to provide using many less-integrated processors.\nApplications and services that are I/O bound are likely to benefit from such physicalized environments.  This ensures that each operating system instance is running on a processor that has its own network interface card, host bus and I/O sub-system unlike in the case of a multi-core servers where a single I/O sub-system is shared between all the cores / VMs.",
    "link": "https://en.wikipedia.org/wiki/Physicalization"
  },
  {
    "title": "Microsoft Azure",
    "slug": "microsoft-azure",
    "content": "Microsoft Azure, sometimes stylized Azure, and formerly Windows Azure, is the cloud computing platform developed by Microsoft. It offers management, access and development of applications and services to individuals, companies, and governments through its global infrastructure. It also provides capabilities that are usually not included within other cloud platforms, including software as a service (SaaS), platform as a service (PaaS), and infrastructure as a service (IaaS). Microsoft Azure supports many programming languages, tools, and frameworks, including Microsoft-specific and third-party software and systems.\nAzure was first introduced at the Professional Developers Conference (PDC) in October 2008 under the codename \"Project Red Dog\". It was officially launched as Windows Azure in February 2010 and later renamed to Microsoft Azure on March 25, 2014.",
    "link": "https://en.wikipedia.org/wiki/Microsoft_Azure"
  },
  {
    "title": "Online OS",
    "slug": "online-os",
    "content": "The Online Operating System was a fully multi-lingual and free to use web desktop written in JavaScript using Ajax. It was a Windows-based desktop environment with open-source applications and system utilities developed upon the reBOX web application framework by iCUBE Network Solutions, an Austrian company located in Vienna.",
    "link": "https://en.wikipedia.org/wiki/Online_OS"
  },
  {
    "title": "Plug computer",
    "slug": "plug-computer",
    "content": "A plug computer is a small-form-factor computer whose chassis contains the AC power plug, and thus plugs directly into the wall. Alternatively, the computer may resemble an AC adapter or a similarly small device. Plug computers are often configured for use in the home or office as compact computer.",
    "link": "https://en.wikipedia.org/wiki/Plug_computer"
  },
  {
    "title": "Open Cloud Computing Interface",
    "slug": "open-cloud-computing-interface",
    "content": "The Open Cloud Computing Interface (OCCI) is a set of specifications delivered through the Open Grid Forum, for cloud computing service providers. OCCI has a set of implementations that act as proofs of concept. It builds upon World Wide Web fundamentals by using the Representational State Transfer (REST) approach for interacting with services.",
    "link": "https://en.wikipedia.org/wiki/Open_Cloud_Computing_Interface"
  },
  {
    "title": "Virtual private cloud",
    "slug": "virtual-private-cloud",
    "content": "A virtual private cloud (VPC) is an on-demand configurable pool of shared resources allocated within a public cloud environment, providing a certain level of isolation between the different organizations (denoted as users hereafter) using the resources.  The isolation between one VPC user and all other users of the same cloud (other VPC users as well as other public cloud users) is achieved normally through allocation of a private IP subnet and a virtual communication construct (such as a VLAN or a set of encrypted communication channels) per user. In a VPC, the previously described mechanism, providing isolation within the cloud, is accompanied with a virtual private network (VPN) function (again, allocated per VPC user) that secures, by means of authentication and encryption, the remote access of the organization to its VPC resources. With the introduction of the described isolation levels, an organization using this service is in effect working on a 'virtually private' cloud (that is, as if the cloud infrastructure is not shared with other users), and hence the name VPC.\nVPC is most commonly used in the context of cloud infrastructure as a service. In this context, the infrastructure provider, providing the underlying public cloud infrastructure, and the provider realizing the VPC service over this infrastructure, may be different vendors.",
    "link": "https://en.wikipedia.org/wiki/Virtual_private_cloud"
  },
  {
    "title": "Native cloud application",
    "slug": "native-cloud-application",
    "content": "A native cloud application (NCA) is a type of computer software that natively utilizes services and infrastructure from cloud computing providers such as Amazon EC2, Force.com, or Microsoft Azure. NCAs exhibit a combined usage of the three fundamental technologies:\n\nComputational grid - loosely, e.g. MapReduce\nData grids (e.g. distributed in-memory data caches)\nAuto-scaling on any managed infrastructure",
    "link": "https://en.wikipedia.org/wiki/Native_cloud_application"
  },
  {
    "title": "Apache Pig",
    "slug": "apache-pig",
    "content": "Apache Pig\nis a high-level platform for creating programs that run on Apache Hadoop. The language for this platform is called Pig Latin.  Pig can execute its Hadoop jobs in MapReduce, Apache Tez, or Apache Spark.  Pig Latin abstracts the programming from the Java MapReduce idiom into a notation which makes MapReduce programming high level, similar to that of SQL for relational database management systems. Pig Latin can be extended using user-defined functions (UDFs) which the user can write in Java, Python, JavaScript, Ruby or Groovy and then call directly from the language.",
    "link": "https://en.wikipedia.org/wiki/Apache_Pig"
  },
  {
    "title": "Open Data Center Alliance",
    "slug": "open-data-center-alliance",
    "content": "opendatacenteralliance.org appears to have been closed down.\nThe Open Data Center Alliance is an independent organization created in Oct. 2010 with the assistance of Intel to coordinate the development of standards for cloud computing. Approximately 100 companies, which account for more than $50bn of IT spending, have joined the Alliance, including BMW, Royal Dutch Shell and Marriott Hotels. \"The Alliance's Cloud 2015 vision is aimed at creating a federated cloud where common standards will be laid down for those in the hardware and software arena.\"",
    "link": "https://en.wikipedia.org/wiki/Open_Data_Center_Alliance"
  },
  {
    "title": "RCUDA",
    "slug": "rcuda",
    "content": "rCUDA, which stands for Remote CUDA, is a type of middleware software framework for remote GPU virtualization. Fully compatible with the CUDA application programming interface (API), it allows the allocation of one or more CUDA-enabled GPUs to a single application. Each GPU can be part of a cluster or running inside of a virtual machine. The approach is aimed at improving performance in GPU clusters that are lacking full utilization. GPU virtualization reduces the number of GPUs needed in a cluster, and in turn, leads to a lower cost configuration – less energy, acquisition, and maintenance.\nThe recommended distributed acceleration architecture is a high performance computing cluster with GPUs attached to only a few of the cluster nodes. When a node without a local GPU executes an application needing GPU resources, remote execution of the kernel is supported by data and code transfers between local system memory and remote GPU memory. rCUDA is designed to accommodate this client-server architecture. On one end, clients employ a library of wrappers to the high-level CUDA Runtime API, and on the other end, there is a network listening service that receives requests on a TCP port. Several nodes running different GPU-accelerated applications can concurrently make use of the whole set of accelerators installed in the cluster. The client forwards the request to one of the servers, which accesses the GPU installed in that computer and executes the request in it. Time-multiplexing the GPU, or in other words sharing it, is accomplished by spawning different server processes for each remote GPU execution request.",
    "link": "https://en.wikipedia.org/wiki/RCUDA"
  },
  {
    "title": "Mobile cloud computing",
    "slug": "mobile-cloud-computing",
    "content": "Mobile Cloud Computing (MCC) is the combination of cloud computing and mobile computing to bring rich computational resources to mobile users, network operators, as well as cloud computing providers. The ultimate goal of MCC is to enable execution of rich mobile applications on a plethora of mobile devices, with a rich user experience. MCC provides business opportunities for mobile network operators as well as cloud providers. More comprehensively, MCC can be defined as \"a rich mobile computing technology that leverages unified elastic resources of varied clouds and network technologies toward unrestricted functionality, storage, and mobility to serve a multitude of mobile devices anywhere, anytime through the channel of Ethernet or Internet regardless of heterogeneous environments and platforms based on the pay-as-you-use principle.\"",
    "link": "https://en.wikipedia.org/wiki/Mobile_cloud_computing"
  },
  {
    "title": "Single-chip Cloud Computer",
    "slug": "singlechip-cloud-computer",
    "content": "The Single-Chip Cloud Computer (SCC) is a computer processor created by Intel Corporation in 2009 with 48 distinct physical cores that communicate through an architecture similar to that of a cloud computer data center. Cores are components of the processor responsible for executing instructions that enable the computer to function. The SCC resulted from an Intel project focusing on researching multi-core processors and parallel processing. Intel also aimed to explore the integration of designs and architecture from large cloud computer data centers (cloud computing) into a single processing chip. The name \"Single-chip Cloud Computer\" reflects this concept.",
    "link": "https://en.wikipedia.org/wiki/Single-chip_Cloud_Computer"
  },
  {
    "title": "Douglas Parkhill",
    "slug": "douglas-parkhill",
    "content": "Douglas F. Parkhill is a Canadian technologist and former research minister, best known for his pioneering work on what is now called cloud computing, and his work on Canada's Telidon videotex project.\nHe started working at the Canadian ministry of Communications (now part of the Department of Trade and Industry) in 1969, having previously worked at the Mitre Corporation. He was responsible for many activities in communications satellites, computer communications, command and control systems and telecommunications. He was winner of the Treasury Board of Canada Secretariat's Outstanding Achievement award in 1982, the Conestoga shield for services to government and industry in computer communications research and development, the Touche Ross award for Telidon development.\nHe was an author of several publications  including the 1966 book, The Challenge of the Computer Utility. In the book, Parkhill thoroughly explored many of the modern-day characteristics of cloud computing (elastic provisioning through a utility service) as well as the comparison to the electricity industry and the use of public, private, government and community forms. The book won the McKinsey Foundation award for distinguished contributions to management literature.\nHe worked with Dave Godfrey, the Canadian writer and novelist on a later book Gutenberg two about the social and political meaning of computer technology.\nHe was in charge of research at the Federal Department of Communications at the time when the department was funding development of the Telidon videotext system, was heavily involved in promoting the system, and had overall control of the program. In a radio broadcast in 1980, he outlined some of the potential of the system, from financial information, to theatre reservations, with the ability to pay and print out tickets from the system. He later documented the history of the Telidon project, and the history of videotext in general.",
    "link": "https://en.wikipedia.org/wiki/Douglas_Parkhill"
  },
  {
    "title": "Silk Technologies",
    "slug": "silk-technologies",
    "content": "Silk is a software company specializing in software-defined cloud storage. The company provides a platform designed to optimize the performance, scalability, and cost-efficiency of cloud storage, catering to enterprise applications and workloads, including artificial intelligence (AI) and machine learning (ML).\nThe company is headquartered in Needham, Massachusetts, with additional operations in Israel.",
    "link": "https://en.wikipedia.org/wiki/Silk_Technologies"
  },
  {
    "title": "Stackdriver",
    "slug": "stackdriver",
    "content": "Google Stackdriver was a cloud computing systems management service offered by Google. It provided performance and diagnostics data (in the form of monitoring, logging, tracing, error reporting, and alerting) to public cloud users. Stackdriver was a multi-cloud solution, providing support for both Google Cloud and AWS cloud environments.\nGoogle ended use of the Stackdriver brand in February 2020.",
    "link": "https://en.wikipedia.org/wiki/Stackdriver"
  },
  {
    "title": "Software-defined data center",
    "slug": "softwaredefined-data-center",
    "content": "Software-defined data center (SDDC; also: virtual data center, VDC) is a marketing term that extends virtualization concepts such as abstraction, pooling, and automation to all data center resources and services to achieve IT as a service (ITaaS).\nIn a software-defined data center, \"all elements of the infrastructure — networking, storage, CPU and security – are virtualized and delivered as a service.\"  \nSDDC support can be claimed by a wide variety of approaches.  Critics see the software-defined data center as a marketing tool and \"software-defined hype,\" noting this variability.\nIn 2013, analysts were divided into three different groups, those who think it is \"just another software-defined hype\", those who think most of the components are already available and those who see a potential future market. There was no unified agreement about the direction of SDDC. For some areas like the software-defined networking a market value of about US$3.7 billion by 2016 was expected, compared to US$360 million in 2013. (software-defined networking was expected to reach US$18.5 billion in 2022) IDC estimates that the software-defined storage market is poised to expand faster than any other storage market.",
    "link": "https://en.wikipedia.org/wiki/Software-defined_data_center"
  },
  {
    "title": "Personal cloud",
    "slug": "personal-cloud",
    "content": "A personal cloud is a collection of digital content and services that are accessible from any device through the Internet. It is not a tangible entity, but a place that gives users the ability to store, synchronize, stream and share content on a relative core, moving from one platform, screen and location to another. Created on connected services and applications, it reflects and sets consumer expectations for how next-generation computing services will work.\nThe four primary types of personal cloud in use today are: Online cloud, NAS device cloud, server device cloud, and home-made clouds.",
    "link": "https://en.wikipedia.org/wiki/Personal_cloud"
  },
  {
    "title": "Multicloud",
    "slug": "multicloud",
    "content": "Multicloud (also written as multi-cloud or multi cloud) is a term with varying interpretations, generally referring to a system using multiple cloud computing providers. According to ISO/IEC 22123-1: \"multi-cloud is a cloud deployment model in which a customer uses public cloud services provided by two or more cloud service providers\". Multi-cloud can involve various deployment models, including public, private, and hybrid clouds, and multiple service models, such as Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). Multicloud incorporates workload, data, traffic and workflow portability options, exhibiting differing implementation complexities.\nWhen effectively implemented, multicloud solutions can enhance architectural resilience, reduce dependence on a single vendor, and improve flexibility by leveraging services from different providers. However, multicloud strategies also present challenges, including increased operational complexity, security risks, higher costs, and integration difficulties.\nAccording to the 2024 State of the Cloud Report by Flexera, multi-cloud adoption has continued to rise in 2024. Enterprises increasingly silo applications into specific clouds and select best-fit services. Key use cases include data analysis in separate clouds and cross-cloud disaster recovery.",
    "link": "https://en.wikipedia.org/wiki/Multicloud"
  },
  {
    "title": "Operating system",
    "slug": "operating-system",
    "content": "An operating system (OS) is system software that manages computer hardware and software resources, and provides common services for computer programs.\nTime-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, peripherals, and other resources.\nFor hardware functions such as input and output and memory allocation, the operating system acts as an intermediary between programs and the computer hardware, although the application code is usually executed directly by the hardware and frequently makes system calls to an OS function or is interrupted by it. Operating systems are found on many devices that contain a computer – from cellular phones and video game consoles to web servers and supercomputers.\nAs of November 2025, Android is the most popular operating system with a 38% market share, followed by Microsoft Windows at 33%, iOS and iPadOS at 15%, macOS at 4%, and Linux at 1%. Android, iOS, and iPadOS are operating systems for mobile devices such as smartphones, while Windows, macOS, and Linux are for desktop computers. Linux distributions are dominant in the server and supercomputing sectors. Other specialized classes of operating systems (special-purpose operating systems), such as embedded and real-time systems, exist for many applications. Security-focused operating systems also exist. Some operating systems have low system requirements (e.g. light-weight Linux distribution). Others may have higher system requirements.\nSome operating systems require installation or may come pre-installed with purchased computers (OEM-installation), whereas others may run directly from media (i.e. live CD) or flash memory (i.e. a LiveUSB from a USB stick).",
    "link": "https://en.wikipedia.org/wiki/Operating_system"
  },
  {
    "title": "Real-time operating system",
    "slug": "realtime-operating-system",
    "content": "A real-time operating system (RTOS) is an operating system (OS) for real-time computing applications that processes data and events that have critically defined time constraints. A RTOS mainly targets resource constrained devices like microcontrollers. It is distinct from a time-sharing operating system, such as Unix, which manages the sharing of system resources with a scheduler, data buffers, or fixed task prioritization in multitasking or multiprogramming environments. All operations must verifiably complete within given time and resource constraints or else the RTOS will fail safe. Real-time operating systems are event-driven and preemptive, meaning the OS can monitor the relevant priority of competing tasks, and make changes to the task priority.",
    "link": "https://en.wikipedia.org/wiki/Real-time_operating_system"
  },
  {
    "title": "UCSD Pascal",
    "slug": "ucsd-pascal",
    "content": "UCSD Pascal is a Pascal programming language system that runs on the UCSD p-System, a portable, highly machine-independent operating system. UCSD Pascal was first released in 1977. It was developed at the University of California, San Diego (UCSD).",
    "link": "https://en.wikipedia.org/wiki/UCSD_Pascal"
  },
  {
    "title": "Network operating system",
    "slug": "network-operating-system",
    "content": "A network operating system (NOS) is a specialized operating system for a network device such as a router, switch or firewall.\nHistorically operating systems with networking capabilities were described as network operating systems, because they allowed personal computers (PCs) to participate in computer networks and shared file and printer access within a local area network (LAN). This description of operating systems is now largely historical, as common operating systems include a network stack to support a client–server model.",
    "link": "https://en.wikipedia.org/wiki/Network_operating_system"
  },
  {
    "title": "History of operating systems",
    "slug": "history-of-operating-systems",
    "content": "Computer operating systems (OSes) provide a set of functions needed and used by most application programs on a computer, and the links needed to control and synchronize computer hardware. On the first computers, with no operating system, every program needed the full hardware specification to run correctly and perform standard tasks, and its own drivers for peripheral devices like printers and punched paper card readers. The growing complexity of hardware and application programs eventually made operating systems a necessity for everyday use.",
    "link": "https://en.wikipedia.org/wiki/History_of_operating_systems"
  },
  {
    "title": "List of operating systems",
    "slug": "list-of-operating-systems",
    "content": "This is a list of operating systems. Computer operating systems can be categorized by technology, ownership, licensing, working state, usage, and by many other characteristics. In practice, many of these groupings may overlap. Criteria for inclusion is notability, as shown either through an existing Wikipedia article or citation to a reliable source.",
    "link": "https://en.wikipedia.org/wiki/List_of_operating_systems"
  },
  {
    "title": "LCARS",
    "slug": "lcars",
    "content": "In the Star Trek fictional universe, LCARS (; an acronym for Library Computer Access/Retrieval System) is a computer operating system.  Within Star Trek chronology, the term was first used in the Star Trek: The Next Generation series.",
    "link": "https://en.wikipedia.org/wiki/LCARS"
  },
  {
    "title": "Timeline of operating systems",
    "slug": "timeline-of-operating-systems",
    "content": "This article presents a timeline of events in the history of computer operating systems from 1951 to the current day. For a narrative explaining the overall developments, see the History of operating systems.",
    "link": "https://en.wikipedia.org/wiki/Timeline_of_operating_systems"
  },
  {
    "title": "Localhost",
    "slug": "localhost",
    "content": "In computer networking, localhost is a hostname that refers to the current computer used to access it. The name localhost is reserved for loopback purposes.\nIt is used to access the network services that are running on the host via the loopback network interface. Using the loopback interface bypasses any local network interface hardware.",
    "link": "https://en.wikipedia.org/wiki/Localhost"
  },
  {
    "title": "Comparison of operating systems",
    "slug": "comparison-of-operating-systems",
    "content": "These tables provide a comparison of operating systems, of computer devices, as listing general and technical information for a number of widely used and currently available PC or handheld (including smartphone and tablet computer) operating systems. The article \"Usage share of operating systems\" provides a broader, and more general, comparison of operating systems that includes servers, mainframes and supercomputers.\nBecause of the large number and variety of available Linux distributions, they are all grouped under a single entry; see comparison of Linux distributions for a detailed comparison. There is also a variety of BSD and DOS operating systems, covered in comparison of BSD operating systems and comparison of DOS operating systems.",
    "link": "https://en.wikipedia.org/wiki/Comparison_of_operating_systems"
  },
  {
    "title": "Campus network",
    "slug": "campus-network",
    "content": "A campus network, campus area network, corporate area network or CAN is a computer network made up of an interconnection of local area networks (LANs) within a limited geographical area. The networking equipments (switches, routers) and transmission media (optical fiber, copper plant, Cat5 cabling etc.) are almost entirely owned by the campus tenant / owner: an enterprise, university, government etc. A campus area network is larger than a local area network but smaller than a metropolitan area network (MAN) or wide area network (WAN).",
    "link": "https://en.wikipedia.org/wiki/Campus_network"
  },
  {
    "title": "AS2",
    "slug": "as2",
    "content": "AS2 (Applicability Statement 2) is a specification on how to transport structured business-to-business data securely and reliably over the Internet. Security is achieved by using digital certificates and encryption.",
    "link": "https://en.wikipedia.org/wiki/AS2"
  },
  {
    "title": "Single address space operating system",
    "slug": "single-address-space-operating-system",
    "content": "In computer science, a single address space operating system (or SASOS) is an operating system that provides only one globally shared address space for all processes. In a single address space operating system, numerically identical (virtual memory) logical addresses in different processes all refer to exactly the same byte of data.\nIn a traditional OS with private per-process address space, memory protection is based on address space boundaries (\"address space isolation\"). Single address-space operating systems make translation and protection orthogonal, which in no way weakens protection. \nThe core advantage is that pointers (i.e. memory references) have global validity, meaning their meaning is independent of the process using it. This allows sharing pointer-connected data structures across processes, and making them persistent, i.e. storing them on backup store.\nSome processor architectures have direct support for protection independent of translation. On such architectures, a SASOS may be able to perform context switches faster than a traditional OS. Such architectures include Itanium, and Version 5 of the Arm architecture, as well as capability architectures such as CHERI.\nA SASOS should not be confused with a flat memory model, which provides no address translation and generally no memory protection. In contrast, a SASOS makes protection orthogonal to translation: it may be possible to name a data item (i.e. know its virtual address) while not being able to access it.\nSASOS projects using hardware-based protection include the following:\n\nAngel\nIBM i (formerly called OS/400)\nIguana at NICTA, Australia\nMungi at NICTA, Australia\nNemesis\nOpal\nScout\nSombrero\nRelated are OSes that provide protection through language-level type safety:\n\nBr1X\nGenera\nJX a research Java OS\nPhantom OS\nSingularity\nTheseus OS\nTorsion",
    "link": "https://en.wikipedia.org/wiki/Single_address_space_operating_system"
  },
  {
    "title": "Computer network",
    "slug": "computer-network",
    "content": "In computer science, computer engineering, and telecommunications, a network is a group of communicating computers and peripherals known as hosts, which communicate data to other hosts via communication protocols, as facilitated by networking hardware.\nWithin a computer network, hosts are identified by network addresses, which allow networking hardware to locate and identify hosts. Hosts may also have hostnames, memorable labels for the host nodes, which can be mapped to a network address using a hosts file or a name server such as Domain Name Service. The physical medium that supports information exchange includes wired media like copper cables, optical fibers, and wireless radio-frequency media. The arrangement of hosts and hardware within a network architecture is known as the network topology.\nThe first computer network was created in 1940 when George Stibitz connected a terminal at Dartmouth to his Complex Number Calculator at Bell Labs in New York. Today, almost all computers are connected to a computer network, such as the global Internet or embedded networks such as those found in many modern electronic devices. Many applications have only limited functionality unless they are connected to a network. Networks support applications and services, such as access to the World Wide Web, digital video and audio, application and storage servers, printers, and email and instant messaging applications.",
    "link": "https://en.wikipedia.org/wiki/Computer_network"
  },
  {
    "title": "Linux",
    "slug": "linux",
    "content": "Linux ( LIN-uuks) is a family of open source Unix-like operating systems based on the Linux kernel, a kernel first released on September 17, 1991, by Linus Torvalds. Linux is typically packaged as a Linux distribution (distro), which includes the kernel and supporting system software and libraries—most of which are provided by third parties—to create a complete operating system, designed as a clone of Unix and released under the copyleft GPL license.\nThousands of Linux distributions exist, many based directly or indirectly on other distributions; popular Linux distributions include Debian, Fedora Linux, Linux Mint, Arch Linux, and Ubuntu, while commercial distributions include Red Hat Enterprise Linux, SUSE Linux Enterprise, and ChromeOS. Linux distributions are frequently used in server platforms. Many Linux distributions use the word \"Linux\" in their name, but the Free Software Foundation uses and recommends the name \"GNU/Linux\" to emphasize the use and importance of GNU software in many distributions, causing some controversy. Other than the Linux kernel, key components that make up a distribution may include a display server (windowing system), a package manager, a bootloader and a Unix shell.\n\nLinux is one of the most prominent examples of free and open-source software collaboration. While originally developed for x86-based personal computers, it has since been ported to more platforms than any other operating system, and is used on a wide variety of devices including PCs, workstations, mainframes and embedded systems. Linux is the predominant operating system for servers and is also used on all of the world's 500 fastest supercomputers. When combined with Android, which is Linux-based and designed for smartphones, they have the largest installed base of all general-purpose operating systems.",
    "link": "https://en.wikipedia.org/wiki/Linux"
  },
  {
    "title": "Application delivery network",
    "slug": "application-delivery-network",
    "content": "An application delivery network (ADN) is a suite of technologies that, when deployed together, provide availability, security, visibility, and acceleration for Internet applications such as websites. ADN components provide supporting functionality that enables website content to be delivered to visitors and other users of that website, in a fast, secure, and reliable way.\nGartner defines application delivery networking as the combination of WAN optimization controllers (WOCs) and application delivery controllers (ADCs). At the data center end of an ADN is the ADC, an advanced traffic management device that is often also referred to as a web switch, content switch, or multilayer switch, the purpose of which is to distribute traffic among a number of servers or geographically dislocated sites based on application specific criteria. In the branch office portion of an ADN is the WAN optimization controller, which works to reduce the number of bits that flow over the network using caching and compression, and shapes TCP traffic using prioritization and other optimization techniques. Some WOC components are installed on PCs or mobile clients, and there is typically a portion of the WOC installed in the data center. Application delivery networks are also offered by some CDN vendors.\nThe ADC, one component of an ADN, evolved from layer 4-7 switches in the late 1990s when it became apparent that traditional load balancing techniques were not robust enough to handle the increasingly complex mix of application traffic being delivered over a wider variety of network connectivity options.",
    "link": "https://en.wikipedia.org/wiki/Application_delivery_network"
  },
  {
    "title": "Usage share of operating systems",
    "slug": "usage-share-of-operating-systems",
    "content": "The usage share of an operating system is the percentage of computers running that operating system (OS). These statistics are estimates as wide scale OS usage data is difficult to obtain and measure. Reliable primary sources are limited and data collection methodology is not formally agreed. Currently devices connected to the internet allow for web data collection to approximately measure OS usage.\nAs of December 2025, Android, which uses the Linux kernel, is the world's most popular operating system with 38.94% of the global market, followed by Windows with 29.99%, iOS with 15.66%, macOS with 2.14%, and other operating systems with 10.78%. This is for all device types excluding embedded devices.\n\nFor smartphones and other mobile devices, Android has 72% market share, and Apple's iOS has 28%.\nFor desktop computers and laptops, Microsoft Windows has 71%, followed by Apple's macOS at 16%, unknown operating systems at 8%, desktop Linux at 4%, then Google's ChromeOS at 2%.\nFor tablets, Apple's iPadOS (a variant of iOS) has 52% share and Android has 48% worldwide.\nFor the top 500 most powerful supercomputers, Linux distributions have had 100% of the marketshare since 2017.\nThe global server operating system marketshare has Linux leading with a 63.1% marketshare, followed by Windows, Unix and other operating systems.\nLinux is also most used for web servers, and the most common Linux distribution is Ubuntu, followed by Debian. Linux has almost caught up with the second-most popular (desktop) OS, macOS, in some regions, such as in South America, and in Asia it's at 6.4% (7% with ChromeOS) vs 9.7% for macOS. In the US, ChromeOS is third at 5.5%, followed by (desktop) Linux at 4.3%, but can arguably be combined into a single number 9.8%.\nThe most numerous type of device with an operating system are embedded systems. Not all embedded systems have operating systems, instead running their application code on the \"bare metal\"; of those that do have operating systems, a high percentage are standalone or do not have a web browser, which makes their usage share difficult to measure. Some operating systems used in embedded systems are more widely used than some of those mentioned above; for example, modern Intel microprocessors contain an embedded management processor running a version of the Minix operating system.",
    "link": "https://en.wikipedia.org/wiki/Usage_share_of_operating_systems"
  },
  {
    "title": "Just enough operating system",
    "slug": "just-enough-operating-system",
    "content": "Just enough operating system (JeOS, pronounced \"juice\" according to SUSE) is a paradigm for customizing operating systems to fit the needs of a particular application such as for a software appliance. The platform only includes the operating system components required to support a particular application and any other third-party components contained in the appliance (e.g., the kernel). This makes the appliance smaller, faster (to boot and to execute the particular application) and potentially more secure than an application running under a full general-purpose OS.",
    "link": "https://en.wikipedia.org/wiki/Just_enough_operating_system"
  },
  {
    "title": "Mobile operating system",
    "slug": "mobile-operating-system",
    "content": "A mobile operating system is an operating system used for smartphones, tablets, smartwatches, smartglasses, or other non-laptop personal mobile computing devices. While computers such as laptops are \"mobile\", the operating systems used on them are usually not considered mobile, as they were originally designed for desktop computers that historically did not have or need specific mobile features. This \"fine line\" distinguishing mobile and other forms has become blurred in recent years, due to the fact that newer devices have become smaller and more mobile, unlike the hardware of the past. Key factors blurring this line are the introduction of tablet computers, light laptops, and the hybridization of the 2-in-1 PCs.\nMobile operating systems combine features of a desktop computer operating system with other features useful for mobile or handheld use, and usually including a wireless built-in modem and SIM tray for telephone and data connection. In 2024, approximately 1.22 billion smartphones were sold globally, marking a 7% increase over the previous year and a solid rebound after two consecutive years of declines. Sales in 2012 were 1.56 billion; sales in 2023 were 1.43 billion with 53.32% being Android. Android alone has more sales than the popular desktop operating system Microsoft Windows, and smartphone use (even without tablets) outnumbers desktop use.\nMobile devices, with mobile communications abilities (for example, smartphones), contain two mobile operating systems. The main user-facing software platform is supplemented by a second low-level proprietary real-time operating system which operates the radio and other hardware. Research has shown that these low-level systems may contain a range of security vulnerabilities permitting malicious base stations to gain high levels of control over the mobile device.\nMobile operating systems have had the most use of any operating system since 2017 (measured by web use).",
    "link": "https://en.wikipedia.org/wiki/Mobile_operating_system"
  },
  {
    "title": "Internet",
    "slug": "internet",
    "content": "The Internet (or internet) is the global system of interconnected computer networks that uses the Internet protocol suite (TCP/IP) to communicate between networks and devices. It is a network of networks that comprises private, public, academic, business, and government networks of local to global scope, linked by electronic, wireless, and optical networking technologies. The Internet carries a vast range of information services and resources, such as the interlinked hypertext documents and applications of the World Wide Web (WWW), electronic mail, discussion groups, internet telephony, streaming media and file sharing.\nMost traditional communication media, including telephone, radio, television, paper mail, newspapers, and print publishing, have been transformed by the Internet, giving rise to new media such as email, online music, digital newspapers, news aggregators, and audio and video streaming websites. The Internet has enabled and accelerated new forms of personal interaction through instant messaging, Internet forums, and social networking services. Online shopping has also grown to occupy a significant market across industries, enabling firms to extend brick and mortar presences to serve larger markets. Business-to-business and financial services on the Internet affect supply chains across entire industries. \nThe origins of the Internet date back to research that enabled the time-sharing of computer resources, the development of packet switching, and the design of computer networks for data communication. The set of communication protocols to enable internetworking on the Internet arose from research and development commissioned in the 1970s by the Defense Advanced Research Projects Agency (DARPA) of the United States Department of Defense in collaboration with universities and researchers across the United States and in the United Kingdom and France. \nThe Internet has no single centralized governance in either technological implementation or policies for access and usage. Each constituent network sets its own policies. The overarching definitions of the two principal name spaces on the Internet, the Internet Protocol address (IP address) space and the Domain Name System (DNS), are directed by a maintainer organization, the Internet Corporation for Assigned Names and Numbers (ICANN). The technical underpinning and standardization of the core protocols is an activity of the non-profit Internet Engineering Task Force (IETF).",
    "link": "https://en.wikipedia.org/wiki/Internet"
  },
  {
    "title": "Myrinet",
    "slug": "myrinet",
    "content": "Myrinet, ANSI/VITA 26-1998, is a high-speed local area networking system designed by the company Myricom to be used as an interconnect between multiple machines to form computer clusters.",
    "link": "https://en.wikipedia.org/wiki/Myrinet"
  },
  {
    "title": "Semi-Automatic Ground Environment",
    "slug": "semiautomatic-ground-environment",
    "content": "The Semi-Automated Ground Environment (SAGE) was a system of large computers and associated networking equipment that coordinated data from many radar sites and processed it to produce a single unified image of the airspace over a wide area. SAGE directed and controlled the NORAD response to a possible Soviet air attack, operating in this role from the late 1950s into the 1980s.\nThe processing power behind SAGE was supplied by the largest discrete component-based computer ever built, the AN/FSQ-7, manufactured by IBM. Each SAGE Direction Center (DC) housed an FSQ-7 which occupied an entire floor, approximately 22,000 square feet (2,000 m2) not including supporting equipment. The FSQ-7 was actually two computers, \"A\" side and \"B\" side. Computer processing was switched from \"A\" side to \"B\" side on a regular basis, allowing maintenance on the unused side. Information was fed to the DCs from a network of radar stations as well as readiness information from various defense sites. The computers, based on the raw radar data, developed \"tracks\" for the reported targets, and automatically calculated which defenses were within range. Operators used light guns to select targets on-screen for further information, select one of the available defenses, and issue commands to attack. These commands would then be automatically sent to the defense site via teleprinter.\nConnecting the various sites was an enormous network of telephones, modems and teleprinters. Later additions to the system allowed SAGE's tracking data to be sent directly to CIM-10 Bomarc missiles and some of the US Air Force's interceptor aircraft in-flight, directly updating their autopilots to maintain an intercept course without operator intervention. Each DC also forwarded data to a Combat Center (CC) for \"supervision of the several sectors within the division\" (\"each combat center [had] the capability to coordinate defense for the whole nation\").\nSAGE became operational in the late 1950s and early 1960s at an estimated total cost between 8 and 12 billion dollars, four times the cost of the Manhattan Project. Throughout its development, there were continual concerns about its real ability to deal with large attacks, and the Operation Sky Shield tests showed that only about one-fourth of enemy bombers would have been intercepted. Nevertheless, SAGE was the backbone of NORAD's air defense system into the 1980s, by which time the tube-based FSQ-7s were increasingly costly to maintain and completely outdated. Today the same command and control task is carried out by microcomputers, based on the same basic underlying data.",
    "link": "https://en.wikipedia.org/wiki/Semi-Automatic_Ground_Environment"
  },
  {
    "title": "Intranet",
    "slug": "intranet",
    "content": "An intranet is a computer network for sharing information, easier communication, collaboration tools, operational systems, and other computing services within an organization, usually to the exclusion of access by outsiders. The term is used in contrast to public networks, such as the Internet, but uses the same technology based on the Internet protocol suite.\nAn organization-wide intranet can constitute an important focal point of internal communication and collaboration, and provide a single starting point to access internal and external resources. In its simplest form, an intranet is established with the technologies for local area networks (LANs) and wide area networks (WANs). Many modern intranets have search engines, user profiles, blogs, mobile apps with notifications, and events planning within their infrastructure.\nAn intranet is sometimes contrasted to an extranet. While an intranet is generally restricted to employees of the organization, extranets may also be accessed by customers, suppliers, or other approved parties. Extranets extend a private network onto the Internet with special provisions for authentication, authorization and accounting (AAA protocol).",
    "link": "https://en.wikipedia.org/wiki/Intranet"
  },
  {
    "title": "Frame (networking)",
    "slug": "frame-networking",
    "content": "A frame is a digital data transmission unit in computer networking and telecommunications. In packet switched systems, a frame is a simple container for a single network packet. In other telecommunications systems, a frame is a repeating structure supporting time-division multiplexing.\nA frame typically includes frame synchronization features consisting of a sequence of bits or symbols that indicate to the receiver the beginning and end of the payload data within the stream of symbols or bits it receives. If a receiver is connected to the system during frame transmission, it ignores the data until it detects a new frame synchronization sequence.",
    "link": "https://en.wikipedia.org/wiki/Frame_(networking)"
  },
  {
    "title": "InfiniBand",
    "slug": "infiniband",
    "content": "InfiniBand (IB) is a computer networking standard used in high-performance computing that features very high throughput and very low latency. It is used for data interconnect both among and within computers. InfiniBand is also used as either a direct or switched interconnect between servers and storage systems, as well as an interconnect between storage systems. It is designed to be scalable and uses a switched fabric network topology.\nBetween 2014 and June 2016, it was the most commonly used interconnect in the TOP500 list of supercomputers.\nMellanox (acquired by Nvidia) manufactures InfiniBand host bus adapters and network switches, which are used by large computer system and database vendors in their product lines. \nAs a computer cluster interconnect, IB competes with Ethernet, Fibre Channel, and Intel Omni-Path. The technology is promoted by the InfiniBand Trade Association.",
    "link": "https://en.wikipedia.org/wiki/InfiniBand"
  },
  {
    "title": "Scalable Coherent Interface",
    "slug": "scalable-coherent-interface",
    "content": "The Scalable Coherent Interface or Scalable Coherent Interconnect (SCI), is a high-speed interconnect standard for shared memory multiprocessing and message passing. The goal was to scale well, provide system-wide memory coherence and a simple interface; i.e. a standard to replace existing buses in multiprocessor systems with one with no inherent scalability and performance limitations.\nThe IEEE Std 1596-1992, IEEE Standard for Scalable Coherent Interface (SCI) was approved by the IEEE standards board on March 19, 1992. It saw some use during the 1990s, but never became widely used and has been replaced by other systems from the early 2000s.",
    "link": "https://en.wikipedia.org/wiki/Scalable_Coherent_Interface"
  },
  {
    "title": "Open Data-Link Interface",
    "slug": "open-datalink-interface",
    "content": "The Open Data-Link Interface (ODI) is an application programming interface (API) for network interface controllers (NICs) developed by Apple and Novell. The API serves the same function as Microsoft and 3COM's Network Driver Interface Specification (NDIS). Originally, ODI was written for NetWare and Macintosh environments. Like NDIS, ODI provides rules that establish a vendor-neutral interface between the protocol stack and the adapter driver. It resides in Layer 2, the Data Link layer, of the OSI model. This interface also enables one or more network drivers to support one or more protocol stacks.",
    "link": "https://en.wikipedia.org/wiki/Open_Data-Link_Interface"
  },
  {
    "title": "Interplanetary Internet",
    "slug": "interplanetary-internet",
    "content": "The interplanetary Internet is a conceived computer network in space, consisting of a set of network nodes that can communicate with each other. These nodes are the planet's orbiters and landers, and the Earth ground stations. For example, the orbiters collect the scientific data from the Curiosity rover on Mars through near-Mars communication links, transmit the data to Earth through direct links from the Mars orbiters to the Earth ground stations via the NASA Deep Space Network, and finally the data routed through Earth's internal internet.\nInterplanetary communication is greatly delayed by interplanetary distances, as data transmission can only go as fast as the speed of light, so a new set of protocols and technologies that are tolerant to large delays and errors are required. The interplanetary Internet is a store and forward network of internets that is often disconnected, has a wireless backbone fraught with error-prone links and delays ranging from tens of minutes to even hours, even when there is a connection.\nAs of 2024 agencies and companies working towards bringing the network to fruition include NASA, ESA, SpaceX and Blue Origin.",
    "link": "https://en.wikipedia.org/wiki/Interplanetary_Internet"
  },
  {
    "title": "Reverse proxy",
    "slug": "reverse-proxy",
    "content": "In computer networks, a reverse proxy or surrogate server is a proxy server that appears to any client to be an ordinary web server, but in reality merely acts as an intermediary that forwards the client's requests to one or more ordinary web servers. Reverse proxies help increase scalability, performance, resilience, and security, but they also carry a number of risks.\nCompanies that run web servers often set up reverse proxies to facilitate the communication between an Internet user's browser and the web servers. An important advantage of doing so is that the web servers can be hidden behind a firewall on a company-internal network, and only the reverse proxy needs to be directly exposed to the Internet. Reverse proxy servers are implemented in popular open-source web servers. Dedicated reverse proxy servers are used by some of the biggest websites on the Internet.\nA reverse proxy is capable of tracking IP addresses of requests that are relayed through it as well as reading and/or modifying any non-encrypted traffic. However, this implies that anyone who has compromised the server could do so as well. \nReverse proxies differ from forward proxies, which are used when the client is restricted to a private, internal network and asks a forward proxy to retrieve resources from the public Internet.",
    "link": "https://en.wikipedia.org/wiki/Reverse_proxy"
  },
  {
    "title": "Netsukuku",
    "slug": "netsukuku",
    "content": "Netsukuku is an experimental peer-to-peer routing system, developed by the FreakNet MediaLab in 2005, created to build up a distributed network, anonymous and censorship-free, fully independent but not necessarily separated from the Internet, without the support of any server, Internet service provider and no central authority.\nNetsukuku is designed to handle up to 2128 nodes without any servers or central systems, with minimal CPU and memory resources. This mesh network can be built using existing network infrastructure components such as Wi-Fi.\nThe project has been in slow development since 2005, never abandoning a beta state. It has also never been tested on large scale.",
    "link": "https://en.wikipedia.org/wiki/Netsukuku"
  },
  {
    "title": "Defence Information Infrastructure",
    "slug": "defence-information-infrastructure",
    "content": "Defence Information Infrastructure (DII) is a secure military network owned by the United Kingdom's Ministry of Defence MOD.  It is used by all branches of the armed forces, including the Royal Navy, British Army and Royal Air Force as well as MOD civil servants.  It reaches to deployed bases and ships at sea, but not to aircraft in flight.\nIn 2000, the MOD began to plan the systems replacement project. In March 2005, the MOD gave a contract to the Atlas Consortium, with EDS as prime contractor, for installation and management over 10 years. That has developed into a consortium made up of DXC Technology (formerly EDS), Fujitsu, Airbus Defence and Space (formerly EADS Defence & Security) and CGI (formerly Logica).\nStarting in May 2016, MOD users of DII begin to migrate to the New Style of IT within the defence to be known as MODNET; again supported by ATLAS.",
    "link": "https://en.wikipedia.org/wiki/Defence_Information_Infrastructure"
  },
  {
    "title": "SCinet",
    "slug": "scinet",
    "content": "SCinet is the high-performance network built annually by volunteers in support of SC (formerly Supercomputing, the International Conference for High Performance Computing, Networking, Storage and Analysis).\nSCinet is the primary network for the yearly conference and is used by attendees and exhibitors to demonstrate and test high-performance computing and networking applications.",
    "link": "https://en.wikipedia.org/wiki/SCinet"
  },
  {
    "title": "NYSERNet",
    "slug": "nysernet",
    "content": "NYSERNet, Inc. (New York State Education and Research Network), is a non-profit Internet service provider in New York State. It mainly provides Internet access to universities, colleges, museums, health care facilities, primary and secondary schools, and research institutions.",
    "link": "https://en.wikipedia.org/wiki/NYSERNet"
  },
  {
    "title": "Service Assurance Agent",
    "slug": "service-assurance-agent",
    "content": "IP SLA (Internet Protocol Service Level Agreement) is an active computer network measurement technology that was initially developed by Cisco Systems. IP SLA was previously known as Service Assurance Agent (SAA) or Response Time Reporter (RTR). IP SLA is used to track network performance like latency, ping response, and jitter, it also helps to provide service quality.",
    "link": "https://en.wikipedia.org/wiki/Service_Assurance_Agent"
  },
  {
    "title": "IBM 37xx",
    "slug": "ibm-37xx",
    "content": "IBM 37xx (or 37x5) is a family of IBM Systems Network Architecture (SNA) programmable front-end processors used mainly in mainframe environments.\nAll members of the family ran one of three IBM-supplied programs.\n\nEmulation Program (EP) mimicked the operation of the older IBM 270x non-programmable controllers.\nNetwork Control Program (NCP) supported Systems Network Architecture devices.\nPartitioned Emulation Program (PEP) combined the functions of the two.",
    "link": "https://en.wikipedia.org/wiki/IBM_37xx"
  },
  {
    "title": "Telenet",
    "slug": "telenet",
    "content": "Telenet was an American commercial packet-switched network which went into service in August 16, 1975. It was the first FCC-licensed public data network in the United States. Various commercial and government interests paid monthly fees for dedicated lines connecting their computers and local networks to this backbone network. Free public dialup access to Telenet, for those who wished to access these systems, was provided in hundreds of cities throughout the United States.",
    "link": "https://en.wikipedia.org/wiki/Telenet"
  },
  {
    "title": "European Grid Infrastructure",
    "slug": "european-grid-infrastructure",
    "content": "EGI (originally an initialism for European Grid Infrastructure) is a federation of computing and storage resource providers that deliver advanced computing and data analytics services for research and innovation. The Federation is governed by its participants represented in the EGI Council and coordinated by the EGI Foundation.\nAs of 2024, the EGI Federation supports 160 scientific communities worldwide and over 95,000 users in their intensive data analysis. The most significant scientific communities supported by EGI in 2022 were Medical and Health Sciences, High Energy Physics, and Engineering and Technology. The EGI Federation provideds services through over 150 data centres, of which 25 are cloud sites, in 43 countries and 64 Research Infrastructures (4 of which are members of the Federation).",
    "link": "https://en.wikipedia.org/wiki/European_Grid_Infrastructure"
  },
  {
    "title": "IEBus",
    "slug": "iebus",
    "content": "IEBus (Inter Equipment Bus) is a communication bus specification \"between equipments within a vehicle or a chassis\" of Renesas Electronics. It defines OSI model layer 1 and layer 2 specification. IEBus is mainly used for car audio and car navigations, which established de facto standard in Japan, though SAE J1850 is major in United States.\n\nIEBus is also used in some vending machines, which major customer is Fuji Electric.\nEach button on the vending machine has an IEBus ID, i.e. has a controller.\n\nDetailed specification is disclosed to licensees only, but protocol analyzers are provided from some test equipment vendors.\nIts modulation method is PWM (Pulse-Width Modulation) with 6.00 MHz base clock originally, but most of automotive customers use 6.291 MHz, and physical layer is a pair of differential signalling harness. Its physical layer adopts half-duplex, asynchronous, and multi-master communication with carrier-sense multiple access with collision detection (CSMA/CD) for medium access control. It allows for up to fifty units on one bus over a maximum length of 150 meters. Two differential signalling lines are used with Bus+ / Bus− naming, sometimes labeled as Data(+) / Data(−).\nIt is sometimes described as \"IE-BUS\", \"IE-Bus,\" or \"IE Bus,\" but these are incorrect. In formal, it is \"IEBus.\"\nIEBus® and Inter Equipment Bus® are registered trademark symbols of Renesas Electronics Corporation, formerly NEC Electronics Corporation, (JPO: Reg. No.2552418\nand 2552419, respectively).",
    "link": "https://en.wikipedia.org/wiki/IEBus"
  },
  {
    "title": "IWARP",
    "slug": "iwarp",
    "content": "iWARP is a computer networking protocol that implements remote direct memory access (RDMA) for efficient data transfer over Internet Protocol networks. Contrary to some accounts, iWARP is not an acronym.\nBecause iWARP is layered on Internet Engineering Task Force (IETF)-standard congestion-aware protocols such as Transmission Control Protocol (TCP) and Stream Control Transmission Protocol (SCTP), it makes few requirements on the network, and can be successfully deployed in a broad range of environments.",
    "link": "https://en.wikipedia.org/wiki/IWARP"
  },
  {
    "title": "VSAN",
    "slug": "vsan",
    "content": "A virtual storage area network (virtual SAN, VSAN or vSAN) is a logical representation of a physical storage area network (SAN). A VSAN abstracts the storage-related operations from the physical storage layer, and provides shared storage access to the applications and virtual machines by combining the servers' local storage over a network into a single or multiple storage pools.\nThe use of VSANs allows the isolation of traffic within specific portions of the network. If a problem occurs in one VSAN, that problem can be handled with a minimum of disruption to the rest of the network.  VSANs can also be configured separately and independently.",
    "link": "https://en.wikipedia.org/wiki/VSAN"
  },
  {
    "title": "Usenet",
    "slug": "usenet",
    "content": "Usenet (), a portmanteau of User's Network, is a worldwide distributed discussion system available on computers. It was developed from the general-purpose Unix-to-Unix Copy (UUCP) dial-up network architecture. Tom Truscott and Jim Ellis conceived the idea in 1979, and it was established in 1980. Users read and post messages (called articles or posts, and collectively termed news) to one or more topic categories, known as newsgroups. Usenet resembles a bulletin board system (BBS) in many respects and is the precursor to the Internet forums that were developed after the introduction of the World Wide Web. Discussions are threaded, as with web forums and BBSes, though posts are stored on the server sequentially.\nA major difference between a BBS or web message board and Usenet is the absence of a central server and dedicated administrator or hosting provider. Usenet is distributed among a large, constantly changing set of news servers that store and forward messages to one another via \"news feeds\". Individual users may read messages from and post to a local (or simply preferred) news server, which can be operated by anyone, and those posts will automatically be forwarded to any other news servers peered with the local one, while the local server will receive any news its peers have that it currently lacks. This results in the automatic proliferation of content posted by any user on any server to any other user subscribed to the same newsgroups on other servers.\nAs with BBSes and message boards, individual news servers or service providers are under no obligation to carry any specific content, and may refuse to do so for many reasons: a news server might attempt to control the spread of spam by refusing to accept or forward any posts that trigger spam filters, or a server without high-capacity data storage may refuse to carry any newsgroups used primarily for file sharing, limiting itself to discussion-oriented groups. However, unlike BBSes and web forums, the dispersed nature of Usenet usually permits users who are interested in receiving some content to access it simply by choosing to connect to news servers that carry the feeds they want.\nUsenet is culturally and historically significant in the networked world, having given rise to, or popularized, many widely recognized concepts and terms such as \"FAQ\", \"flame\", \"sockpuppet\", and \"spam\".  In the early 1990s, shortly before access to the Internet became commonly affordable, Usenet connections via FidoNet's dial-up BBS networks made long-distance or worldwide discussions and other communication widespread.\n\nThe name Usenet comes from the term \"users' network\". The first Usenet group was NET.general, which quickly became net.general. The first commercial spam on Usenet was from immigration attorneys Canter and Siegel advertising green card services.\nOn the Internet, Usenet is transported via the Network News Transfer Protocol (NNTP) on Transmission Control Protocol (TCP) port 119 for standard, unprotected connections, and on TCP port 563 for Secure Sockets Layer (SSL) encrypted connections.",
    "link": "https://en.wikipedia.org/wiki/Usenet"
  },
  {
    "title": "X.1035",
    "slug": "x1035",
    "content": "ITU-T Recommendation X.1035 specifies a password-authenticated key agreement protocol that ensures mutual authentication of two parties by using a Diffie–Hellman key exchange to establish a symmetric cryptographic key. The use of Diffie-Hellman exchange ensures perfect forward secrecy—a property of a key establishment protocol that guarantees that compromise of a session key or long-term private key after a given session does not cause the compromise of any earlier session.\nIn X.1035, the exchange is protected from the man-in-the-middle attack. The authentication relies on a pre-shared secret (e.g., password), which is protected (i.e., remains unrevealed) to an eavesdropper preventing an off-line dictionary attack.\nThe protocol can be used in a wide variety of applications including those with pre-shared secrets based on possibly weak passwords.\nX.1035 was approved on 13 February 2007 by ITU-T Study Group 17.",
    "link": "https://en.wikipedia.org/wiki/X.1035"
  },
  {
    "title": "VRPN",
    "slug": "vrpn",
    "content": "VRPN (Virtual-Reality Peripheral Network) is a device-independent, network-based interface for accessing virtual reality peripherals in VR applications.  It was originally designed and implemented by Russell M. Taylor II at the Department of Computer Science of the University of North Carolina at Chapel Hill.  VRPN was maintained and supported by Sensics while it was business.  It is currently maintained by ReliaSolve and developed in collaboration with a productive community of contributors.  It is described more fully at vrpn.net and in VRPN-VRST.\nThe purpose of VRPN is to provide a unified interface to input devices, like motion trackers or joystick controllers. It also provides the following:\n\nTime-stamping of data\nMultiple simultaneous access to peripheral devices\nAutomatic re-connection of failed servers\nStorage and playback of sessions\nThe VRPN system consists of programming interfaces for both the client application and the hardware drivers and a server application that communicates with the hardware devices. The client interfaces are written in C++ but have been wrapped in C#, Python and Java.\nA typical application of VRPN is to encode and send 6DoF motion capture data through the network in real time.",
    "link": "https://en.wikipedia.org/wiki/VRPN"
  },
  {
    "title": "Torus interconnect",
    "slug": "torus-interconnect",
    "content": "A torus interconnect is a switch-less network topology for connecting processing nodes in a parallel computer system.",
    "link": "https://en.wikipedia.org/wiki/Torus_interconnect"
  },
  {
    "title": "TRAME",
    "slug": "trame",
    "content": "TRAME (TRAnsmission of MEssages) was the name of the second computer network in the world similar to the internet to be used in an electric utility. Like the internet, the base technology was packet switching; it was developed by the electric utility ENHER in Barcelona. It was deployed by the same utility, first in Catalonia and Aragón, Spain, and later in other places. Its development started in 1974 and the first routers, called nodes at that time, were deployed by 1978. The network was in operation until 2016 (38 years) with successive technological software and hardware updates.",
    "link": "https://en.wikipedia.org/wiki/TRAME"
  }
]